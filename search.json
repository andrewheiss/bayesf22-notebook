[
  {
    "objectID": "bayes-rules/02-chapter.html",
    "href": "bayes-rules/02-chapter.html",
    "title": "Reading notes",
    "section": "",
    "text": "# Load packages\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(janitor)\n\n# Import article data\ndata(fake_news)\n\nperc <- scales::label_percent(accuracy = 1)\nperc2 <- scales::label_percent(accuracy = 0.01)\nHow many are fake vs. real?\n60/150 or 40% of news articles are fake .\nHow is the use of exclamation marks distributed across fake and real news articles?\n16/60 or 26.67% of news articles with !s are fake; only 2/90 or 2.22% of real articles with have !s.\nOur prior is thus that 40% of news articles are fake. We have new data, that !s are more common in fake news articles. So what’s the posterior if we find an article with a !?"
  },
  {
    "objectID": "bayes-rules/02-chapter.html#conditional-probabilities",
    "href": "bayes-rules/02-chapter.html#conditional-probabilities",
    "title": "Reading notes",
    "section": "Conditional probabilities",
    "text": "Conditional probabilities\nWe have two variables:\n\nFake vs. real status\nUse of exclamation points\n\nThese features can vary at random across different articles, so we have to represent that randomness with probabilities models\n\nPrior probability model\nWe know from previous data that 40% are fake and 60% are real. If \\(B\\) means the article is fake, we can write that as\n\\[\nP(B) = 0.40 \\text{ and } P(B^c) = 0.60\n\\]\n\n\nConditional probability\nThe occurrence of !s depends on fakeness. Conditional probabilities of !s and fakeness, where \\(A\\) is the use of an exclamation mark:\n\\[\nP(A \\mid B) = 0.2667 \\text{ and } P(A \\mid B^c) = 0.0222\n\\]\nBy comparing conditional vs. unconditional probabilities, we learn how much \\(B\\) can inform our understanding of \\(A\\).\nAn event \\(A\\) might increase in probability given \\(B\\), like how the probability of joining an orchestra is greater if we know someonw practices daily:\n\\[\nP(\\text{join orchestra} \\mid \\text{practice daily}) > P(\\text{join orchestra})\n\\]\nOr the probability of getting the flu is lower if you know someone washes their hands a lot:\n\\[\nP(\\text{get flu} \\mid \\text{wash hands regularly}) < P(\\text{get flu})\n\\]\n\n\nLikelihood\nLikelihood is kind of like the inverse of probability (not really! just that the order of A and B matters)\n\nIf we know \\(B\\), the conditional probability \\(P(\\cdot \\mid B)\\) lets us compare the probabilities of an unknown event \\(A\\) (or \\(A^c\\)) occurring with \\(B\\), or\n\\[\nP(A \\mid B) \\text{ vs. } P(A^c \\mid B)\n\\]\nIf we know \\(A\\), the likelihood function \\(L(\\cdot \\mid A) = P(A \\mid \\cdot)\\) lets us compare the relative compatibility of data \\(A\\) with events \\(B\\) or \\(B^c\\)\n\\[\nL(B \\mid A) \\text{ vs. } L(B^c \\mid A)\n\\]\n\nWhat this looks like in practice, where \\(A\\) means having an exclamation mark and \\(B\\) means being fake:\n\n# Prior probability\nrow_prior <- fake_news %>% \n  count(type) %>% \n  mutate(prop = n / sum(n)) %>% \n  select(-n) %>% \n  pivot_wider(names_from = type, values_from = prop)\n\n# Likelihood\nrow_likelihood <- fake_news %>% \n  count(type, title_has_excl) %>% \n  pivot_wider(names_from = title_has_excl, values_from = n) %>% \n  mutate(likelihood = `TRUE` / (`TRUE` + `FALSE`)) %>% \n  select(-c(`FALSE`, `TRUE`)) %>%\n  pivot_wider(names_from = type, values_from = likelihood)\n\nbind_cols(Statistic = c(\"Prior probability\", \"Likelihood\"),\n          bind_rows(row_prior, row_likelihood)) %>% \n  mutate(Total = fake + real) %>% \n  rename(`Fake ($B$)` = fake, \n         `Real ($B^c$)` = real) %>% \n  knitr::kable(digits = 3)\n\n\n\n\nStatistic\nFake (\\(B\\))\nReal (\\(B^c\\))\nTotal\n\n\n\n\nPrior probability\n0.400\n0.600\n1.000\n\n\nLikelihood\n0.267\n0.022\n0.289\n\n\n\n\n\n\n\nNormalizing constants\nThe last piece we need is the marginal probability of observing exclamation points across all articles, or \\(P(A)\\), which is the normalizing constant, or \\(P(B)L(B \\mid A) + P(B^c)L(B^c \\mid A)\\)\n\nfake_news %>% \n  count(type, title_has_excl) %>% \n  mutate(prop = n / sum(n)) %>% \n  filter(title_has_excl == TRUE) %>% \n  summarize(normalizing_constant = sum(prop))\n##   normalizing_constant\n## 1                 0.12\n\n\n\nFinal analytical posterior\nThus, given this formula:\n\\[\n\\text{posterior} = \\frac{\\text{prior} \\times \\text{likelihood}}{\\text{normalizing constant}}\n\\]\n…we have\n\\[\n\\text{posterior} = \\frac{0.4 \\times 0.2667}{0.12} = 0.889\n\\]"
  },
  {
    "objectID": "bayes-rules/02-chapter.html#simulation",
    "href": "bayes-rules/02-chapter.html#simulation",
    "title": "Reading notes",
    "section": "Simulation",
    "text": "Simulation\nWe can simulate this too\n\nsim_params <- tibble(type = c(\"real\", \"fake\"),\n                     prior = c(0.6, 0.4))\n\nset.seed(1234)\n\nsims <- sample(sim_params$type, size = 10000, prob = sim_params$prior, replace = TRUE) %>% \n  enframe(value = \"type\") %>% \n  mutate(data_model = case_when(type == \"fake\" ~ 0.2667,\n                                type == \"real\" ~ 0.0222)) %>% \n  rowwise() %>% \n  mutate(usage = sample(c(\"no\", \"yes\"), size = 1,\n                        prob = c(1 - data_model, data_model))) %>% \n  ungroup()\n\nsims %>% \n  tabyl(usage, type) %>% \n  adorn_totals(c(\"col\", \"row\"))\n##  usage fake real Total\n##     no 2914 5872  8786\n##    yes 1075  139  1214\n##  Total 3989 6011 10000\n\nggplot(sims, aes(x = type, fill = usage)) +\n  geom_bar(position = position_fill())\n\n\n\n\n# Posterior\nsims %>% \n  filter(usage == \"yes\") %>% \n  count(type) %>% \n  mutate(prop = n / sum(n))\n## # A tibble: 2 × 3\n##   type      n  prop\n##   <chr> <int> <dbl>\n## 1 fake   1075 0.886\n## 2 real    139 0.114"
  },
  {
    "objectID": "bayes-rules/02-chapter.html#chess-simulation",
    "href": "bayes-rules/02-chapter.html#chess-simulation",
    "title": "Reading notes",
    "section": "Chess simulation",
    "text": "Chess simulation\n\nchess <- c(0.2, 0.5, 0.8)\nprior <- c(0.1, 0.25, 0.65)\n\nset.seed(1234)\nchess_sim <- tibble(pi = sample(chess, size = 10000, prob = prior, replace = TRUE)) %>% \n  mutate(y = rbinom(n(), size = 6, prob = pi))\n\nchess_sim %>% \n  count(pi) %>% \n  mutate(prop = n / sum(n))\n## # A tibble: 3 × 3\n##      pi     n   prop\n##   <dbl> <int>  <dbl>\n## 1   0.2   986 0.0986\n## 2   0.5  2523 0.252 \n## 3   0.8  6491 0.649\n\nchess_sim %>% \n  ggplot(aes(x = y)) +\n  stat_count(aes(y = ..prop..)) +\n  facet_wrap(vars(pi))"
  },
  {
    "objectID": "bayes-rules/03-chapter.html",
    "href": "bayes-rules/03-chapter.html",
    "title": "Reading notes",
    "section": "",
    "text": "library(bayesrules)\nlibrary(tidyverse)\nlibrary(extraDistr)\nlibrary(brms)\nlibrary(tidybayes)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nBAYES_SEED <- 1234\nset.seed(1234)"
  },
  {
    "objectID": "bayes-rules/03-chapter.html#beta-prior-model",
    "href": "bayes-rules/03-chapter.html#beta-prior-model",
    "title": "Reading notes",
    "section": "3.1: Beta prior model",
    "text": "3.1: Beta prior model\n\\[\n\\pi \\sim \\operatorname{Beta}(45, 55)\n\\]\n\nggplot() +\n  geom_function(fun = ~dbeta(., 45, 55), n = 1001) +\n  labs(title = \"dbeta(45, 55)\")\n\nggplot() +\n  geom_function(fun = ~dprop(., mean = 0.45, size = 100), n = 1001) +\n  labs(title = \"dprop(0.45, 100)\")"
  },
  {
    "objectID": "bayes-rules/03-chapter.html#binomial-data-model-and-likelihood",
    "href": "bayes-rules/03-chapter.html#binomial-data-model-and-likelihood",
    "title": "Reading notes",
    "section": "3.2: Binomial data model and likelihood",
    "text": "3.2: Binomial data model and likelihood\n\\[\nY \\mid \\pi = \\operatorname{Binomial}(50, \\pi)\n\\]"
  },
  {
    "objectID": "bayes-rules/03-chapter.html#beta-posterior-model",
    "href": "bayes-rules/03-chapter.html#beta-posterior-model",
    "title": "Reading notes",
    "section": "3.3: Beta posterior model",
    "text": "3.3: Beta posterior model\n\\[\n\\begin{aligned}\nY \\mid \\pi &= \\operatorname{Binomial}(50, \\pi) \\\\\n\\pi &\\sim \\operatorname{Beta}(45, 55)\n\\end{aligned}\n\\]\n\nmodel_election <- brm(\n  bf(support | trials(n_in_poll) ~ 0 + Intercept),\n  data = list(support = 30, n_in_poll = 50),\n  family = binomial(link = \"identity\"),\n  prior(beta(45, 55), class = b, lb = 0, ub = 1),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED,\n  backend = \"rstan\", cores = 4\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\nmodel_election %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value)) +\n  stat_halfeye(fill = clrs[6]) +\n  labs(x = \"π\", title = \"Plausible values of π that could produce\\na poll where 30/50 voters support Michelle\")\n\n\n\n\n\nmodel_election %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value)) +\n  geom_density(aes(fill = \"Posterior\"), color = NA, alpha = 0.75) +\n  stat_function(geom = \"area\", fun = ~dbeta(., 45, 55), aes(fill = \"Beta(45, 55) prior\"), alpha = 0.75) +\n  scale_fill_manual(values = clrs[5:6])"
  },
  {
    "objectID": "bayes-rules/03-chapter.html#milgrams-experiment",
    "href": "bayes-rules/03-chapter.html#milgrams-experiment",
    "title": "Reading notes",
    "section": "Milgram’s experiment",
    "text": "Milgram’s experiment\n\\[\n\\begin{aligned}\nY \\mid \\pi &= \\operatorname{Binomial}(40, \\pi) \\\\\n\\pi &\\sim \\operatorname{Beta}(1, 10)\n\\end{aligned}\n\\]\n\nmodel_milgram <- brm(\n  bf(obey | trials(participants) ~ 0 + Intercept),\n  data = list(obey = 26, participants = 40),\n  family = binomial(link = \"identity\"),\n  prior(beta(1, 10), class = b, lb = 0, ub = 1),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED,\n  backend = \"rstan\", cores = 4\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\nmodel_milgram %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value)) +\n  geom_density(aes(fill = \"Posterior\"), color = NA, alpha = 0.75) +\n  stat_function(geom = \"area\", fun = ~dbeta(., 1, 10), aes(fill = \"Beta(1, 10) prior\"), alpha = 0.75) +\n  scale_fill_manual(values = clrs[5:6]) +\n  xlim(c(0, 1))"
  },
  {
    "objectID": "bayes-rules/04-practice.html",
    "href": "bayes-rules/04-practice.html",
    "title": "Exercises",
    "section": "",
    "text": "library(bayesrules)\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nBAYES_SEED <- 1234\nset.seed(1234)"
  },
  {
    "objectID": "bayes-rules/04-practice.html#section",
    "href": "bayes-rules/04-practice.html#section",
    "title": "Exercises",
    "section": "4.9.2",
    "text": "4.9.2\n\nThe local ice cream shop is open until it runs out of ice cream for the day. It’s 2 p.m. and Chad wants to pick up an ice cream cone. He asks his coworkers about the chance (π) that the shop is still open. Their Beta priors for π are below:\n\n\nworker_priors <- tribble(\n  ~coworker, ~prior,\n  \"Kimya\", \"Beta(1, 2)\",\n  \"Fernando\", \"Beta(0.5, 1)\",\n  \"Ciara\", \"Beta(3, 10)\",\n  \"Taylor\", \"Beta(2, 0.1)\"\n)\n\nworker_priors %>% knitr::kable()\n\n\n\n\ncoworker\nprior\n\n\n\n\nKimya\nBeta(1, 2)\n\n\nFernando\nBeta(0.5, 1)\n\n\nCiara\nBeta(3, 10)\n\n\nTaylor\nBeta(2, 0.1)\n\n\n\n\n\n\n4.4: Choice of prior\n\nVisualize and summarize (in words) each coworker’s prior understanding of Chad’s chances to satisfy his ice cream craving.\n\n\nworker_prior_densities <- worker_priors %>% \n  mutate(shapes = str_match_all(prior, \"Beta\\\\((\\\\d+\\\\.?\\\\d*), (\\\\d+\\\\.?\\\\d*)\\\\)\")) %>% \n  mutate(shape1 = map_dbl(shapes, ~as.numeric(.x[2])),\n         shape2 = map_dbl(shapes, ~as.numeric(.x[3]))) %>% \n  mutate(range = list(seq(0, 1, length.out = 1001))) %>% \n  mutate(density = pmap(list(range, shape1, shape2), ~dbeta(..1, ..2, ..3)))\n\nworker_prior_densities %>% \n  unnest(c(range, density)) %>% \n  # Truncate this a little for plotting\n  filter(range <= 0.99, range >= 0.01) %>%\n  ggplot(aes(x = range, y = density, fill = coworker, color = coworker)) +\n  geom_line(size = 1) +\n  geom_area(position = position_identity(), alpha = 0.4) +\n  scale_fill_manual(values = clrs[c(1, 2, 3, 5)]) +\n  scale_color_manual(values = clrs[c(1, 2, 3, 5)])\n\n\n\n\n\nKimya is relatively uncertain, but leaning towards believing that π is low\nFernando puts heavy weight on very low probabilities of π—moreso than Kimya\nCiara believes that π is clustered around 20%, and no higher than 50%\nTaylor is the most optimistic, believing that π is exceptionally high (like 90+%)\n\n\n\n4.5 & 4.6: Simulating and identifying the posterior\n\nChad peruses the shop’s website. On 3 of the past 7 days, they were still open at 2 p.m.. Complete the following for each of Chad’s coworkers:\n\nsimulate their posterior model;\ncreate a histogram for the simulated posterior; and\nuse the simulation to approximate the posterior mean value of π\n\n\nand\n\nComplete the following for each of Chad’s coworkers:\n\nidentify the exact posterior model of π;\ncalculate the exact posterior mean of π; and\ncompare these to the simulation results in the previous exercise.\n\n\n\nCiara only\n\\[\n\\begin{aligned}\n(Y = 3) \\mid \\pi &= \\operatorname{Binomial}(7, \\pi) \\\\\n\\pi &\\sim \\operatorname{Beta}(3, 10)\n\\end{aligned}\n\\]\n\nBayes RulesGrid approximationbrmsRaw StanExact posterior\n\n\nThe Bayes Rules simulation approach is to simulate all the possibly likelihoods (here 0–7 / 7) and then filter to just choose one (3)\n\npi_ciara <- tibble(pi = rbeta(10000, 3, 10)) %>% \n  mutate(y = rbinom(10000, size = 7, prob = pi))\n\nggplot(pi_ciara, aes(x = pi, y = y)) +\n  geom_point(aes(color = (y == 3)))\n\n\n\n\n\npi_ciara %>% \n  filter(y == 3) %>% \n  summarize(across(pi, lst(mean, median)))\n## # A tibble: 1 × 2\n##   pi_mean pi_median\n##     <dbl>     <dbl>\n## 1   0.302     0.296\n\npi_ciara %>% \n  filter(y == 3) %>% \n  ggplot(aes(x = pi)) +\n  geom_density()\n\n\n\n\n\n\n\npi_grid <- tibble(pi_grid = seq(0, 1, length.out = 1001)) %>%\n  mutate(prior_beta = dbeta(pi_grid, 3, 10)) %>% \n  mutate(likelihood = dbinom(3, size = 7, prob = pi_grid)) %>% \n  mutate(posterior = (likelihood * prior_beta) / sum(likelihood * prior_beta))\n\npi_samples <- pi_grid %>% \n  slice_sample(n = 10000, weight_by = posterior, replace = TRUE)\n\npi_samples %>% \n  summarize(across(pi_grid, lst(mean, median)))\n## # A tibble: 1 × 2\n##   pi_grid_mean pi_grid_median\n##          <dbl>          <dbl>\n## 1        0.301          0.295\n\nggplot(pi_samples, aes(x = pi_grid)) +\n  geom_density()\n\n\n\n\n\n\n\nmodel_pi <- brm(\n  bf(days_open | trials(weekdays) ~ 0 + Intercept),\n  data = list(days_open = 3, weekdays = 7),\n  family = binomial(link = \"identity\"),\n  prior(beta(3, 10), class = b, lb = 0, ub = 1),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED,\n  backend = \"rstan\", cores = 4\n)\n## Compiling Stan program...\n## Start sampling\n\n\nmodel_pi %>% \n  spread_draws(b_Intercept) %>%\n  summarize(across(b_Intercept, lst(mean, median, hdci = ~median_hdci(., width = 0.89)))) %>% \n  unnest(b_Intercept_hdci)\n## # A tibble: 1 × 8\n##   b_Intercept_mean b_Intercept_median     y  ymin  ymax .width .point .interval\n##              <dbl>              <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>  <chr>    \n## 1            0.298              0.292 0.292 0.110 0.493   0.95 median hdci\n\n\nmodel_pi %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value)) +\n  geom_density(aes(fill = \"Posterior\"), color = NA, alpha = 0.75) +\n  stat_function(geom = \"area\", fun = ~dbeta(., 3, 10), aes(fill = \"Beta(3, 10) prior\"), alpha = 0.75) +\n  scale_fill_manual(values = clrs[5:6]) +\n  xlim(c(0, 1))\n\n\n\n\n\n\npi_stan.stan:\n\n// Things coming in from R\ndata {\n  int<lower=0> total_days;  // Possible days open (corresponds to binomial trials)\n  int<lower=0> days_open;  // Outcome variable\n}\n\n// Things to estimate\nparameters {\n  real<lower=0, upper=1> pi;  // Probability the store is open\n}\n\n// Models and distributions\nmodel {\n  // Prior\n  pi ~ beta(3, 10);\n  \n  // Likelihood\n  days_open ~ binomial(total_days, pi);\n  \n  // Internally, these ~ formulas really look like this:\n  //   target += beta_lpdf(pi | 3, 10);\n  //   target += binomial_lpmf(days_open | total_days, pi);\n  // The ~ notation is a lot nicer and maps onto the notation more directly\n}\n\n\nmodel_stan <- rstan::sampling(\n  pi_stan,\n  data = list(days_open = 3, total_days = 7),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, chains = 4\n)\n\n\nmodel_stan %>% \n  spread_draws(pi) %>% \n  summarize(across(pi, lst(mean, median)))\n## # A tibble: 1 × 2\n##   pi_mean pi_median\n##     <dbl>     <dbl>\n## 1   0.298     0.292\n\n\nmodel_stan %>% \n  spread_draws(pi) %>% \n  ggplot(aes(x = pi)) +\n  stat_halfeye()\n\n\n\n\n\n\nFrom equation 3.10 in Bayes Rules!:\n\\[\n\\begin{aligned}\n\\pi \\mid (Y = y) &\\sim \\operatorname{Beta}(\\alpha + y, \\quad \\beta + n - y) \\\\\n\\pi \\mid (Y = 3) &\\sim \\operatorname{Beta}(3 + 3, \\quad 10 + 7 - 3) \\\\\n&\\sim \\operatorname{Beta}(6, 14)\n\\end{aligned}\n\\]\n\nggplot() +\n  geom_function(fun = ~dbeta(., 6, 14))\n\n\n\n\nAnd from equation 3.11 in Bayes Rules!:\n\\[\n\\begin{aligned}\nE(\\pi \\mid Y = y) &= \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\nE(\\pi \\mid Y = 3) &= \\frac{3 + 3}{3 + 10 + 7} \\\\\n&= \\frac{6}{20} = 0.3 \\\\\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\operatorname{Mode}(\\pi \\mid Y = y) &= \\frac{\\alpha + y - 1}{\\alpha + \\beta + n - 2} \\\\\n\\operatorname{Mode}(\\pi \\mid Y = 3) &= \\frac{3 + 3 - 1}{3 + 10 + 7 - 2} \\\\\n&= \\frac{5}{18} = 0.27\\bar{7} \\\\\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\operatorname{Var}(\\pi \\mid Y = y) &= \\frac{(\\alpha + y)~(\\beta + n - y)}{(\\alpha + \\beta + n)^2~(\\alpha + \\beta + n + 1)} \\\\\n\\operatorname{Var}(\\pi \\mid Y = 3) &= \\frac{(3 + 3)~(10 + 7 - 3)}{(3 + 10 + 7)^2~(3 + 10 + 7 + 1)} \\\\\n&= \\frac{6 \\times 14}{20^2 \\times 21} = \\frac{84}{8,400} = 0.01 \\\\\n\\operatorname{SD}(\\pi \\mid Y = 3) &= \\sqrt{0.01} = 0.1\n\\end{aligned}\n\\]\nVerify using summarize_beta_binomial():\n\nsummarize_beta_binomial(alpha = 3, beta = 10, y = 3, n = 7)\n##       model alpha beta      mean      mode        var        sd\n## 1     prior     3   10 0.2307692 0.1818182 0.01267963 0.1126039\n## 2 posterior     6   14 0.3000000 0.2777778 0.01000000 0.1000000\n\n\n\n\n\n\nAll four coworkers\n(sans raw Stan; brms is fine and great for this anyway)\n\n# Clean this table of coworkers up a bit\npriors_clean <- worker_prior_densities %>% \n  select(coworker, prior, shape1, shape2)\n\npriors_clean %>% \n  knitr::kable()\n\n\n\n\ncoworker\nprior\nshape1\nshape2\n\n\n\n\nKimya\nBeta(1, 2)\n1.0\n2.0\n\n\nFernando\nBeta(0.5, 1)\n0.5\n1.0\n\n\nCiara\nBeta(3, 10)\n3.0\n10.0\n\n\nTaylor\nBeta(2, 0.1)\n2.0\n0.1\n\n\n\n\n\n\nBayes RulesGrid approximationbrmsExact posterior\n\n\n\nbr_simulation_pi <- priors_clean %>% \n  mutate(pi_sim = map2(shape1, shape2, ~{\n    tibble(pi = rbeta(10000, .x, .y)) %>% \n      mutate(y = rbinom(10000, size = 7, prob = pi))\n  }))\n\nbr_simulation_pi %>% \n  unnest(pi_sim) %>% \n  ggplot(aes(x = pi, y = y)) +\n  geom_point(aes(color = (y == 3))) +\n  facet_wrap(vars(coworker))\n\n\n\n\n\nbr_simulation_pi %>% \n  unnest(pi_sim) %>% \n  filter(y == 3) %>% \n  group_by(coworker) %>% \n  summarize(across(pi, lst(mean, median)))\n## # A tibble: 4 × 3\n##   coworker pi_mean pi_median\n##   <chr>      <dbl>     <dbl>\n## 1 Ciara      0.300     0.291\n## 2 Fernando   0.419     0.413\n## 3 Kimya      0.401     0.397\n## 4 Taylor     0.549     0.550\n\nbr_simulation_pi %>% \n  unnest(pi_sim) %>% \n  filter(y == 3) %>% \n  ggplot(aes(x = pi, fill = coworker, color = coworker)) +\n  geom_density(size = 1, alpha = 0.4) +\n  scale_fill_manual(values = clrs[c(1, 2, 3, 5)]) +\n  scale_color_manual(values = clrs[c(1, 2, 3, 5)])\n\n\n\n\nCool cool. Fernando and Kimya’s flatter priors end up leading to posteriors of ≈40%. Taylor’s extreme optimism leads to a posterior mean of 57%! Ciara’s more reasonable range leads to a posterior of 30%.\n\n\n\ngrid_simulation_pi <- priors_clean %>% \n  mutate(pi_grid = list(seq(0.01, 0.99, length.out = 1001))) %>% \n  mutate(prior_beta = pmap(list(pi_grid, shape1, shape2), ~{\n    dbeta(..1, ..2, ..3)\n  })) %>% \n  mutate(likelihood = map(pi_grid, ~{\n    dbinom(3, size = 7, prob = .x)\n  })) %>% \n  mutate(posterior = map2(prior_beta, likelihood, ~{\n    (.y * .x) / sum(.y * .x)\n  })) \n\ngrid_simulation_samples <- grid_simulation_pi %>% \n  unnest(c(pi_grid, posterior)) %>% \n  group_by(coworker) %>% \n  slice_sample(n = 10000, weight_by = posterior, replace = TRUE)\n\ngrid_simulation_samples %>% \n  group_by(coworker) %>% \n  summarize(across(pi_grid, lst(mean, median)))\n## # A tibble: 4 × 3\n##   coworker pi_grid_mean pi_grid_median\n##   <chr>           <dbl>          <dbl>\n## 1 Ciara           0.300          0.294\n## 2 Fernando        0.412          0.404\n## 3 Kimya           0.399          0.393\n## 4 Taylor          0.550          0.556\n\ngrid_simulation_samples %>% \n  ggplot(aes(x = pi_grid, fill = coworker, color = coworker)) +\n  geom_density(size = 1, alpha = 0.4) +\n  scale_fill_manual(values = clrs[c(1, 2, 3, 5)]) +\n  scale_color_manual(values = clrs[c(1, 2, 3, 5)])\n\n\n\n\n\n\n\nbrms_pi <- priors_clean %>% \n  mutate(stan_prior = map2(shape1, shape2, ~{\n    prior_string(glue::glue(\"beta({.x}, {.y})\"), class = \"b\", lb = 0, ub = 1)\n  })) %>% \n  mutate(model = map(stan_prior, ~{\n    brm(\n      bf(days_open | trials(weekdays) ~ 0 + Intercept),\n      data = list(days_open = 3, weekdays = 7),\n      family = binomial(link = \"identity\"),\n      prior = .x,\n      iter = 5000, warmup = 1000, seed = BAYES_SEED,\n      backend = \"rstan\", cores = 4\n    )\n  }))\n## Compiling Stan program...\n## Start sampling\n## Compiling Stan program...\n## Start sampling\n## Compiling Stan program...\n## Start sampling\n## Compiling Stan program...\n## Start sampling\n\n\nbrms_pi %>% \n  mutate(draws = map(model, ~spread_draws(., b_Intercept))) %>% \n  unnest(draws) %>% \n  group_by(coworker) %>% \n  summarize(across(b_Intercept, lst(mean, median, hdci = ~median_hdci(., width = 0.89)))) %>% \n  unnest(b_Intercept_hdci)\n## # A tibble: 4 × 9\n##   coworker b_Intercept_mean b_Intercep…¹     y  ymin  ymax .width .point .inte…²\n##   <chr>               <dbl>        <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>  <chr>  \n## 1 Ciara               0.298        0.292 0.292 0.110 0.493   0.95 median hdci   \n## 2 Fernando            0.411        0.403 0.403 0.125 0.726   0.95 median hdci   \n## 3 Kimya               0.399        0.392 0.392 0.130 0.693   0.95 median hdci   \n## 4 Taylor              0.547        0.552 0.552 0.258 0.850   0.95 median hdci   \n## # … with abbreviated variable names ¹​b_Intercept_median, ²​.interval\n\n\nbrms_pi %>% \n  mutate(draws = map(model, ~gather_draws(., b_Intercept))) %>% \n  unnest(draws) %>% \n  ggplot(aes(x = .value, fill = coworker)) +\n  stat_halfeye(alpha = 0.4) +\n  scale_fill_manual(values = clrs[c(1, 2, 3, 5)])\n\n\n\n\n\n\n\nlik_y <- 3\nlik_n <- 7\n\nposteriors_manual <- priors_clean %>% \n  mutate(posterior_shape1 = shape1 + lik_y,\n         posterior_shape2 = shape2 + lik_n - lik_y)\n\nposteriors_manual %>% \n  mutate(posterior = glue::glue(\"Beta({posterior_shape1}, {posterior_shape2})\")) %>% \n  select(coworker, prior, posterior) %>% \n  knitr::kable()\n\n\n\n\ncoworker\nprior\nposterior\n\n\n\n\nKimya\nBeta(1, 2)\nBeta(4, 6)\n\n\nFernando\nBeta(0.5, 1)\nBeta(3.5, 5)\n\n\nCiara\nBeta(3, 10)\nBeta(6, 14)\n\n\nTaylor\nBeta(2, 0.1)\nBeta(5, 4.1)\n\n\n\n\n\n\nposteriors_manual_plot <- posteriors_manual %>% \n  mutate(range = list(seq(0.01, 0.99, length.out = 1001))) %>% \n  mutate(density = pmap(list(range, posterior_shape1, posterior_shape2), ~dbeta(..1, ..2, ..3)))\n\nposteriors_manual_plot %>% \n  unnest(c(range, density)) %>% \n  ggplot(aes(x = range, y = density, fill = coworker, color = coworker)) +\n  geom_line(size = 1) +\n  geom_area(position = position_identity(), alpha = 0.4) +\n  scale_fill_manual(values = clrs[c(1, 2, 3, 5)]) +\n  scale_color_manual(values = clrs[c(1, 2, 3, 5)])\n\n\n\n\n\nposteriors_manual_summary <- posteriors_manual %>% \n  group_by(coworker) %>% \n  summarize(summary = map2(shape1, shape2, ~{\n    summarize_beta_binomial(alpha = .x, beta = .y, y = lik_y, n = lik_n)\n  })) %>% \n  unnest(summary) \n\nposteriors_manual_summary %>% \n  select(-coworker) %>% \n  kableExtra::kbl(digits = 3) %>% \n  kableExtra::pack_rows(index = table(posteriors_manual_summary$coworker)) %>% \n  kableExtra::kable_styling()\n\n\n\n \n  \n    model \n    alpha \n    beta \n    mean \n    mode \n    var \n    sd \n  \n \n\n  Ciara\n\n    prior \n    3.0 \n    10.0 \n    0.231 \n    0.182 \n    0.013 \n    0.113 \n  \n  \n    posterior \n    6.0 \n    14.0 \n    0.300 \n    0.278 \n    0.010 \n    0.100 \n  \n  Fernando\n\n    prior \n    0.5 \n    1.0 \n    0.333 \n    1.000 \n    0.089 \n    0.298 \n  \n  \n    posterior \n    3.5 \n    5.0 \n    0.412 \n    0.385 \n    0.025 \n    0.160 \n  \n  Kimya\n\n    prior \n    1.0 \n    2.0 \n    0.333 \n    0.000 \n    0.056 \n    0.236 \n  \n  \n    posterior \n    4.0 \n    6.0 \n    0.400 \n    0.375 \n    0.022 \n    0.148 \n  \n  Taylor\n\n    prior \n    2.0 \n    0.1 \n    0.952 \n    1.000 \n    0.015 \n    0.121 \n  \n  \n    posterior \n    5.0 \n    4.1 \n    0.549 \n    0.563 \n    0.025 \n    0.157"
  },
  {
    "objectID": "bayes-rules/05-chapter.html",
    "href": "bayes-rules/05-chapter.html",
    "title": "Reading notes",
    "section": "",
    "text": "library(bayesrules)\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nset.seed(1234)\nBAYES_SEED <- 1234\nConjugate families are neat because they let us calculate exact posteriors without difficult integration, like the beta binomial trick:\n\\[\n\\pi \\mid (Y = y) \\sim \\operatorname{Beta}(\\alpha + y, \\quad \\beta + n - y)\n\\]"
  },
  {
    "objectID": "bayes-rules/05-chapter.html#gamma-poisson-conjugate-family",
    "href": "bayes-rules/05-chapter.html#gamma-poisson-conjugate-family",
    "title": "Reading notes",
    "section": "5.2 Gamma-Poisson conjugate family",
    "text": "5.2 Gamma-Poisson conjugate family\nUseful for modeling rates and counts, like fraudulent phone calls per day.\n\nRate of calls per day = \\(\\lambda\\). Any positive value.\nNumber of calls per day = \\(Y_i\\). Any non-negative integer.\n\n\nPoisson distributions\nSee this from program evaluation too, where I give up and say\n\nI have absolutely zero mathematical intuition for how [\\(\\lambda\\)] works. The two shape parameters for a Beta distribution at least fit in a fraction and you can wrap your head around that, but the lambda in a Poisson distribution is just a mystery to me.\n\nIn general, as the rate of events \\(\\lambda\\) increases…\n\nthe typical number of events increases,\nthe variability increases, and\nthe skew decreases\n\n\nexpand_grid(y = 0:12, lambda = c(1, 2, 5)) %>% \n  mutate(density = dpois(y, lambda)) %>% \n  ggplot(aes(x = y, y = density)) +\n  geom_col() + \n  facet_wrap(vars(lambda), \n             labeller = as_labeller(function(x) glue::glue(\"Poisson(λ = {x})\")))\n\n\n\n\n\n\nGamma distributions\nGamma models are positive and right skewed, and conjugate to Poisson. They take two hyperparameters: \\(s\\) (shape) and \\(r\\) (rate). Exponential models are Gammas with \\(s = 1\\).\n\nexpand_grid(y = seq(0, 7, length.out = 1001), s = c(1, 2, 4), r = c(1, 2)) %>% \n  mutate(density = dgamma(y, shape = s, rate = r)) %>% \n  mutate(panel_name = glue::glue(\"Gamma(s = {s}, r = {r})\"),\n         panel_name = fct_inorder(panel_name)) %>% \n  ggplot(aes(x = y, y = density)) +\n  geom_area() + \n  facet_wrap(vars(panel_name), dir = \"v\", nrow = 2)\n\n\n\n\nTuning the gamma prior: We think the rate of calls is 5 a day, with a range of 2–7ish. Through trial and error, it looks like \\(\\lambda \\sim \\operatorname{Gamma}(10, 2)\\) fits that well:\n\nggplot() +\n  geom_function(fun = ~dgamma(., shape = 10, rate = 2)) +\n  xlim(c(0, 15)) +\n  labs(x = \"λ\")\n\n\n\n\n\n\nGamma-Poisson conjugacy\nGamma and Poisson families work together like Beta and binomial!\nModel:\n\\[\n\\begin{aligned}\nY_i \\mid \\lambda &\\stackrel{\\text{ind}}{\\sim} \\operatorname{Poisson}(\\lambda) \\\\\n\\lambda &\\sim \\operatorname{Gamma}(s, r)\n\\end{aligned}\n\\]\nAnd the magical posterior based on the two distributions’ conjugacy:\n\\[\n\\lambda \\mid y \\sim \\operatorname{Gamma}(s + \\sum y_i,\\quad r + n)\n\\]\nAnd summary statistics:\n\\[\n\\begin{aligned}\nE(\\lambda) &= \\frac{s}{r} \\\\\n\\operatorname{Mode}(\\lambda) &= \\frac{s - 1}{r} \\\\\n\\operatorname{Var}(\\lambda) &= \\frac{s}{r^2} \\\\\n\\operatorname{SD}(\\lambda) &= \\sqrt{\\frac{s}{r^2}}\n\\end{aligned}\n\\]\nTime to try it!\nWe’ll assume that the daily rate of calls \\(\\lambda\\) is distributed with \\(\\operatorname{Gamma}(10, 2)\\). Over 4 days, we receive 6, 2, 2, and 1 calls. That’s an \\(n\\) of 4 and a \\(\\sum y_i\\) of (6 + 2 + 2 + 1), or 11, and an average of \\(\\frac{11}{4}\\), or 2.75.\nThe posterior model is then the \\(\\operatorname{Gamma}(10, 2)\\) prior mixed with the likelihood in fancy conjugate-y ways:\n\\[\n\\begin{aligned}\n\\lambda \\mid y &\\sim \\operatorname{Gamma}(s + \\sum y_i,\\quad r + n) \\\\\n\\lambda \\mid (6, 2, 2, 1) &\\sim \\operatorname{Gamma}(10 + 11,\\quad 2 + 4) \\\\\n&\\sim \\operatorname{Gamma}(21, 6)\n\\end{aligned}\n\\]\nThis new data changes our understanding of the rate of calls per day:\n\\[\n\\begin{aligned}\nE(\\lambda) &= \\frac{10}{2} = 5 \\text{ calls a day, from prior} \\\\\nE[\\lambda \\mid (6, 2, 2, 1)] &= \\frac{21}{6} = 3.5 \\text{ calls a day, from posterior}\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nSD(\\lambda) &= \\sqrt{\\frac{10}{2^2}} = 1.581 \\\\\nSD[\\lambda \\mid (6, 2, 2, 1)] &= \\sqrt{\\frac{21}{6^2}} = 0.764\n\\end{aligned}\n\\]\nAnd here’s what that looks like:\n\nggplot() +\n  stat_function(fun = ~dgamma(., shape = 10, rate = 2), \n                geom = \"area\", aes(fill = \"Gamma(10, 2) prior\"), alpha = 0.75) +\n  stat_function(fun = ~dgamma(., shape = (10 + 11), rate = (2 + 4)),\n                geom = \"area\", aes(fill = \"Gamma(21, 6) posterior\"), alpha = 0.75) +\n  xlim(c(0, 15)) +\n  scale_fill_manual(values = clrs[5:6])\n\n\n\n\nAnd confirming with the summarize_gamma_poisson() helper function:\n\nsummarize_gamma_poisson(shape = 10, rate = 2, sum_y = 11, n = 4)\n##       model shape rate mean     mode       var        sd\n## 1     prior    10    2  5.0 4.500000 2.5000000 1.5811388\n## 2 posterior    21    6  3.5 3.333333 0.5833333 0.7637626\n\nAnd confirming with brms, just because this conjugate prior stuff feels like dark magic:\n\nmodel_rate <- brm(\n  bf(fraud_calls ~ 0 + Intercept),\n  data = list(fraud_calls = c(6, 2, 2, 1)),\n  family = poisson(link = \"identity\"),\n  prior = prior(gamma(10, 2), class = b, lb = 0),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED,\n  backend = \"rstan\", cores = 4\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\nmodel_rate %>% \n  spread_draws(b_Intercept) %>%\n  summarize(across(b_Intercept, lst(mean, sd, median, hdci = ~median_hdci(., width = 0.89)))) %>% \n  unnest(b_Intercept_hdci)\n## # A tibble: 1 × 9\n##   b_Intercept_mean b_Intercept…¹ b_Int…²     y  ymin  ymax .width .point .inte…³\n##              <dbl>         <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>  <chr>  \n## 1             3.50         0.756    3.44  3.44  2.09  5.00   0.95 median hdci   \n## # … with abbreviated variable names ¹​b_Intercept_sd, ²​b_Intercept_median,\n## #   ³​.interval\n\n\nmodel_rate %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value)) +\n  geom_density(aes(fill = \"Posterior\"), color = NA, alpha = 0.75) +\n  stat_function(geom = \"area\", fun = ~dgamma(., 10, 2), aes(fill = \"Gamma(10, 2) prior\"), alpha = 0.75) +\n  scale_fill_manual(values = clrs[5:6]) +\n  xlim(c(0, 15))\n\n\n\n\nAHHH it works!"
  },
  {
    "objectID": "bayes-rules/05-chapter.html#normal-normal-conjugate-family",
    "href": "bayes-rules/05-chapter.html#normal-normal-conjugate-family",
    "title": "Reading notes",
    "section": "5.3: Normal-Normal conjugate family",
    "text": "5.3: Normal-Normal conjugate family\nGeneral story here: we’re interested in \\(\\mu\\)m or the average volume of the hippocampus. Wikipedia says that one half is between 3–3.5 cm3, so the total volume is between 6–7 cm3.\n\nNormal distributions\nNormal distribution defined with \\(\\mu\\) and \\(\\sigma\\) (I’ve got this intuition, but I’ll plot it anyway):\n\nexpand_grid(y = seq(-2, 10, length.out = 1001), \n            params = list(list(mu = 2, sigma = 0.5), \n                          list(mu = 2, sigma = 1),\n                          list(mu = 4, sigma = 2))) %>%\n  mutate(density = map2_dbl(y, params, ~dnorm(.x, .y$mu, .y$sigma))) %>% \n  mutate(panel_name = map_chr(params, ~glue::glue(\"N({.x$mu}, {.x$sigma})\"))) %>% \n  ggplot(aes(x = y, y = density)) +\n  geom_area() +\n  facet_wrap(vars(panel_name))\n\n\n\n\n\n\nNormal prior\nSo, if we think the volume of the hippocampus is 6.5 cm3, ± 0.8, we can do 6.5 ± (2 * 0.4), or:\n\\[\n\\mu \\sim \\mathcal{N}(6.5, 0.4^2)\n\\]\nHere’s what that looks like:\n\nggplot() +\n  geom_function(fun = ~dnorm(., mean = 6.5, sd = 0.4)) +\n  xlim(c(5, 8))\n\n\n\n\n\n\nNormal-normal conjugacy\nNormal-normal situations are conjugates, which means we can find exact posteriors without complex integration. This is a little more complicated than the nice easy Beta-binomial or even the Gamma-Poisson conjugates, though.\nHere’s the model:\n\\[\n\\begin{aligned}\nY_i \\mid \\mu &\\stackrel{\\text{ind}}{\\sim} \\mathcal{N}({\\mu, \\sigma^2}) \\\\\n\\mu &\\sim \\mathcal{N}(\\theta, \\tau^2)\n\\end{aligned}\n\\]\nAnd the magical posterior:\n\\[\n\\mu \\mid \\vec{y} \\; \\sim \\;  \\mathcal{N}\\bigg(\\theta\\frac{\\sigma^2}{n\\tau^2+\\sigma^2} + \\bar{y}\\frac{n\\tau^2}{n\\tau^2+\\sigma^2}, \\; \\frac{\\tau^2\\sigma^2}{n\\tau^2+\\sigma^2}\\bigg)\n\\]\nWow that’s a mess. We need these things:\n\nPrior mean (\\(\\theta\\))\nPrior sd (\\(\\tau\\))\nObserved mean (\\(\\bar{y}\\))\nObserved sd (\\(\\sigma\\))\nNumber of observations (\\(n\\))\n\nLet’s try it with real data, with the football data from bayesrules. What’s the average hippocampus volume for football players with concussions? This is our \\(\\bar{y}\\).\n\nconcussion_subjects <- bayesrules::football %>% \n  filter(group == \"fb_concuss\")\n\nconcussion_subjects %>% \n  summarize(across(volume, lst(mean, sd)))\n##   volume_mean volume_sd\n## 1      5.7346 0.5933976\n\nIn the book, they look at the distribution and figure that a standard deviation of 0.5 seems reasonable (and it’s basically that in the data too)\n\nconcussion_subjects %>% \n  ggplot(aes(x = volume)) +\n  geom_density()\n\n\n\n\nWith that, we have all these pieces:\n\nPrior mean (\\(\\theta\\)): 6.5\nPrior sd (\\(\\tau\\)): 0.4\nObserved mean (\\(\\bar{y}\\)): 5.735\nObserved (assumed) sd (\\(\\sigma\\)): 0.5\nNumber of observations (\\(n\\)): 25\n\nMath time!\n\\[\n\\begin{aligned}\n\\mu \\mid \\vec{y} \\; &\\sim \\; \\mathcal{N}\\bigg(\\theta\\frac{\\sigma^2}{n\\tau^2+\\sigma^2} + \\bar{y}\\frac{n\\tau^2}{n\\tau^2+\\sigma^2}, \\; \\frac{\\tau^2\\sigma^2}{n\\tau^2+\\sigma^2}\\bigg) \\\\\n&\\sim \\; \\mathcal{N}\\bigg(6.5\\frac{0.5^2}{25 \\times 0.4^2+0.5^2} + 5.735\\frac{25 \\times 0.4^2}{25 \\times 0.4^2+0.5^2}, \\; \\frac{0.4^2 \\times 0.5^2}{25 \\times 0.4^2+0.5^2}\\bigg) \\\\\n&\\sim \\; \\mathcal{N}\\bigg(5.78, 0.009^2\\bigg)\n\\end{aligned}\n\\]\nOr, with the summarize_normal_normal() helper function:\n\nsummarize_normal_normal(mean = 6.5, sd = 0.4, sigma = 0.5,\n                        y_bar = 5.735, n = 25)\n##       model mean mode         var         sd\n## 1     prior 6.50 6.50 0.160000000 0.40000000\n## 2 posterior 5.78 5.78 0.009411765 0.09701425\n\nAnd here’s what that looks like:\n\nggplot() +\n  stat_function(fun = ~dnorm(., mean = 6.5, sd = 0.4), \n                geom = \"area\", aes(fill = \"N(6.5, 0.4) prior\"), alpha = 0.75,\n                n = 1001) +\n  stat_function(fun = ~dnorm(., mean = 5.78, sd = 0.097),\n                geom = \"area\", aes(fill = \"N(5.78, 0.097) posterior\"), alpha = 0.75,\n                n = 1001) +\n  xlim(c(5, 8)) +\n  scale_fill_manual(values = clrs[6:5], guide = guide_legend(reverse = TRUE))\n\n\n\n\nAnd confirming with brms:\n\nmodel_volume <- brm(\n  bf(volume ~ 0 + Intercept),\n  data = concussion_subjects,\n  family = gaussian(),\n  prior = prior(normal(6.5, 0.4), class = b),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED,\n  backend = \"rstan\", cores = 4\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\nmodel_volume %>% \n  spread_draws(b_Intercept) %>%\n  summarize(across(b_Intercept, lst(mean, sd, median, hdci = ~median_hdci(., width = 0.89)))) %>% \n  unnest(b_Intercept_hdci)\n## # A tibble: 1 × 9\n##   b_Intercept_mean b_Intercept…¹ b_Int…²     y  ymin  ymax .width .point .inte…³\n##              <dbl>         <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>  <chr>  \n## 1             5.80         0.124    5.80  5.80  5.57  6.05   0.95 median hdci   \n## # … with abbreviated variable names ¹​b_Intercept_sd, ²​b_Intercept_median,\n## #   ³​.interval\n\n\nmodel_volume %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value)) +\n  geom_density(aes(fill = \"Posterior\"), color = NA, alpha = 0.75) +\n  stat_function(geom = \"area\", fun = ~dnorm(., 6.5, 0.4), aes(fill = \"N(6.5, 0.4) prior\"), alpha = 0.75) +\n  scale_fill_manual(values = clrs[5:6]) +\n  xlim(c(5, 8))\n\n\n\n\nSO COOL.\n\n\nOverriding the observed sd with an assumed sd\nBUT that’s not actually correct because it’s using the actual observed standard deviation (0.5934) instead of the assumed standard deviation (0.5) from the conjugate calculation earlier. I can’t figure out how to override brms’s sd, but we can use raw Stan:\nnormal_normal.stan:\n\ndata {\n  int<lower = 1> N;  // Number of observations\n  vector[N] volume;  // Observed hippocampus volumes\n  real volume_sd;    // Assumed sd of hippocampus volumes\n}\n\nparameters {\n  real mu;  // Posterior average hippocampus volume\n}\n\nmodel {\n  // Prior\n  mu ~ normal(6.5, 0.4);\n\n  // Likelihood\n  volume ~ normal(mu, volume_sd);\n}\n\n\nmodel_volume_stan <- rstan::sampling(\n  normal_normal,\n  data = list(volume = concussion_subjects$volume, \n              volume_sd = 0.5,\n              N = nrow(concussion_subjects)),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, chains = 4\n)\n\nThe results are basically identical to the math-based version!\n\nmodel_volume_stan %>% \n  spread_draws(mu) %>%\n  summarize(across(mu, lst(mean, sd, median, hdci = ~median_hdci(., width = 0.89)))) %>% \n  unnest(mu_hdci)\n## # A tibble: 1 × 9\n##   mu_mean  mu_sd mu_median     y  ymin  ymax .width .point .interval\n##     <dbl>  <dbl>     <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>  <chr>    \n## 1    5.78 0.0978      5.78  5.78  5.59  5.98   0.95 median hdci\n\n\nsummarize_normal_normal(mean = 6.5, sd = 0.4, sigma = 0.5,\n                        y_bar = 5.735, n = 25)\n##       model mean mode         var         sd\n## 1     prior 6.50 6.50 0.160000000 0.40000000\n## 2 posterior 5.78 5.78 0.009411765 0.09701425\n\nAnd the distribution is the same too:\n\nmodel_volume_stan %>% \n  gather_draws(mu) %>% \n  ggplot(aes(x = .value)) +\n  geom_density(aes(fill = \"Posterior\"), color = NA, alpha = 0.75) +\n  stat_function(geom = \"area\", fun = ~dnorm(., 6.5, 0.4), aes(fill = \"N(6.5, 0.4) prior\"), alpha = 0.75) +\n  scale_fill_manual(values = clrs[5:6]) +\n  xlim(c(5, 8))"
  },
  {
    "objectID": "bayes-rules/05-practice.html",
    "href": "bayes-rules/05-practice.html",
    "title": "Exercises",
    "section": "",
    "text": "library(bayesrules)\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nset.seed(1234)\nBAYES_SEED <- 1234"
  },
  {
    "objectID": "bayes-rules/05-practice.html#practice-gamma-poisson",
    "href": "bayes-rules/05-practice.html#practice-gamma-poisson",
    "title": "Exercises",
    "section": "Practice: Gamma-Poisson",
    "text": "Practice: Gamma-Poisson\n\n5.1: Tuning a Gamma prior\n\\[\n\\begin{aligned}\nE(\\lambda) &= \\frac{s}{r} \\\\\n\\operatorname{Mode}(\\lambda) &= \\frac{s - 1}{r} \\\\\n\\operatorname{Var}(\\lambda) &= \\frac{s}{r^2}\n\\end{aligned}\n\\]\n\nThe most common value of λ is 4, and the mean is 7.\n\\[\n\\begin{cases}\n\\frac{s}{r} = 7 & [\\text{Mean}] \\\\\n\\frac{s-1}{r} = 4 & [\\text{Mode}] \\\\\n\\end{cases}\n\\]\nSolving the system of equations gives:\n\\[\n\\begin{aligned}\nr &= \\frac{1}{3} \\\\\ns &= \\frac{7}{3}\n\\end{aligned}\n\\]\nOr with code:\n\neq_mean <- function(r) 7 * r\neq_mode <- function(r) (4 * r) + 1\n\nr <- uniroot(function(x) eq_mean(x) - eq_mode(x), c(0, 100))$root\ns <- eq_mean(r)\n\nr; s\n## [1] 0.3333333\n## [1] 2.333333\n\n\nggplot() +\n  stat_function(fun = ~dgamma(., shape = 7/3, rate = 1/3), geom = \"area\",\n                fill = clrs[2]) +\n  geom_vline(xintercept = 4, linetype = \"21\", color = clrs[6]) +\n  annotate(geom = \"label\", x = 4, y = 0.01, label = \"Mode\", \n           fill = clrs[6], color = \"white\") +\n  geom_vline(xintercept = 7, linetype = \"23\", color = clrs[3]) +\n  annotate(geom = \"label\", x = 7, y = 0.01, label = \"Mean\", \n           fill = clrs[3], color = \"white\") +\n  xlim(c(0, 20))\n\n\n\n\n\nThe most common value of λ is 10 and the mean is 12.\n\\[\n\\begin{cases}\n\\frac{s}{r} = 12 & [\\text{Mean}] \\\\\n\\frac{s-1}{r} = 10 & [\\text{Mode}] \\\\\n\\end{cases}\n\\]\nSolving the system of equations gives:\n\\[\n\\begin{aligned}\nr &= \\frac{1}{2} \\\\\ns &= 6\n\\end{aligned}\n\\]\nOr with code:\n\neq_mean <- function(r) 12 * r\neq_mode <- function(r) (10 * r) + 1\n\nr <- uniroot(function(x) eq_mean(x) - eq_mode(x), c(0, 100))$root\ns <- eq_mean(r)\n\nr; s\n## [1] 0.5\n## [1] 6\n\n\nggplot() +\n  stat_function(fun = ~dgamma(., shape = 6, rate = 0.5), geom = \"area\",\n                fill = clrs[2]) +\n  geom_vline(xintercept = 10, linetype = \"21\", color = clrs[6]) +\n  annotate(geom = \"label\", x = 10, y = 0.01, label = \"Mode\", \n           fill = clrs[6], color = \"white\") +\n  geom_vline(xintercept = 12, linetype = \"23\", color = clrs[3]) +\n  annotate(geom = \"label\", x = 12, y = 0.02, label = \"Mean\", \n           fill = clrs[3], color = \"white\") +\n  xlim(c(0, 40))\n\n\n\n\n\nThe most common value of λ is 5, and the variance is 3.\n\\[\n\\begin{cases}\n\\frac{s-1}{r} = 5 & [\\text{Mode}] \\\\\n\\frac{s}{r^2} = 3 & [\\text{Variance}] \\\\\n\\end{cases}\n\\]\nSolving the system of equations gives:\n\\[\n\\begin{aligned}\nr &= \\frac{5 \\pm \\sqrt{37}}{6} \\\\\ns &= \\frac{31 \\pm 5\\sqrt{37}}{6}\n\\end{aligned}\n\\]\nlol k\n\nr <- (5 + sqrt(37)) / 6\ns <- (31 + 5*sqrt(37)) / 6\n\nr; s\n## [1] 1.847127\n## [1] 10.23564\n\nYep, it works:\n\ntable(round(rgamma(10000, shape = s, rate = r)))\n## \n##    1    2    3    4    5    6    7    8    9   10   11   12   13 \n##    2  149  845 1871 2427 2108 1338  692  355  143   42   22    6\nvar(rgamma(10000, shape = s, rate = r))\n## [1] 3.013767\n\n\nggplot() +\n  stat_function(fun = ~dgamma(., shape = s, rate = r), geom = \"area\",\n                fill = clrs[2]) +\n  geom_vline(xintercept = 5, linetype = \"21\", color = clrs[6]) +\n  annotate(geom = \"label\", x = 5, y = 0.01, label = \"Mode\",\n           fill = clrs[6], color = \"white\") +\n  xlim(c(0, 12))\n\n\n\n\n\nAnd so on… I get the point :)\n\n\n5.2: Poisson likelihood functions\nFrom equation 5.6 in Bayes Rules:\n\\[\nL(\\lambda \\mid \\vec{y}) ~ \\propto ~ \\lambda^{\\sum y_i}e^{-n\\lambda}\n\\]\nIn code:\n\nL <- function(lambda, sum_y, n) lambda^sum_y * exp(-n * lambda)\n\n(3, 7, 19)\n\nobserved_data <- c(3, 7, 19)\nn <- length(observed_data)\nsum_y <- sum(observed_data)\n\n\n\\(n\\) = 3\n\\(\\sum y_i\\) = 29\n\n\\[\nL(\\lambda \\mid \\vec{y}) ~ \\propto ~ \\lambda^{29} e^{-3\\lambda}\n\\]\n\nggplot() +\n  stat_function(fun = ~L(., sum_y, n), geom = \"area\", fill = clrs[1]) +\n  xlim(c(0, 20))\n\n\n\n\n\n(12, 12, 12, 0)\n\nobserved_data <- c(12, 12, 12, 0)\nn <- length(observed_data)\nsum_y <- sum(observed_data)\n\n\n\\(n\\) = 4\n\\(\\sum y_i\\) = 36\n\n\\[\nL(\\lambda \\mid \\vec{y}) ~ \\propto ~ \\lambda^{36} e^{-4\\lambda}\n\\]\n\nggplot() +\n  stat_function(fun = ~L(., sum_y, n), geom = \"area\", fill = clrs[1]) +\n  xlim(c(0, 20))\n\n\n\n\n\n(12)\n\nobserved_data <- c(12)\nn <- length(observed_data)\nsum_y <- sum(observed_data)\n\n\n\\(n\\) = 1\n\\(\\sum y_i\\) = 12\n\n\\[\nL(\\lambda \\mid \\vec{y}) ~ \\propto ~ \\lambda^{12} e^{-\\lambda}\n\\]\n\nggplot() +\n  stat_function(fun = ~L(., sum_y, n), geom = \"area\", fill = clrs[1]) +\n  xlim(c(0, 30))\n\n\n\n\n\n(16, 10, 17, 11, 11)\n\nobserved_data <- c(16, 10, 17, 11, 11)\nn <- length(observed_data)\nsum_y <- sum(observed_data)\n\n\n\\(n\\) = 5\n\\(\\sum y_i\\) = 65\n\n\\[\nL(\\lambda \\mid \\vec{y}) ~ \\propto ~ \\lambda^{65} e^{-5\\lambda}\n\\]\n\nggplot() +\n  stat_function(fun = ~L(., sum_y, n), geom = \"area\", fill = clrs[1]) +\n  xlim(c(0, 20))\n\n\n\n\n\n\n5.3: Gamma-Poisson posteriors\nPrior:\n\\[\n\\lambda \\sim \\operatorname{Gamma}(24, 2)\n\\]\nModel:\n\\[\n\\begin{aligned}\nY_i \\mid \\lambda &\\stackrel{\\text{ind}}{\\sim} \\operatorname{Poisson}(\\lambda) \\\\\n\\lambda &\\sim \\operatorname{Gamma}(s, r)\n\\end{aligned}\n\\]\nConjugate posterior:\n\\[\n\\lambda \\mid y \\sim \\operatorname{Gamma}(s + \\sum y_i,\\quad r + n)\n\\]\n(3, 7, 19)\n\nobserved_data <- c(3, 7, 19)\n\n\n\\(n\\) = 3\n\\(\\sum y_i\\) = 29\n\n\\[\n\\begin{aligned}\n\\lambda \\mid y &\\sim \\operatorname{Gamma}(s + \\sum y_i,\\quad r + n) \\\\\n\\lambda \\mid (3, 7, 19) &\\sim \\operatorname{Gamma}(24 + 29,\\quad 2 + 3) \\\\\n&\\sim \\operatorname{Gamma}(53, 5)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nE(\\lambda) &= \\frac{24}{2} = 12 \\text{ from prior} \\\\\nE[\\lambda \\mid (3, 7, 19)] &= \\frac{53}{5} = 10.6 \\text{ from posterior}\n\\end{aligned}\n\\]\n\n(12, 12, 12, 0)\n\nobserved_data <- c(12, 12, 12, 0)\n\n\n\\(n\\) = 4\n\\(\\sum y_i\\) = 36\n\n\\[\n\\begin{aligned}\n\\lambda \\mid y &\\sim \\operatorname{Gamma}(s + \\sum y_i,\\quad r + n) \\\\\n\\lambda \\mid (12, 12, 12, 0) &\\sim \\operatorname{Gamma}(24 + 36,\\quad 2 + 4) \\\\\n&\\sim \\operatorname{Gamma}(60, 6)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nE(\\lambda) &= \\frac{24}{2} = 12 \\text{ from prior} \\\\\nE[\\lambda \\mid (12, 12, 12, 0)] &= \\frac{60}{6} = 10 \\text{ from posterior}\n\\end{aligned}\n\\]\n\n(12)\n\nobserved_data <- c(12)\n\n\n\\(n\\) = 1\n\\(\\sum y_i\\) = 12\n\n\\[\n\\begin{aligned}\n\\lambda \\mid y &\\sim \\operatorname{Gamma}(s + \\sum y_i,\\quad r + n) \\\\\n\\lambda \\mid (12) &\\sim \\operatorname{Gamma}(24 + 12,\\quad 2 + 1) \\\\\n&\\sim \\operatorname{Gamma}(36, 3)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nE(\\lambda) &= \\frac{24}{2} = 12 \\text{ from prior} \\\\\nE[\\lambda \\mid (12)] &= \\frac{36}{3} = 12 \\text{ from posterior}\n\\end{aligned}\n\\]\n\n(16, 10, 17, 11, 11)\n\nobserved_data <- c(16, 10, 17, 11, 11)\n\n\n\\(n\\) = 5\n\\(\\sum y_i\\) = 65\n\n\\[\n\\begin{aligned}\n\\lambda \\mid y &\\sim \\operatorname{Gamma}(s + \\sum y_i,\\quad r + n) \\\\\n\\lambda \\mid (16, 10, 17, 11, 11) &\\sim \\operatorname{Gamma}(24 + 65,\\quad 2 + 5) \\\\\n&\\sim \\operatorname{Gamma}(89, 7)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nE(\\lambda) &= \\frac{24}{2} = 12 \\text{ from prior} \\\\\nE[\\lambda \\mid (16, 10, 17, 11, 11)] &= \\frac{89}{7} = 12.714 \\text{ from posterior}\n\\end{aligned}\n\\]\n\nggplot() +\n  stat_function(fun = ~dgamma(., shape = 24, rate = 2), \n                geom = \"area\", aes(fill = \"Gamma(24, 2) prior\"), alpha = 0.75) +\n  stat_function(fun = ~dgamma(., shape = 53, rate = 5),\n                geom = \"area\", aes(fill = \"Gamma(53, 5) posterior\"), alpha = 0.75) +\n  stat_function(fun = ~dgamma(., shape = 60, rate = 6),\n                geom = \"area\", aes(fill = \"Gamma(60, 6) posterior\"), alpha = 0.75) +\n  stat_function(fun = ~dgamma(., shape = 36, rate = 3),\n                geom = \"area\", aes(fill = \"Gamma(36, 3) posterior\"), alpha = 0.75) +\n  stat_function(fun = ~dgamma(., shape = 89, rate = 7),\n                geom = \"area\", aes(fill = \"Gamma(89, 7) posterior\"), alpha = 0.75) +\n  xlim(c(5, 25)) +\n  scale_fill_manual(values = clrs[1:5])\n\n\n\n\n\n\n5.5 & 5.6: Text messages"
  },
  {
    "objectID": "bayes-rules/05-practice.html#practice-normal-normal",
    "href": "bayes-rules/05-practice.html#practice-normal-normal",
    "title": "Exercises",
    "section": "Practice: Normal-Normal",
    "text": "Practice: Normal-Normal\n\n5.8: Normal likelihood functions\n\n\n5.9 & 5.10: Investing in stock\n\n\n5.11: Normal-normal calculation\n\n\n5.12: Control brains"
  },
  {
    "objectID": "bayes-rules/06-chapter.html",
    "href": "bayes-rules/06-chapter.html",
    "title": "Reading notes",
    "section": "",
    "text": "library(bayesrules)\nlibrary(tidyverse)\nlibrary(cmdstanr)\nlibrary(posterior)\nlibrary(tidybayes)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nset.seed(1234)\nBAYES_SEED <- 1234"
  },
  {
    "objectID": "bayes-rules/06-chapter.html#grid-approximation",
    "href": "bayes-rules/06-chapter.html#grid-approximation",
    "title": "Reading notes",
    "section": "6.1 Grid approximation",
    "text": "6.1 Grid approximation\n\nBeta-binomial example\n\\[\n\\begin{aligned}\nY &\\sim \\operatorname{Binomial}(10, π) \\\\\n\\pi &= \\operatorname{Beta}(2, 2)\n\\end{aligned}\n\\]\nWe can figure this posterior out mathematically using conjugate priors. If we know that Y = 9, then\n\\[\n\\pi \\mid (Y = 9) \\sim \\operatorname{Beta}(2 + 9, 10 - 2 + 2) \\rightarrow \\operatorname{Beta}(11, 3)\n\\]\nBut we can also do this with grid approximation:\n\n# Create a grid of 6 pi values\ngrid_data <- tibble(pi_grid = seq(0, 1, length.out = 6)) |> \n  # Evaluate the prior and likelihood at each pi\n  mutate(prior = dbeta(pi_grid, 2, 2),\n         likelihood = dbinom(9, 10, pi_grid)) |> \n  # Approximate the posterior\n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\ngrid_data\n## # A tibble: 6 × 5\n##   pi_grid prior likelihood unnormalized posterior\n##     <dbl> <dbl>      <dbl>        <dbl>     <dbl>\n## 1     0    0    0            0          0        \n## 2     0.2  0.96 0.00000410   0.00000393 0.0000124\n## 3     0.4  1.44 0.00157      0.00226    0.00712  \n## 4     0.6  1.44 0.0403       0.0580     0.183    \n## 5     0.8  0.96 0.268        0.258      0.810    \n## 6     1    0    0            0          0\n\nggplot(grid_data, aes(x = pi_grid, y = posterior)) +\n  geom_point() +\n  geom_segment(aes(xend = pi_grid, yend = 0))\n\n\n\n\nThat’s our discretized posterior, but since there are only 6 values, it’s not great. If we sample from it, the samples will be just 0.6, 0.8, etc.:\n\nposterior_samples <- grid_data |> \n  slice_sample(n = 10000, replace = TRUE, weight_by = posterior)\n\nposterior_samples |> count(pi_grid)\n## # A tibble: 3 × 2\n##   pi_grid     n\n##     <dbl> <int>\n## 1     0.4    56\n## 2     0.6  1809\n## 3     0.8  8135\n\nLet’s compare that to the actual \\(\\operatorname{Beta}(11, 3)\\) posterior:\n\nggplot(posterior_samples, aes(x = pi_grid)) +\n  geom_histogram(aes(y = ..density..), color = \"white\", binwidth = 0.1, boundary = 0) +\n  stat_function(fun = ~dbeta(., 11, 3)) +\n  xlim(c(0, 1))\n\n\n\n\nlol\nHere’s the same grid approximation with 10,000 grid values this time:\n\ngrid_data <- tibble(pi_grid = seq(0, 1, length.out = 10000)) |> \n  mutate(prior = dbeta(pi_grid, 2, 2),\n         likelihood = dbinom(9, 10, pi_grid)) |> \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n\n# Actual approximated posterior\nggplot(grid_data, aes(x = pi_grid, y = posterior)) +\n  geom_line()\n\n\n\n\n# Samples from the posterior\nposterior_samples <- grid_data |> \n  slice_sample(n = 10000, replace = TRUE, weight_by = posterior)\n\nggplot(posterior_samples, aes(x = pi_grid)) +\n  geom_histogram(aes(y = ..density..), color = \"white\", binwidth = 0.01, boundary = 0) +\n  stat_function(fun = ~dbeta(., 11, 3)) +\n  xlim(c(0, 1))\n\n\n\n\n\n\nGamma-Poisson example\n\\[\n\\begin{aligned}\nY_i &\\sim \\operatorname{Poisson}(\\lambda) \\\\\n\\lambda &= \\operatorname{Gamma}(3, 1)\n\\end{aligned}\n\\]\nIf we see Y = 2 and then Y = 8, our true posterior based on conjugate family magic ends up being this:\n\\[\n\\lambda \\mid Y = (2, 8) \\sim \\operatorname{Gamma}(3 + (2 + 8), 1 + 2) \\rightarrow \\operatorname{Gamma}(13, 3)\n\\]\nGrid time:\n\ngrid_data <- tibble(lambda_grid = seq(0, 15, length.out = 501)) |> \n  mutate(prior = dgamma(lambda_grid, 3, 1),\n         likelihood = dpois(2, lambda_grid) * dpois(8, lambda_grid)) |> \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n\n# Actual approximated posterior\nggplot(grid_data, aes(x = lambda_grid, y = posterior)) +\n  geom_line()\n\n\n\n\n# Samples from the posterior\nposterior_samples <- grid_data |> \n  slice_sample(n = 10000, replace = TRUE, weight_by = posterior)\n\nggplot(posterior_samples, aes(x = lambda_grid)) +\n  geom_histogram(aes(y = ..density..), color = \"white\", binwidth = 0.5, boundary = 0) +\n  stat_function(fun = ~dgamma(., 13, 3)) +\n  xlim(c(0, 15))\n\n\n\n\nLovely."
  },
  {
    "objectID": "bayes-rules/06-chapter.html#markov-chains-via-rstan",
    "href": "bayes-rules/06-chapter.html#markov-chains-via-rstan",
    "title": "Reading notes",
    "section": "6.2 Markov chains via rstan",
    "text": "6.2 Markov chains via rstan\nMCMC samples aren’t independent—each value depends on the previous value (hence “chains”). But you only need to know one previous value of \\(\\theta\\) to calculate the next \\(\\theta\\), so there’s no long history or anything. Also, the chain of \\(\\theta\\) values aren’t even simulated from the posterior. But with magical MCMC algorithms, we can approximate the posterior with the values in the chains\n\nBeta-binomaial\nLet’s do this model again, but with Stan instead of with grid approximation:\n\\[\n\\begin{aligned}\nY &\\sim \\operatorname{Binomial}(10, π) \\\\\n\\pi &= \\operatorname{Beta}(2, 2)\n\\end{aligned}\n\\]\n\n\n\n06-stan/bb_sim.stan\n\n// Step 1: Define the model\n// Stuff from R\ndata {\n  int<lower=0, upper=10> Y;\n}\n\n// Thing to estimate\nparameters {\n  real<lower=0, upper=1> pi;\n}\n\n// Prior and likelihood\nmodel {\n  Y ~ binomial(10, pi);\n  pi ~ beta(2, 2);\n}\n\n\n\nbb_sim <- cmdstan_model(\"06-stan/bb_sim.stan\")\n\n\n# Step 2: Simulate the posterior\n# Compiled cmdstan objects are R6 objects with functions embedded in specific\n# slots, which makes it hard to look them up in the documentation. ?CmdStanModel\n# shows an index of all the available methods, like $sample()\nbb_sim_samples <- bb_sim$sample(\n  data = list(Y = 9),\n  parallel_chains = 4, iter_warmup = 2500, iter_sampling = 2500, \n  refresh = 0, seed = BAYES_SEED\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.2 seconds.\n\n\n# cmdstan samples are also R6 objects with embedded functions. $draws() lets you\n# extract the draws as an array\nbb_sim_samples$draws(variables = \"pi\") |> head(4)\n## # A draws_array: 4 iterations, 4 chains, and 1 variables\n## , , variable = pi\n## \n##          chain\n## iteration    1    2    3    4\n##         1 0.89 0.75 0.71 0.87\n##         2 0.94 0.87 0.56 0.82\n##         3 0.88 0.89 0.59 0.82\n##         4 0.89 0.81 0.67 0.76\n\n# Or we can use posterior::as_draws_array to avoid R6\n# as_draws_array(bb_sim_samples)\n\n# Or even better, use tidybayes\nbb_sim_samples |>\n  spread_draws(pi) |> \n  head(4)\n## # A tibble: 4 × 4\n##   .chain .iteration .draw    pi\n##    <int>      <int> <int> <dbl>\n## 1      1          1     1 0.888\n## 2      1          2     2 0.938\n## 3      1          3     3 0.877\n## 4      1          4     4 0.892\n\nThe values in these chains aren’t independent. In chain 1 here, for instance, it starts with 0.89, then plugs that into the next iteration to get 0.94, then plugs that into the next iteration to get 0.88, then plugs that into the next iteration to get 0.89, and so on.\nThe chain explores the sample space, or range of posterior plausible \\(\\pi\\)s. We want them to explore lots of values along their journey, and we can check that by looking at traceplots (to show the history of the chain) and density plots (to show the distribution of values that were visited)\n\nTrace plot, first few iterationsFull trace plot, separateFull trace plot, mixed\n\n\n\n# Look at the first 20, for fun\nbb_sim_samples |>\n  gather_draws(pi) |> \n  filter(.iteration <= 20) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 1) +\n  facet_grid(rows = vars(.variable), cols = vars(.chain)) +\n  labs(color = \"Chain\")\n\n\n\n\n\n\n\nbb_sim_samples |>\n  gather_draws(pi) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.1) +\n  facet_grid(rows = vars(.variable), cols = vars(.chain)) +\n  labs(color = \"Chain\")\n\n\n\n\n\n\n\nbb_sim_samples |>\n  gather_draws(pi) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.1) +\n  labs(color = \"Chain\")\n\n\n\n\n\n\n\nAnd here’s the distribution of the draws, which should be the same as the numeric \\(\\operatorname{Beta}(11, 3)\\) posterior:\n\nbb_sim_samples |>\n  spread_draws(pi) |> \n  ggplot(aes(x = pi)) +\n  stat_density(geom = \"area\", fill = clrs[1]) +\n  stat_function(fun = ~dbeta(., 11, 3), color = clrs[3], size = 1)\n\n\n\n\n\n\nGamma-Poisson\n\\[\n\\begin{aligned}\nY_i &\\sim \\operatorname{Poisson}(\\lambda) \\\\\n\\lambda &= \\operatorname{Gamma}(3, 1)\n\\end{aligned}\n\\]\n\n\n\n06-stan/gp_sim.stan\n\n// Step 1: Define the model\n// Stuff from R\ndata {\n  array[2] int Y;\n}\n\n// Thing to estimate\nparameters {\n  real<lower=0, upper=15> lambda;\n}\n\n// Prior and likelihood\nmodel {\n  Y ~ poisson(lambda);\n  lambda ~ gamma(3, 1);\n}\n\n\n\ngp_sim <- cmdstan_model(\"06-stan/gp_sim.stan\")\n\n\n# Step 2: Simulate the posterior\ngp_sim_samples <- gp_sim$sample(\n  data = list(Y = c(2, 8)),\n  parallel_chains = 4, iter_warmup = 2500, iter_sampling = 2500, \n  refresh = 0, seed = BAYES_SEED\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.2 seconds.\n\nCheck the chains:\n\ngp_sim_samples |>\n  gather_draws(lambda) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.1) +\n  labs(color = \"Chain\")\n\n\n\n\nCompare the distribution with the true \\(\\operatorname{Gamma}(13, 3)\\) posterior:\n\ngp_sim_samples |>\n  spread_draws(lambda) |> \n  ggplot(aes(x = lambda)) +\n  stat_density(geom = \"area\", fill = clrs[2]) +\n  stat_function(fun = ~dgamma(., 13, 3), color = clrs[3], size = 1)"
  },
  {
    "objectID": "bayes-rules/06-chapter.html#markov-chain-diagnostics",
    "href": "bayes-rules/06-chapter.html#markov-chain-diagnostics",
    "title": "Reading notes",
    "section": "6.3: Markov chain diagnostics",
    "text": "6.3: Markov chain diagnostics\n\n6.3.1: Examining trace plots\nTrace plots should look like nothing (“hairy caterpillars”). This indicates that the chains are stable, well-mixed, and converged:\n\ngp_sim_samples |>\n  gather_draws(lambda) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.1) +\n  labs(color = \"Chain\")\n\n\n\n\nWe can also use trace rank plots (trank plots), where we take all the samples for a parameter (\\(\\lambda\\) here), calculate their ranks, and make a histogram of those ranks colored by chain. According to McElreath (p. 284),\n\nIf the chains are exploring the same space efficinetly, the histograms should be similar to one another and largely overlapping.\n\nNeat!\n\ngp_sim_samples |>\n  spread_draws(lambda) |> \n  mutate(draw_rank = rank(lambda)) |> \n  ggplot(aes(x = draw_rank)) +\n  stat_bin(aes(color = factor(.chain)), geom = \"step\", binwidth = 500, \n           position = position_identity(), boundary = 0) + \n  labs(color = \"Chain\") +\n  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n\n\n\n\nHere are some bad traceplots from Figure 6.12 in the book:\n\n\n\n\n\n\n\n\n\nChain A has a noticeable slope, which is a sign that it hasn’t stabilized. It hasn’t found a good range of possible \\(\\pi\\) values. It is mixing slowly.\nChain B gets stuck when exploring smaller values of \\(\\pi\\)\nFix these issues by (1) making sure the model and priors are appropriate, and (2) run the chain for more iterations.\n\n\n6.3.2 Comparing parallel chains\nWe want to see consistency across the four chains. Check with a density plot:\n\ngp_sim_samples |>\n  spread_draws(lambda) |> \n  ggplot(aes(x = lambda, color = factor(.chain))) +\n  geom_density() +\n  labs(color = \"Chain\")\n\n\n\n\n\n\n6.3.3. Effective sample size and autocorrelation\nSince there are so many MCMC draws, it’s tricky to know what the actual sample size is. “How many [truly] independent sample values would it take to produce an equivalently accurate posterior approximation?” That’s what the effective sample size ratio is for:\n\\[\n\\frac{N_\\text{effective}}{N}\n\\]\nThere’s no official rule for this, but it would be bad if a chain had a ratio of less than 0.1, or where the effective sample size is less than 10% of the actual sample size.\nFor both of these models the ratio is 34ish%, which means “our 20,000 Markov chain values are about as useful as only 6800 independent samples (0.34 × 20000).”\n\nbayesplot::neff_ratio(bb_sim_samples)\n##        pi \n## 0.3423651\nbayesplot::neff_ratio(gp_sim_samples)\n##    lambda \n## 0.3456354\n\nThe bayesplot::neff_ratio() uses the ess_basic summary statistic, which Aki Vehtari says is fine here. We can also extract the ESS basic statistic with posterior::ess_basic():\n\nposterior::ess_basic(bb_sim_samples$draws(variables = \"pi\"))\n## [1] 3401.823\n\nHowever, in the documentation for ess_basic(), the Stan team strongly recommends using either ess_bulk or ess_tail, both of which are reported by default in summary() (and also in rstanarm and brms models):\n\nposterior::ess_bulk(bb_sim_samples$draws(variables = \"pi\")) / 10000\n## [1] 0.3114404\nposterior::ess_tail(bb_sim_samples$draws(variables = \"pi\")) / 10000\n## [1] 0.3960722\nbb_sim_samples$summary() |> \n  select(variable, mean, median, ess_bulk, ess_tail)\n## # A tibble: 2 × 5\n##   variable   mean median ess_bulk ess_tail\n##   <chr>     <dbl>  <dbl>    <dbl>    <dbl>\n## 1 lp__     -7.80  -7.52     4526.    4831.\n## 2 pi        0.785  0.800    3140.    3991.\n\nWe can also look at autocorrelation. There’s inherently some degree of autocorrelation, since each draw depends on the previous one, but we still want draws to bounce around and to not be too correlated after a few lagged periods.\nWe can check this with an autocorrelation plot. This shows the correlation between an MCMC draw and the one before it at different lags. When the lag is 0, there’s perfect correlation (since it’s the correlation between the draw and itself). At lag 1, there’s a correlation of 0.5 between a draw and its previous value, and it drops off to near 0 by the time we get to 5 lags. That’s good.\n\n[T]here’s very little correlation between Markov chain values that are more than a few steps apart. This is all good news. It’s more confirmation that our Markov chain is mixing quickly, i.e., quickly moving around the range of posterior plausible π values, and thus at least mimicking an independent sample.\n\n\n# Boring bayesplot way\n# mcmc_acf(bb_sim_samples$draws(variables = \"pi\"))\n\nautocor_manual <- bb_sim_samples |>\n  spread_draws(pi) |> \n  group_by(.chain) |> \n  nest() |> \n  summarize(autocor = map(data, ~{\n    x <- acf(.$pi, plot = FALSE, lag.max = 20)\n    tibble(lag = x$lag, acf = x$acf)\n  })) |>\n  unnest(autocor)\n\nggplot(autocor_manual, aes(x = lag, y = acf, color = factor(.chain))) +\n  geom_line() +\n  scale_x_continuous(breaks = 0:20) +\n  labs(x = \"Lag\", y = \"Autocorrelation\", color = \"Chain\") +\n  theme(panel.grid.minor = element_blank())\n\n\n\n\nFinally, we can look at \\(\\hat{R}\\) or R-hat. R-hat looks at the consistency of values across chains:\n\nR-hat addresses this consistency by comparing the variability in sampled π values across all chains combined to the variability within each individual chain\n\n\\[\n\\hat{R} \\approx \\sqrt{\\frac{\\operatorname{Variability}_\\text{combined}}{\\operatorname{Variability}_\\text{within}}}\n\\]\nWe want R-hat to be 1. When R-hat > 1, it means there’s instability across chains, and more specifically that “the variability in the combined chains exceeds that within the chains. R-hat > 1.05 is bad (and the Stan people have recently considered thinking about 1.01 as a possible warning sign, and proposed alternative mixing statistics, like R*).\nBasically we want the variability across the chains to look just like the variability within the chains so that it’s impossible to distinguish between them in a trace plot. Can you see any rogue chains here? Nope. We’re good.\n\nrhat_basic(bb_sim_samples$draws(variables = \"pi\"))\n## [1] 1.000178\n\n\nbb_sim_samples |>\n  gather_draws(pi) |> \n  ggplot(aes(x = .iteration, y = .value, group = .chain)) +\n  geom_line(size = 0.1) +\n  labs(color = \"Chain\")"
  },
  {
    "objectID": "bayes-rules/07-chapter.html",
    "href": "bayes-rules/07-chapter.html",
    "title": "Reading notes",
    "section": "",
    "text": "(Original chapter)"
  },
  {
    "objectID": "bayes-rules/07-chapter.html#the-big-idea",
    "href": "bayes-rules/07-chapter.html#the-big-idea",
    "title": "Reading notes",
    "section": "7.1: The Big Idea",
    "text": "7.1: The Big Idea\n(SO EXCITED FOR THIS)\nStan uses Hamiltonian Monte Carlo sampling; JAGS uses Gibbs sampling. Both of these are enhanced versions of the fundamental Metropolis-Hastings algorithm for sampling, which we’ll implement here (yay!)\nThink of Markov chains as a tour around the range of posterior possible values of a parameter (like µ or π or whatever). The chains move around that parameter and hopefully converge around it, but the chains need a tour manager to do that properly.\nTrace plots show the tour route; density plots show the relative amount of time spent at each stop or parameter region during the tour.\nThe tour manager’s goal is “to ensure that the density of tour stops in each μ region is proportional to its posterior plausibility”\nWe can automate the tour managing process with an algorithm, like the Metropolis-Hastings algorithm, which consists of two steps.\nAssume the Markov chain is at location \\(\\mu^{(i)}\\) currently. In order to choose the next tour stop, or \\(\\mu^{(i + 1)}\\), follow this process:\n\nPropose a random location for the next tour stop: \\(\\mu^\\prime\\)\nDecide whether to go to \\(\\mu^\\prime\\) or stay at the current location \\(\\mu^{(i)}\\) for another iteration\n\nThat’s it. This simplified special version of Metropolis-Hastings is called the Monte Carlo algorithm.\nHere’s how to implement it. Assume we have a posterior (calculated with magical conjugate prior families) like this:\n\\[\n\\mu \\sim \\mathcal{N}(4, 0.6^2)\n\\]\nWe can draw random values from that distribution and tour it:\n\nmc_tour <- tibble(\n  mu = rnorm(5000, mean = 4, sd = 0.6)\n) |> \n  mutate(.iteration = 1:n())\n\n# Trace plot\nmc_tour |> \n  ggplot(aes(x = .iteration, y = mu)) +\n  geom_line(size = 0.1, alpha = 0.75)\n\n\n\n\n# Density plot\nmc_tour |> \n  ggplot(aes(x = mu)) +\n  geom_histogram(aes(y = ..density..),binwidth = 0.25, \n                  color = \"white\", fill = clrs[2]) +\n  geom_function(fun = ~dnorm(., 4, 0.6), color = clrs[3])\n\n\n\n\nNeat! The trace plot shows that the tour was stable and had good coverage; the density plot shows that most of the time was spent around 4.\nBut this Monte Carlo algorithm is way too easy. We already know the posterior here! MCMC is great for approximating the posterior when math is too hard; if we can get the posterior through conjugate magic, there’s no need to then randomly sample and tour the posterior.\nSo what do we do if we don’t know the true posterior? We do know some of the posterior—the whole point of Bayes’ rule is that the posterior is proportional to the prior and the likelihood:\n\\[\n\\begin{aligned}\n\\text{Posterior} &\\propto \\text{Prior} \\times \\text{Likelihood} \\\\\nf(\\mu \\mid y = 6.25) &\\propto f(\\mu) \\times L(\\mu \\mid y = 6.25)\n\\end{aligned}\n\\]\n\nplot_data <- tibble(mu = seq(1, 7, length.out = 101)) |> \n  mutate(likelihood = dnorm(6.25, mean = mu, sd = 0.75),\n         prior = dnorm(mu, 0, 1)) |> \n  mutate(unnormalized = likelihood * prior)\n\nggplot(plot_data, aes(x = mu, y = unnormalized)) + \n  geom_area(fill = clrs[1]) +\n  labs(x = \"µ\", y = NULL,\n       title = \"Unnormalized posterior distribution\",\n       subtitle = \"Prior × L(µ | y = 6.25)\")\n\n\n\n\nThis distribution isn’t quite correct—it’s not scaled correctly—but it does “preserve the shape, central tendency, and variability of the actual posterior”. So we know something about the posterior that we can work with, and that can influence the sampling procedure.\nMetropolis-Hastings also does another neat thing. Instead of just choosing a new stop at random, it uses a proposal model to propose possible stops. There are lots of possible proposal models—in Bayes Rules they use a uniform proposal model with a half-width parameter \\(w\\) that adds a window, or range, or neighborhood around the current µ location in the chain, or the current stop.\nSo if we’re currently at \\(\\mu^{(i)}\\), the proposal for the next stop will be drawn from a window of \\(\\mu^{(i)} \\pm w\\), or more formally:\n\\[\n\\mu^\\prime \\sim \\operatorname{Uniform}(\\mu^{(i)} - w, \\mu^{(i)} + w)\n\\]\nIf we’re currently at \\(\\mu = 3\\), for instance, and we’re using a half-width \\(w\\) of 1, the proposal for the next draw will come from runif(n = 1, min = 2, max = 4):\n\nggplot(plot_data, aes(x = mu, y = unnormalized)) + \n  geom_area(fill = clrs[1]) +\n  labs(x = \"µ\", y = NULL,\n       title = \"Unnormalized posterior distribution\",\n       subtitle = \"Prior × L(µ | y = 6.25)\") +\n  scale_x_continuous(breaks = 1:7) +\n  annotate(geom = \"segment\", x = 2, xend = 4, y = 2e-7, yend = 2e-7) + \n  annotate(geom = \"segment\", x = 3, xend = 3, y = 2e-7, yend = 0, linetype = \"21\")\n\n\n\n\nThe second step in the algorithm then decides if the proposal should be accepted or rejected. If the proposed \\(\\mu^\\prime\\) is bad, the chain will hang out for a round before making another proposal, checking if it’s good, and then maybe moving on.\nIf we’re currently at 3 and we draw from \\(\\operatorname{Uniform}(2, 4)\\) and get a 3.8, is that good? Yeah. That fits nicely in the unnormalized posterior distribution, so we should go there. If the uniform distribution proposes a 2, that’s probably not great—that’s really rare."
  },
  {
    "objectID": "bayes-rules/07-chapter.html#the-metropolis-hastings-algorithm",
    "href": "bayes-rules/07-chapter.html#the-metropolis-hastings-algorithm",
    "title": "Reading notes",
    "section": "7.2: The Metropolis-Hastings algorithm",
    "text": "7.2: The Metropolis-Hastings algorithm\nSo in general, Metropolis-Hastings does this:\n\nPropose a random location for the next tour stop, \\(\\mu^\\prime\\), by drawing it from a proposal model\nDecide whether to go to \\(\\mu^\\prime\\) or stay at the current location \\(\\mu^{(i)}\\) for another iteration, based on this process:\n\n\nIf the unnormalized posterior plausibility of \\(\\mu^\\prime > \\mu^{(i)}\\), then definitely go there\nOtherwise maybe go there\n\nThat “maybe go there” part is determined based on an acceptance probability \\(\\alpha\\). It’s like a weighted coin flip—if it’s heads, which has probability \\(\\alpha\\), go there; if it’s tails, which has probability \\(1 - \\alpha\\), stay:\n\\[\n\\mu^{(i+1)} =\n\\begin{cases}\n\\mu^\\prime & \\text{ with probability } \\alpha \\\\\n\\mu & \\text{ with probability } 1 - \\alpha\n\\end{cases}\n\\]\nFormally, the weightedness of this coin flip (or the acceptance model in general) comes from the Metropolis algorithm, which has a symmetric proposal model. It looks like this:\n\\[\n\\alpha = \\min\\left\\lbrace 1, \\; \\frac{f(\\mu^\\prime)\\ L(\\mu^\\prime \\mid y)}{f(\\mu)\\ L(\\mu \\mid y)} \\right\\rbrace\n\\]\nOof that’s a mess. Through some algebra (dividing the numerator and denominator by \\(f(y)\\)), we get this:\n\\[\n\\alpha = \\min\\left\\lbrace 1, \\; \\frac{f(\\mu^\\prime)\\ L(\\mu^\\prime \\mid y)\\ /\\ f(y)}{f(\\mu)\\ L(\\mu \\mid y)\\ /\\ f(y)} \\right\\rbrace = \\min\\left\\lbrace 1, \\; \\frac{f(\\mu^\\prime \\mid y)}{f(\\mu \\mid y)} \\right\\rbrace\n\\]\nThe key part is \\(f(\\mu^\\prime \\mid y)\\) and \\(f(\\mu \\mid y)\\), or how well \\(\\mu\\) and \\(\\mu^\\prime\\) fit in the unnormalized posterior. We look at the ratio of their plausibilities:\n\\[\n\\frac{\\text{Plausibility of proposed } \\mu^\\prime \\text{ in unnormalized posterior}}{\\text{Plausibility of current } \\mu \\text{ in unnormalized posterior}}\n\\]\nThere are two possible outcomes with this ratio:\n\nIf the plausibility of the proposed draw is ≥ the current draw (\\(f(\\mu^\\prime \\mid y) \\geq f(\\mu \\mid y)\\)), \\(\\alpha\\) will be 1, since the ratio will be > 1 (like 0.5 / 0.3 would be 1.666; 4 / 3.9 would be 1.02; and so on). The decision rule says to take the minimum of 1 and the plausibility ratio, so here the minimum is 1 and so \\(\\alpha\\) is 1. This is the “Definitely go there” part of the algorithm.\nIf the plausibility of the proposed draw is < the current draw (\\(f(\\mu^\\prime \\mid y) \\lt f(\\mu \\mid y)\\)), then the ratio will be less than 1 (like 0.3 / 0.5 would be 0.6; 3.9 / 4 would be 0.975; and so on), so \\(\\alpha\\) would be that ratio and not 1 (again, we’re taking the minimum of the two). That ratio then becomes our probability of going to the new draw. The closer the proposed plausibility is to the current plausibility, the higher the chances of visiting there. This is the “Maybe go there” part of the algorithm.\n\nWe can write this algorithm with code:\n\none_mh_iteration <- function(w, current) {\n  # Step 1\n  # Propose the next mu by choosing a value from a uniform distribution with a\n  # window of ±w around the current mu\n  proposal <- runif(1, min = current - w, max = current + w)\n  \n  # Step 2\n  # Decide whether or not to go there\n  # The plausibility is the prior * likelihood\n  proposal_plausibility <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)\n  current_plausibility <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)\n  \n  # Calculate the alpha, taking the minimum of 1 or the ratio of plausiblities\n  alpha <- min(1, proposal_plausibility / current_plausibility)\n  \n  # Determine the next stop based on the alpha\n  next_stop <- sample(c(proposal, current), size = 1, prob = c(alpha, 1 - alpha))\n  \n  return(tibble(proposal, alpha, next_stop))\n}\n\nSo if we’re currently at 3, let’s figure out a next stop with a window of ±1:\n\nset.seed(8)\none_mh_iteration(w = 1, current = 3)\n## # A tibble: 1 × 3\n##   proposal alpha next_stop\n##      <dbl> <dbl>     <dbl>\n## 1     2.93 0.824      2.93\n\nThis iteration proposes going to 2.93. The ratio of plausibilities is less than one here, so we get an alpha of 0.82. The probability of deciding to move from 3 to 2.93 is thus also 0.82. In this case, we accept the proposal and decide to move on, so the next stop is 2.93.\nIn this case, if we’re at 3 and we get a proposal of 2.018, the ratio is really small (0.02), so the probability when deciding to “maybe move on” is tiny. We end up staying at 3.\n\nset.seed(83)\none_mh_iteration(w = 1, current = 3)\n## # A tibble: 1 × 3\n##   proposal  alpha next_stop\n##      <dbl>  <dbl>     <dbl>\n## 1     2.02 0.0171         3"
  },
  {
    "objectID": "bayes-rules/07-chapter.html#implementing-the-metropolis-hastings-algorithm",
    "href": "bayes-rules/07-chapter.html#implementing-the-metropolis-hastings-algorithm",
    "title": "Reading notes",
    "section": "7.3: Implementing the Metropolis-Hastings algorithm",
    "text": "7.3: Implementing the Metropolis-Hastings algorithm\nThat’s the hard part! The rest involves just looping through a bunch of values. We’ll do that with a function:\n\nmh_tour <- function(start = 3, N, w) {\n  # Step 1\n  # Start the chain at some location\n  current <- start\n  \n  # Step 2\n  # Create an empty vector with enough slots to hold all these draws\n  mu <- rep(0, N)\n  \n  # Step 3\n  # Markov chain time\n  for (i in 1:N) {\n    # Do one iteration\n    where_next <- one_mh_iteration(w = w, current = current)\n    \n    # Save this in the vector\n    mu[i] <- where_next$next_stop\n    \n    # Tell the algorithm where we are now\n    current <- where_next$next_stop\n  }\n  \n  # Step 4\n  # Return all the chain values\n  # (use tidybayes name conventions)\n  return(tibble(.iteration = c(1:N), mu))\n}\n\nHere we go! Let’s make a chain with 5000 values with a uniform proposal model with a window \\(w\\) of ±1:\n\nset.seed(84735)\ntour_1 <- mh_tour(start = 3, N = 5000, w = 1)\n\n# Trace plot\ntour_1 |> \n  ggplot(aes(x = .iteration, y = mu)) +\n  geom_line(size = 0.1, alpha = 0.75)\n\n\n\n\n# Density plot\ntour_1 |> \n  ggplot(aes(x = mu)) +\n  geom_histogram(aes(y = ..density..),binwidth = 0.25, \n                  color = \"white\", fill = clrs[2]) +\n  geom_function(fun = ~dnorm(., 4, 0.6), color = clrs[3])\n\n\n\n\nAHHHHHHH THAT’S AWESOME!!!!!!!!!11!!1!1!!\n\nFun times with parallel chains\nFor bonus fun and excitement, I’ll do four parallel chains with 4 random starting values drawn from \\(\\operatorname{Uniform}(0, 10)\\) (because why not)\n\nlibrary(furrr)\nplan(multisession, workers = 4)\n\nset.seed(123)\nfour_tours <- tibble(.chain = 1:4) |> \n  mutate(start = runif(n(), 0, 10)) |> \n  mutate(tour = future_map(start, ~mh_tour(start = ., N = 5000, w = 1),\n                           .options = furrr_options(seed = TRUE)))\nfour_tours\n## # A tibble: 4 × 3\n##   .chain start tour                \n##    <int> <dbl> <list>              \n## 1      1  2.88 <tibble [5,000 × 2]>\n## 2      2  7.88 <tibble [5,000 × 2]>\n## 3      3  4.09 <tibble [5,000 × 2]>\n## 4      4  8.83 <tibble [5,000 × 2]>\n\nLOOK AT THIS TRACE PLOT\n\nfour_tours |> \n  unnest(tour) |> \n  filter(.chain < 2500) |> \n  ggplot(aes(x = .iteration, y = mu, color = factor(.chain))) +\n  geom_line(size = 0.1, alpha = 0.75) +\n  labs(color = \"Chain\")\n\n\n\n\nLOOK AT THIS TRANK PLOT\n\nfour_tours |> \n  unnest(tour) |> \n  mutate(draw_rank = rank(mu)) |> \n  ggplot(aes(x = draw_rank)) +\n  stat_bin(aes(color = factor(.chain)), geom = \"step\", binwidth = 500,\n           position = position_identity(), boundary = 0) +\n  labs(color = \"Chain\") +\n  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n\n\n\n\nLOOK AT THE DENSITIES ACROSS CHAINS\n\n# Density plot\nfour_tours |> \n  unnest(tour) |> \n  ggplot(aes(x = mu, color = factor(.chain))) +\n  geom_density() +\n  labs(color = \"Chain\")\n\n\n\n\nThis even works with posterior functions like ess_basic. Our effective sample size ratio isn’t that great—our 20,000 Markov chain values are as useful as only 2,400 independent samples(0.12 × 20000).\n\nposterior_mu <- four_tours |> unnest(tour) |> pull(mu)\nposterior::ess_basic(posterior_mu)\n## [1] 2379.859\n\n# neff_ratio\nposterior::ess_basic(posterior_mu) / 20000\n## [1] 0.118993\n\nAnd we can look at autocorrelation, which isn’t great. It takes a while for the chains to settle and the chains have a longer memory—we don’t hit 0ish correlation until 13 lags!\n\nautocor_manual <- four_tours |> \n  unnest(tour) |> \n  group_by(.chain) |> \n  nest() |> \n  summarize(autocor = map(data, ~{\n    x <- acf(.$mu, plot = FALSE, lag.max = 20)\n    tibble(lag = x$lag, acf = x$acf)\n  })) |>\n  unnest(autocor)\n\nggplot(autocor_manual, aes(x = lag, y = acf, color = factor(.chain))) +\n  geom_line() +\n  scale_x_continuous(breaks = 0:20) +\n  labs(x = \"Lag\", y = \"Autocorrelation\", color = \"Chain\") +\n  theme(panel.grid.minor = element_blank())\n\n\n\n\nFinally, here’s the overall simulated posterior, after throwing away the first 2,500 draws in each chain as warmups (just like we do with Stan):\n\nfour_tours |> \n  unnest(tour) |> \n  filter(.iteration > 2500) |> \n  ggplot(aes(x = mu)) +\n  geom_density(aes(fill = \"Simulated posterior\"), color = FALSE) +\n  geom_function(fun = ~dnorm(., 4, 0.6), aes(color = \"True posterior\")) +\n  scale_fill_manual(values = c(clrs[2]), name = NULL) +\n  scale_color_manual(values = c(clrs[3]), name = NULL)\n\n\n\n\nSO SO COOL!"
  },
  {
    "objectID": "bayes-rules/07-chapter.html#tuning-the-metropolis-hastings-algorithm",
    "href": "bayes-rules/07-chapter.html#tuning-the-metropolis-hastings-algorithm",
    "title": "Reading notes",
    "section": "7.4: Tuning the Metropolis-Hastings algorithm",
    "text": "7.4: Tuning the Metropolis-Hastings algorithm\nPhew. One final wrinkle to play with. We arbitrarily set \\(w = 1\\) here for the window, which defines how wide the neighborhood of possible proposals is. That \\(w\\) term matters a lot—too wide and we’ll bounce around way too much and never settle; too narrow and we’ll get stuck around the initial value.\nThis \\(w\\) is equivalent to the step size.\n\nset.seed(7)\nsim_too_wide <- mh_tour(N = 5000, w = 100)\n\nset.seed(84735)\nsim_too_narrow <- mh_tour(N = 5000, w = 0.01)\n\ntoo_wide <- ggplot(sim_too_wide, aes(x = .iteration, y = mu)) + \n  geom_line(color = clrs[4]) + \n  geom_hline(yintercept = 4, color = clrs[2], linetype = \"dotted\") +\n  ylim(c(1.6, 6.4)) +\n  labs(title = \"w too wide\")\n\ntoo_narrow <- ggplot(sim_too_narrow, aes(x = .iteration, y = mu)) + \n  geom_line(color = clrs[5]) + \n  geom_hline(yintercept = 4, color = clrs[2], linetype = \"dotted\") +\n  ylim(c(1.6, 6.4)) +\n  labs(title = \"w too narrow\")\n\ntoo_narrow | too_wide"
  },
  {
    "objectID": "bayes-rules/08-chapter.html",
    "href": "bayes-rules/08-chapter.html",
    "title": "Reading notes",
    "section": "",
    "text": "(Original chapter)"
  },
  {
    "objectID": "bayes-rules/08-chapter.html#the-general-setup",
    "href": "bayes-rules/08-chapter.html#the-general-setup",
    "title": "Reading notes",
    "section": "The general setup",
    "text": "The general setup\nWe want to know the probability that an artist in the MoMA is Gen X or younger (born after 1965). This is our \\(\\pi\\).\nWe’ll use a vague \\(\\operatorname{Beta}(4, 6)\\) prior for \\(\\pi\\) and say that the probability is probably below 0.5, but we’re not super sure where it is exactly:\n\nggplot() +\n  stat_function(fun = ~dbeta(., 4, 6), geom = \"area\", fill = clrs[1])\n\n\n\n\nHere’s the data:\n\ndata(\"moma_sample\", package = \"bayesrules\")\nhead(moma_sample)\n##                artist  country birth death alive  genx gender count\n## 1        Ad Gerritsen    dutch  1940  2015 FALSE FALSE   male     1\n## 2 Kirstine Roepstorff   danish  1972  <NA>  TRUE  TRUE female     3\n## 3    Lisa Baumgardner american  1958  2015 FALSE FALSE female     2\n## 4         David Bates american  1952  <NA>  TRUE FALSE   male     1\n## 5          Simon Levy american  1946  <NA>  TRUE FALSE   male     1\n## 6      Pierre Mercure canadian  1927  1966 FALSE FALSE   male     8\n##   year_acquired_min year_acquired_max\n## 1              1981              1981\n## 2              2005              2005\n## 3              2016              2016\n## 4              2001              2001\n## 5              2012              2012\n## 6              2008              2008\n\nOnly 14 are Gen X:\n\nmoma_sample |> \n  count(genx)\n##    genx  n\n## 1 FALSE 86\n## 2  TRUE 14\n\nThrough the magic of conjugate families, we can calculate the exact posterior:\n\\[\n\\begin{aligned}\nY &\\sim \\operatorname{Binomial}(100, \\pi) \\\\\n\\pi &= \\operatorname{Beta}(4, 6)\n\\end{aligned}\n\\]\nSince we observe \\(Y = 14\\), then the actual exact posterior is\n\\[\n\\pi \\mid (Y = 14) \\sim \\operatorname{Beta}(4 + 14, 6 + 100 - 14) \\rightarrow \\operatorname{Beta}(18, 92)\n\\]\n\nggplot() +\n  stat_function(aes(fill = \"Prior: Beta(4, 6)\"),\n                fun = ~dbeta(., 4, 6), geom = \"area\") +\n  stat_function(aes(fill = \"Posterior: Beta(18, 92)\"),\n                fun = ~dbeta(., 18, 92), geom = \"area\") +\n  scale_fill_manual(values = c(clrs[2], clrs[1]))\n\n\n\n\nNeat! We have a posterior, but now we have to do something with it:\n\nEstimation\nHypothesis testing\nPrediction\n\nBut first, for fun, here are some MCMC-based approximations of the posterior:\n\nbrmsStan\n\n\n\nmodel_pi_brms <- brm(\n  bf(num_genx | trials(artworks) ~ 0 + Intercept),\n  data = list(num_genx = 14, artworks = 100),\n  family = binomial(link = \"identity\"),\n  prior(beta(4, 6), class = b, lb = 0, ub = 1),\n  sample_prior = TRUE,  # For calculating Bayes Ratios\n  iter = 5000, warmup = 1000, seed = BAYES_SEED,\n  backend = \"cmdstanr\", cores = 4, refresh = 0\n)\n## Start sampling\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.1 seconds.\n## Chain 2 finished in 0.1 seconds.\n## Chain 3 finished in 0.1 seconds.\n## Chain 4 finished in 0.1 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.1 seconds.\n## Total execution time: 0.2 seconds.\n\nmodel_pi_brms_prior_only <- brm(\n  bf(num_genx | trials(artworks) ~ 0 + Intercept),\n  data = list(num_genx = 14, artworks = 100),\n  family = binomial(link = \"identity\"),\n  prior(beta(4, 6), class = b, lb = 0, ub = 1),\n  sample_prior = \"only\",  # For calculating Bayes Ratios\n  iter = 5000, warmup = 1000, seed = BAYES_SEED,\n  backend = \"cmdstanr\", cores = 4, refresh = 0\n)\n## Start sampling\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.1 seconds.\n\n\nmodel_pi_brms\n##  Family: binomial \n##   Links: mu = identity \n## Formula: num_genx | trials(artworks) ~ 0 + Intercept \n##    Data: list(num_genx = 14, artworks = 100) (Number of observations: 1) \n##   Draws: 4 chains, each with iter = 5000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 16000\n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept     0.16      0.03     0.10     0.24 1.00     6534     6657\n## \n## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\n\n\n08-stan/genx.stan\n\n// Things coming in from R\ndata {\n  int<lower=0> artworks;\n  int<lower=0> num_genx;\n}\n\n// Thing to estimate\nparameters {\n  real<lower=0, upper=1> pi;  // Proportion of Gen X artists\n}\n\n// Prior and likelihood\nmodel {\n  // Prior\n  pi ~ beta(4, 6);\n  \n  // Likelihood\n  num_genx ~ binomial(artworks, pi);\n}\n\n\n\nmodel_pi_stan <- cmdstan_model(\"08-stan/genx.stan\")\n\n\npi_stan_samples <- model_pi_stan$sample(\n  data = list(artworks = 100, num_genx = 14),\n  parallel_chains = 4, iter_warmup = 2500, iter_sampling = 2500, \n  refresh = 0, seed = BAYES_SEED\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.2 seconds."
  },
  {
    "objectID": "bayes-rules/08-chapter.html#posterior-estimation",
    "href": "bayes-rules/08-chapter.html#posterior-estimation",
    "title": "Reading notes",
    "section": "8.1: Posterior estimation",
    "text": "8.1: Posterior estimation\nOur posterior \\(\\operatorname{Beta}(18, 92)\\) is a complete distribution, but we often need to work with summaries of that distribution. The mean here is 16% (\\(\\frac{18}{18 + 92} = 0.1636\\)), meaning that it is most likely the case that 16% of MoMA artists are Gen X or younger, but it could be anywhere between 10-25ish%\nWe can calculate a 95% credible interval around the median using quantiles:\n\nqbeta(c(0.025, 0.975), 18, 92)\n## [1] 0.1009084 0.2379286\n\nThere’s a 95% posterior probability that somewhere between 10% and 24% of museum artists are Gen X or younger:\n\npost_mean <- 18 / (18 + 92)\npost_median <- qbeta(0.5, 18, 92)\npost_mode <- (18 - 1)/(18 + 92 - 2)\n\nggplot() +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\",\n                fill = colorspace::lighten(clrs[3], 0.4)) +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\", \n                xlim = qbeta(c(0.025, 0.975), 18, 92),\n                fill = clrs[3]) +\n  geom_vline(xintercept = post_mode) +\n  xlim(c(0, 0.4)) +\n  labs(x = \"π\")\n\n\n\n\nWe don’t have to use 95%; that’s just arbitrary. We can use different levels:\n\nggplot() +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\",\n                fill = colorspace::lighten(clrs[3], 0.9)) +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\", \n                xlim = qbeta(c(0.025, 0.975), 18, 92),\n                aes(fill = \"95%\")) +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\", \n                xlim = qbeta(c(0.055, 0.945), 18, 92),\n                aes(fill = \"89%\")) +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\", \n                xlim = qbeta(c(0.1, 0.9), 18, 92),\n                aes(fill = \"80%\")) +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\", \n                xlim = qbeta(c(0.25, 0.75), 18, 92),\n                aes(fill = \"50%\")) +\n  geom_vline(xintercept = post_mode) +\n  scale_fill_manual(values = colorspace::lighten(clrs[3], c(0.1, 0.3, 0.5, 0.7))) +\n  xlim(c(0, 0.4)) +\n  labs(x = \"π\", fill = \"Credible interval\")\n\n\n\n\nThis posterior is a little lopsided, so we might want to make an interval that’s not centered at the mode of π, but instead centered at the highest posterior density.\n\nbrmsStan\n\n\n\nmodel_pi_brms |> \n  spread_draws(b_Intercept) |> \n  median_hdci(b_Intercept, .width = c(0.5, 0.89, 0.95))\n## # A tibble: 3 × 6\n##   b_Intercept .lower .upper .width .point .interval\n##         <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1       0.162 0.138   0.184   0.5  median hdci     \n## 2       0.162 0.106   0.215   0.89 median hdci     \n## 3       0.162 0.0944  0.230   0.95 median hdci\n\n\nmodel_pi_brms |> \n  spread_draws(b_Intercept) |> \n  ggplot(aes(x = b_Intercept)) +\n  stat_slab(aes(fill_ramp = stat(level)),\n            .width = c(0.02, 0.5, 0.89, 0.95, 1),\n            point_interval = \"median_hdci\",\n            fill = clrs[3]) +\n  scale_fill_ramp_discrete(range = c(0.2, 1)) +\n  labs(fill_ramp = \"Credible interval\")\n\n\n\n\n\n\n\npi_stan_samples |> \n  spread_draws(pi) |> \n  median_hdci(pi, .width = c(0.5, 0.89, 0.95))\n## # A tibble: 3 × 6\n##      pi .lower .upper .width .point .interval\n##   <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 0.161 0.137   0.182   0.5  median hdci     \n## 2 0.161 0.108   0.217   0.89 median hdci     \n## 3 0.161 0.0987  0.234   0.95 median hdci\n\n\npi_stan_samples |> \n  spread_draws(pi) |> \n  ggplot(aes(x = pi)) +\n  stat_slab(aes(fill_ramp = stat(level)),\n            .width = c(0.02, 0.5, 0.89, 0.95, 1),\n            point_interval = \"median_hdci\",\n            fill = clrs[3]) +\n  scale_fill_ramp_discrete(range = c(0.2, 1)) +\n  labs(fill_ramp = \"Credible interval\")"
  },
  {
    "objectID": "bayes-rules/08-chapter.html#posterior-hypothesis-testing",
    "href": "bayes-rules/08-chapter.html#posterior-hypothesis-testing",
    "title": "Reading notes",
    "section": "8.2: Posterior hypothesis testing",
    "text": "8.2: Posterior hypothesis testing\nWhat if we read somewhere that fewer than 20% of museum artists are Gen X or younger? We can calculate the posterior probability of this scenario, or \\(P(\\pi < 0.2 \\mid Y = 14)\\)\nWith the exact posterior, that’s super easy:\n\npost_prob <- pbeta(0.2, 18, 92)\npost_prob\n## [1] 0.8489856\n\nggplot() +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\",\n                fill = colorspace::lighten(clrs[3], 0.4)) +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\", \n                xlim = c(0, 0.2),\n                fill = clrs[3]) +\n  geom_vline(xintercept = 0.2) +\n  xlim(c(0, 0.4)) +\n  labs(x = \"π\")\n\n\n\n\n85% of the distribution is below 0.2, so we can say there’s an 85% chance that Gen X artists constitute 20% or fewer of modern art museum artists.\nThat’s easy!\nHere it is with MCMC:\n\nbrmsStan\n\n\n\nmodel_pi_brms |> \n  spread_draws(b_Intercept) |> \n  count(b_Intercept < 0.2) |> \n  mutate(prob = n / sum(n))\n## # A tibble: 2 × 3\n##   `b_Intercept < 0.2`     n  prob\n##   <lgl>               <int> <dbl>\n## 1 FALSE                2332 0.146\n## 2 TRUE                13668 0.854\n\nmodel_pi_brms |> \n  spread_draws(b_Intercept) |> \n  ggplot(aes(x = b_Intercept)) +\n  stat_halfeye(aes(fill_ramp = stat(x < 0.2)), fill = clrs[3]) +\n  scale_fill_ramp_discrete(from = colorspace::lighten(clrs[3], 0.4), guide = \"none\")\n\n\n\n\n\n\n\npi_stan_samples |> \n  spread_draws(pi) |> \n  count(pi < 0.2) |> \n  mutate(prob = n / sum(n))\n## # A tibble: 2 × 3\n##   `pi < 0.2`     n  prob\n##   <lgl>      <int> <dbl>\n## 1 FALSE       1445 0.144\n## 2 TRUE        8555 0.856\n\npi_stan_samples |> \n  spread_draws(pi) |> \n  ggplot(aes(x = pi)) +\n  stat_halfeye(aes(fill_ramp = stat(x < 0.2)), fill = clrs[3]) +\n  scale_fill_ramp_discrete(from = colorspace::lighten(clrs[3], 0.4), guide = \"none\")\n\n\n\n\n\n\n\n\nOne-sided tests (probability of direction)\nWe can also use a hypothesis testing framework and present two competing hypotheses:\n\\[\n\\begin{split}\nH_0: & \\; \\; \\pi \\ge 0.2 \\\\\nH_a: & \\; \\; \\pi < 0.2\n\\end{split}\n\\]\nWe already know the probability of \\(H_a\\) (0.849), so the probability of \\(H_0\\) is 1 minus that, or 0.151. The posterior odds is the ratio of those two probabilities\n\\[\n\\text{posterior odds} = \\frac{P(H_a \\mid Y = 14)}{P(H_0 \\mid Y = 14)} = \\frac{0.849}{0.151} \\approx 5.622\n\\]\n\npost_odds <- post_prob / (1 - post_prob)\npost_odds\n## [1] 5.621883\n\nThat means that π is ≈6 times more likely to be below 20% than to be above 20%\nThat’s all based on the posterior though. Back before we knew anything, we had a prior of \\(\\operatorname{Beta}(6, 4)\\), an in that world, we had a 9% chance that it was true and a 91% chance that it was all false\n\nprior_prob <- pbeta(0.2, 4, 6)\nprior_prob\n## [1] 0.08564173\n1 - prior_prob\n## [1] 0.9143583\n\nSo the prior odds were only 1 in 10:\n\nprior_odds <- prior_prob / (1 - prior_prob)\nprior_odds\n## [1] 0.09366321\n\nFinally, we can do something more useful with these prior and posterior odds and calculate the Bayes Factor, which is just their ratio:\n\\[\n\\text{Bayes Factor} = \\frac{\\text{Posterior odds}}{\\text{Prior odds}}\n\\]\n\nBF <- post_odds / prior_odds\nBF\n## [1] 60.02232\n\nAfter learning about 14 Gen X artists, “the posterior odds of our hypothesis … are roughly 60 times higher than the prior odds”, which is “fairly convincing”\nNo significance testing, no failing to reject nulls. Just vibes.\nEvid.Ratio here is the posterior probability of the hypothesis being true / posterior probability of the hypothesis not being true, or the same as post_odds above.\n\nh <- hypothesis(model_pi_brms, \"Intercept < 0.2\")\nh\n## Hypothesis Tests for class b:\n##              Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n## 1 (Intercept)-(0.2) < 0    -0.04      0.03    -0.09     0.02       5.86\n##   Post.Prob Star\n## 1      0.85     \n## ---\n## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n## '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n## for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n## Posterior probabilities of point hypotheses assume equal prior probabilities.\nplot(h)\n\n\n\n\nIf we want the same Bayes Factor ratio that Bayes Rules! calculates, we need to use the evidence ratio from brms and calculate prior_odds by hand:\n\nprior_prob <- pbeta(0.2, 4, 6)\nprior_odds <- prior_prob / (1 - prior_prob)\n\npost_odds_brms <- h$hypothesis$Evid.Ratio\n\nBF_brms <- post_odds_brms / prior_odds\nBF_brms\n## [1] 62.57594\n\n\n\nTwo-sided tests (ROPE stuff)\nWhat if we want to know whether or not 30% of museum artists are Gen X or younger, not just a direction? Now we’re dealing with two sides:\n\\[\n\\begin{split}\nH_0: & \\; \\; \\pi = 0.3 \\\\\nH_a: & \\; \\; \\pi \\ne 0.3 \\\\\n\\end{split}\n\\]\nWe already know the 95% credible interval for π, and 0.3 doesn’t really fit well in it:\n\nggplot() +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\",\n                fill = colorspace::lighten(clrs[3], 0.9)) +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\", \n                xlim = qbeta(c(0.025, 0.975), 18, 92),\n                fill = clrs[3]) +\n  geom_vline(xintercept = 0.3) +\n  xlim(c(0, 0.4)) +\n  labs(x = \"π\", fill = \"Credible interval\")\n\n\n\n\nThat provides us with good evidence that the hypothesis that 30% of artists are Gen X is not correct. It’s subtantially outside of the credible interval. But what does substantial mean? We get to define that.\nWe can be like Kruschke and define a buffer around 0.3, or a region of practical equivalence (ROPE). Here we’ll do 0.3±0.05, or between 0.25 and 0.35. We can calculate how much of the posterior is outside of that ROPE.\nSince we know the actual posterior is \\(\\operatorname{Beta}(18, 92)\\), we can find the percentage of the area of the curve that falls in the ROPE with pbeta():\n\nprop_in_rope <- pbeta(0.35, 18, 92) - pbeta(0.25, 18, 92)\nprop_in_rope\n## [1] 0.01250077\n1 - prop_in_rope\n## [1] 0.9874992\n\n98.7% of the posterior is outside of that ROPE. I’d say a value of 30% is pretty substantially far away from the posterior and thus really unlikely.\n\nggplot() +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\",\n                fill = colorspace::lighten(clrs[3], 0.9)) +\n  stat_function(fun = ~dbeta(., 18, 92), geom = \"area\", \n                xlim = qbeta(c(0.025, 0.975), 18, 92),\n                fill = clrs[3]) +\n  annotate(geom = \"rect\", xmin = 0.25, xmax = 0.35, ymin = -Inf, ymax = Inf, alpha = 0.3) +\n  geom_vline(xintercept = 0.3) +\n  xlim(c(0, 0.4)) +\n  labs(x = \"π\", fill = \"Credible interval\")\n\n\n\n\nWe can do this with the MCMC draws too and we get the same results:\n\nbrmsStan\n\n\n\nmodel_pi_brms |> \n  spread_draws(b_Intercept) |> \n  summarize(prop_in_rope = sum(b_Intercept > 0.25 & b_Intercept < 0.35) / n(),\n            prop_outside_rope = 1 - prop_in_rope)\n## # A tibble: 1 × 2\n##   prop_in_rope prop_outside_rope\n##          <dbl>             <dbl>\n## 1       0.0119             0.988\n\n\n\n\npi_stan_samples |> \n  spread_draws(pi) |> \n  summarize(prop_in_rope = sum(pi > 0.25 & pi < 0.35) / n(),\n            prop_outside_rope = 1 - prop_in_rope)\n## # A tibble: 1 × 2\n##   prop_in_rope prop_outside_rope\n##          <dbl>             <dbl>\n## 1       0.0109             0.989"
  },
  {
    "objectID": "bayes-rules/08-chapter.html#posterior-prediction",
    "href": "bayes-rules/08-chapter.html#posterior-prediction",
    "title": "Reading notes",
    "section": "8.3: Posterior prediction",
    "text": "8.3: Posterior prediction\n(This stuff is all covered in my guide here too)\nWe get data for 20 more pieces of art at the museum. Based on what we know about π, how many would we predict would be by Gen X artists?\nIt’s reasonable to think 3 (since 20 * 0.16 = 3), but that misses out on two levels of uncertainty:\n\nSampling variability in the data - even if π is truly 0.16, the amount we get in the sample will vary just because of randomness\nPosterior variability in π - it could be anywhere between 0.1 and 0.24\n\nThe posterior predictive model takes both kinds of uncertainty into account\nThere’s technically a mathy way to get at posterior predictions, and the book covers it, but it’s a complicated mess and they even conclude by saying “In this book, we’ll never need to do something like this again”\nIn the book, the actual posterior predictive probability that 3 of the 20 new artists will be Gen X, based on a posterior that saw 14 (i.e. the model we created), is 0.2217.\nWe can approximate that exact 0.2217 with the MCMC draws too. With brms models we can use posterior_predict(), posterior_linpred(), and posterior_epred() to extract different types of posterior outcomes on different scales. With raw Stan output, we have to do a little more work ourselves.\n\nbrmsStan\n\n\nWe want to use predicted_draws() since that incorporates both kinds of uncertainty, and it returns values that are predicted counts, not probabilities or π (see my guide for more)\n\npredicted_genx_after_20 <- model_pi_brms |> \n  predicted_draws(newdata = tibble(artworks = 20)) |> \n  group_by(.prediction) |> \n  summarize(n = n()) |> \n  mutate(prop = n / sum(n))\npredicted_genx_after_20\n## # A tibble: 13 × 3\n##    .prediction     n      prop\n##          <int> <int>     <dbl>\n##  1           0   637 0.0398   \n##  2           1  1963 0.123    \n##  3           2  3297 0.206    \n##  4           3  3533 0.221    \n##  5           4  2904 0.182    \n##  6           5  1881 0.118    \n##  7           6  1097 0.0686   \n##  8           7   432 0.027    \n##  9           8   183 0.0114   \n## 10           9    52 0.00325  \n## 11          10    16 0.001    \n## 12          11     4 0.00025  \n## 13          14     1 0.0000625\n\nggplot(predicted_genx_after_20, aes(x = factor(.prediction), y = prop)) + \n  geom_col()\n\n\n\n\n# Posterior predictive probability that 3/20 will be Gen X is roughly the same\n# as 0.2217!\npredicted_genx_after_20 |> \n  filter(.prediction == 3) |> \n  pull(prop)\n## [1] 0.2208125\n\nWe can also get the variability in just π if we wanted by using linpred_draws():\n\nmodel_pi_brms |> \n  linpred_draws(newdata = tibble(artworks = 20)) |> \n  ungroup() |> \n  ggplot(aes(x = .linpred)) +\n  stat_halfeye()\n\n\n\n\nAnd if we use epred_draws(), we’ll get the expected number of Gen X artworks:\n\nmodel_pi_brms |> \n  epred_draws(newdata = tibble(artworks = 20)) |> \n  ungroup() |> \n  ggplot(aes(x = .epred)) +\n  stat_halfeye()\n\n\n\n\nLovely.\n\n\nRaw Stan requires a little more work. We could theoretically use Stan to generate posterior predictions with a generated quantities block:\ngenerated quantities {\n  vector[1000] num_genx_rep;\n\n  for (i in 1:1000) {\n    num_genx_rep[i] = binomial_rng(20, pi);\n  }\n}\nBut that requires either hard-coding two numbers into the Stan code: 1000 for the number of simulations and 20 for the number of new artworks. If we want to change any of those, we’d have to recompile, which is tedious.\nAlternatively, we could add a couple variables to the data block and pass them through R:\ndata {\n  // other variables\n  int<lower=1> n_sims;\n  int<lower=1> new_artworks;\n}\n\n// other blocks\n\ngenerated quantities {\n  vector[n_sims] num_genx_rep;\n\n  for (i in 1:n_sims) {\n    num_genx_rep[i] = binomial_rng(new_artworks, pi);\n  }\n}\nWe’d then need to include values for those new variables in the list of data we pass to Stan:\n\npi_stan_samples <- model_pi_stan$sample(\n  data = list(artworks = 100, num_genx = 14, new_artworks = 20, n_sims = 1000),\n  parallel_chains = 4, iter_warmup = 2500, iter_sampling = 2500, \n  refresh = 0, seed = BAYES_SEED\n)\n\nThat would work great and the results from Stan would include 1000 predictions for the number of Gen X artists. But it feels a little excessive to keep rerunning the original 14-artworks model over and over for different numbers of new artworks.\nSo instead we can use R to build the posterior predictions, since we have all the posterior values of π in the MCMC chains, and since all we’re really doing with Stan is using Stan’s version of rbinom() anyway (binomial_rng()).\n\npredicted_genx_after_20_stan <- pi_stan_samples |> \n  spread_draws(pi) |> \n  mutate(.prediction = rbinom(n(), size = 20, prob = pi)) \n\npredicted_genx_after_20_stan_summarized <- predicted_genx_after_20_stan |> \n  group_by(.prediction) |> \n  summarize(n = n()) |> \n  mutate(prop = n / sum(n))\npredicted_genx_after_20_stan\n## # A tibble: 10,000 × 5\n##    .chain .iteration .draw    pi .prediction\n##     <int>      <int> <int> <dbl>       <int>\n##  1      1          1     1 0.157           4\n##  2      1          2     2 0.151           1\n##  3      1          3     3 0.189           5\n##  4      1          4     4 0.226           6\n##  5      1          5     5 0.192           3\n##  6      1          6     6 0.210           5\n##  7      1          7     7 0.210           4\n##  8      1          8     8 0.174           5\n##  9      1          9     9 0.157           5\n## 10      1         10    10 0.153           3\n## # … with 9,990 more rows\n\nggplot(predicted_genx_after_20_stan_summarized, \n       aes(x = factor(.prediction), y = prop)) + \n  geom_col()\n\n\n\n\n# Posterior predictive probability that 3/20 will be Gen X is roughly the same\n# as 0.2217!\npredicted_genx_after_20_stan_summarized |> \n  filter(.prediction == 3) |> \n  pull(prop)\n## [1] 0.225\n\nWe can also get the equivalent of posterior_epred() by calculating the average of the predictive posterior:\n\nepred <- predicted_genx_after_20_stan |> \n  summarize(epred = mean(.prediction)) |> \n  pull(epred)\nepred\n## [1] 3.2581\n\nggplot(predicted_genx_after_20_stan, aes(x = .prediction)) + \n  stat_count() +\n  geom_vline(xintercept = epred)\n\n\n\n\nI haven’t figured out a way to get posterior_linpred() (the variability of just π) with raw Stan like this though. :("
  },
  {
    "objectID": "bayes-rules/08-chapter.html#posterior-analysis-with-mcmc",
    "href": "bayes-rules/08-chapter.html#posterior-analysis-with-mcmc",
    "title": "Reading notes",
    "section": "8.4: Posterior analysis with MCMC",
    "text": "8.4: Posterior analysis with MCMC\nOh ha, this whole section shows how to do everything above with Stan, but I already did that above with both brms and raw Stan, so just, um look up there ↑."
  },
  {
    "objectID": "bayes-rules/09-chapter.html",
    "href": "bayes-rules/09-chapter.html",
    "title": "Reading notes",
    "section": "",
    "text": "(Original chapter)"
  },
  {
    "objectID": "bayes-rules/09-chapter.html#tuning-prior-models-for-regression-parameters",
    "href": "bayes-rules/09-chapter.html#tuning-prior-models-for-regression-parameters",
    "title": "Reading notes",
    "section": "9.2: Tuning prior models for regression parameters",
    "text": "9.2: Tuning prior models for regression parameters\nWe want to estimate the effect of temperature on bike share ridership. We need to estimate three parameters:\n\n\\(\\beta_0\\), or the intercept. From prior research, we know:\n\n\nOn an average temperature day, say 65 or 70 degrees for D.C., there are typically around 5000 riders, though this average could be somewhere between 3000 and 7000.\n\n\n\\(\\beta_1\\), or the slope. From prior research, we know:\n\n\nFor every one degree increase in temperature, ridership typically increases by 100 rides, though this average increase could be as low as 20 or as high as 180.\n\n\n\\(\\sigma\\), or the variation in ridership. From prior research, we know:\n\n\nAt any given temperature, daily ridership will tend to vary with a moderate standard deviation of 1250 rides.\n\nThe intercept there is centered at 5000 riders.\nThat gives us these priors:\n\np1 <- ggplot() +\n  geom_function(fun = ~dnorm(., 5000, 1000), size = 1, color = clrs[1]) +\n  xlim(c(1000, 9000)) +\n  labs(x = \"**β<sub>0c</sub>**<br>Average daily ridership, centered\") +\n  theme(axis.title.x = element_markdown())\n\np2 <- ggplot() +\n  geom_function(fun = ~dnorm(., 100, 40), size = 1, color = clrs[3]) +\n  xlim(c(-50, 250)) +\n  labs(x = \"**β<sub>1</sub>**<br>Effect of temperature on ridership\") +\n  theme(axis.title.x = element_markdown())\n\np3 <- ggplot() +\n  geom_function(fun = ~dexp(., 1 / 1250), size = 1, color = clrs[4]) +\n  xlim(c(0, 7000)) +\n  labs(x = \"**σ**<br>Variation in daily ridership\") +\n  theme(axis.title.x = element_markdown())\n\np1 | p2 | p3\n\n\n\n\nMore formally, we can write out the whole model like this:\n\\[\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\text{, or}  & \\text{[McElreath's syntax]} \\\\\nY_i \\mid \\beta_0, \\beta_1, \\sigma &\\stackrel{\\text{ind}}{\\sim} \\mathcal{N}(\\mu_i, \\sigma^2) & \\text{[Bayes Rules!'s syntax]}\n\\\\\n\\mu_i &= \\beta_{0c} + \\beta_1 X_i \\\\\n\\\\\n\\beta_{0c} &\\sim \\mathcal{N}(5000, 1000) \\\\\n\\beta_{1} &\\sim \\mathcal{N}(100, 40) \\\\\n\\sigma &\\sim \\operatorname{Exponential}(1 / 1250)\n\\end{aligned}\n\\]\nWe can simulate from all these priors to see how reasonable they are, McElreath-style. In Bayes Rules! they show a picture of this but not the code to make it. I’ll use brms bc it’s easy.\n\npriors <- c(prior(normal(5000, 1000), class = Intercept),\n            prior(normal(100, 40), class = b, coef = \"temp_feel_c\"),\n            prior(exponential(0.0008), class = sigma))\n\nbike_prior_only <- brm(\n  bf(rides ~ temp_feel_c),\n  data = bikes,\n  family = gaussian(),\n  prior = priors,\n  sample_prior = \"only\",\n  backend = \"cmdstanr\", cores = 4, seed = BAYES_SEED, refresh = 0\n)\n## Start sampling\n\nThese lines all look reasonable, yay.\n\ndraws_prior <- tibble(temp_feel_c = seq(45 - temp_details$scaled_center, \n                                        90 - temp_details$scaled_center, \n                                        1)) |> \n  add_epred_draws(bike_prior_only, ndraws = 200) |> \n  mutate(unscaled = temp_feel_c + temp_details$scaled_center)\n\ndraws_prior |> \n  ggplot(aes(x = unscaled, y = .epred)) +\n  geom_line(aes(group = .draw), alpha = 0.2) +\n  labs(x = \"Temperature\", y = \"Number of rides\")"
  },
  {
    "objectID": "bayes-rules/09-chapter.html#posterior-simulation",
    "href": "bayes-rules/09-chapter.html#posterior-simulation",
    "title": "Reading notes",
    "section": "9.3: Posterior simulation",
    "text": "9.3: Posterior simulation\n\nRun the model\n\nrstanarmbrmsStan\n\n\n\nbike_rstanarm <- stan_glm(\n  rides ~ temp_feel_c,\n  data = bikes,\n  family = gaussian(),\n  prior_intercept = normal(5000, 1000),\n  prior = normal(100, 40),\n  prior_aux = exponential(0.0008),\n  chains = 4, iter = 5000*2, seed = 84735, refresh = 0\n)\n\n\n\n\npriors <- c(prior(normal(5000, 1000), class = Intercept),\n            prior(normal(100, 40), class = b, coef = \"temp_feel_c\"),\n            prior(exponential(0.0008), class = sigma))\n\nbike_brms <- brm(\n  bf(rides ~ temp_feel_c),\n  data = bikes,\n  family = gaussian(),\n  prior = priors,\n  chains = 4, iter = 5000*2, seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0\n)\n## Start sampling\n\n\n\n\n\n\n09-stan/bike-simple.stan\n\ndata {\n  int<lower = 0> n;\n  vector[n] Y;\n  vector[n] X;\n}\n\n/*\n// We could also center things here and then use it in mu below:\n// mu = beta0 + beta1 * X_centered;\n// See https://mc-stan.org/docs/stan-users-guide/standardizing-predictors-and-outputs.html\ntransformed data {\n  vector[n] X_centered;\n  \n  X_centered = X - mean(X);\n}\n*/\n\nparameters {\n  real beta0;\n  real beta1;\n  real<lower = 0> sigma;\n}\n\ntransformed parameters {\n  vector[n] mu;\n  mu = beta0 + beta1 * X;\n}\n\nmodel {\n  Y ~ normal(mu, sigma);\n  \n  beta0 ~ normal(5000, 1000);\n  beta1 ~ normal(100, 40);\n  sigma ~ exponential(0.0008);\n}\n\ngenerated quantities {\n  vector[n] Y_rep;\n  \n  for (i in 1:n) {\n    Y_rep[i] = normal_rng(mu[i], sigma);\n  }\n}\n\n\n\nbike_stan <- cmdstan_model(\"09-stan/bike-simple.stan\")\n\n\nbike_stan_samples <- bike_stan$sample(\n  data = list(n = nrow(bikes), Y = bikes$rides, X = bikes$temp_feel_c),\n  parallel_chains = 4, iter_warmup = 5000, iter_sampling = 5000, \n  refresh = 0, seed = BAYES_SEED\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 3 finished in 2.0 seconds.\n## Chain 4 finished in 2.0 seconds.\n## Chain 1 finished in 2.0 seconds.\n## Chain 2 finished in 2.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 2.0 seconds.\n## Total execution time: 2.1 seconds.\n\n\n\n\n\n\nDiagnostics\n\nrstanarmbrmsStan\n\n\n\nEffective sample size and R-hat\n\nneff_ratio(bike_rstanarm)\n## (Intercept) temp_feel_c       sigma \n##     0.96345     0.96075     0.96825\nrhat(bike_rstanarm)\n## (Intercept) temp_feel_c       sigma \n##   0.9998765   0.9999727   1.0000086\n\n\n\nTrace plots\n\nbike_rstanarm |> \n  gather_draws(`(Intercept)`, temp_feel_c, sigma) |> \n  ungroup() |> \n  mutate(.variable = fct_relevel(factor(.variable), c(\"(Intercept)\", \"temp_feel_c\", \"sigma\"))) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.05) +\n  labs(color = \"Chain\") +\n  facet_wrap(vars(.variable), scales = \"free_y\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nTrank plots\n\nbike_rstanarm |> \n  gather_draws(`(Intercept)`, temp_feel_c, sigma) |> \n  ungroup() |> \n  mutate(.variable = fct_relevel(factor(.variable), c(\"(Intercept)\", \"temp_feel_c\", \"sigma\"))) |> \n  group_by(.variable) |> \n  mutate(draw_rank = rank(.value)) |> \n  ggplot(aes(x = draw_rank)) +\n  stat_bin(aes(color = factor(.chain)), geom = \"step\", binwidth = 1000,\n           position = position_identity(), boundary = 0) +\n  labs(color = \"Chain\") +\n  facet_wrap(vars(.variable)) +\n  theme(legend.position = \"bottom\",\n        axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n\n\n\n\n\n\nDensity plots\n\nbike_rstanarm |> \n  gather_draws(`(Intercept)`, temp_feel_c, sigma) |> \n  ungroup() |> \n  mutate(.variable = fct_relevel(factor(.variable), c(\"(Intercept)\", \"temp_feel_c\", \"sigma\"))) |> \n  ggplot(aes(x = .value, color = factor(.chain))) +\n  geom_density() +\n  labs(color = \"Chain\") +\n  facet_wrap(vars(.variable), scales = \"free\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nEffective sample size and R-hat\n\nneff_ratio(bike_brms)\n##   b_Intercept b_temp_feel_c         sigma     Intercept        lprior \n##     1.0579051     1.0534749     1.1040274     1.0579051     1.0473025 \n##          lp__ \n##     0.4827253\nrhat(bike_brms)\n##   b_Intercept b_temp_feel_c         sigma     Intercept        lprior \n##      1.000021      1.000172      1.000024      1.000021      1.000135 \n##          lp__ \n##      1.000185\n\n\n\nTrace plots\n\nbike_brms |> \n  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.05) +\n  labs(color = \"Chain\") +\n  facet_wrap(vars(.variable), scales = \"free_y\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nTrank plots\n\nbike_brms |> \n  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> \n  group_by(.variable) |> \n  mutate(draw_rank = rank(.value)) |> \n  ggplot(aes(x = draw_rank)) +\n  stat_bin(aes(color = factor(.chain)), geom = \"step\", binwidth = 1000,\n           position = position_identity(), boundary = 0) +\n  labs(color = \"Chain\") +\n  facet_wrap(vars(.variable)) +\n  theme(legend.position = \"bottom\",\n        axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n\n\n\n\n\n\nDensity plots\n\nbike_brms |> \n  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> \n  ggplot(aes(x = .value, color = factor(.chain))) +\n  geom_density() +\n  labs(color = \"Chain\") +\n  facet_wrap(vars(.variable), scales = \"free\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nEffective sample size and R-hat\n\nneff_ratio(bike_stan_samples, pars = c(\"beta0\", \"beta1\", \"sigma\"))\n##    beta0    beta1    sigma \n## 1.077305 1.012467 1.085847\nrhat(bike_stan_samples, pars = c(\"beta0\", \"beta1\", \"sigma\"))\n##     beta0     beta1     sigma \n## 1.0001360 1.0000768 0.9999753\n\n\n\nTrace plots\n\nbike_stan_samples |> \n  gather_draws(beta0, beta1, sigma) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.05) +\n  labs(color = \"Chain\") +\n  facet_wrap(vars(.variable), scales = \"free_y\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nTrank plots\n\nbike_stan_samples |> \n  gather_draws(beta0, beta1, sigma) |> \n  group_by(.variable) |> \n  mutate(draw_rank = rank(.value)) |> \n  ggplot(aes(x = draw_rank)) +\n  stat_bin(aes(color = factor(.chain)), geom = \"step\", binwidth = 1000,\n           position = position_identity(), boundary = 0) +\n  labs(color = \"Chain\") +\n  facet_wrap(vars(.variable)) +\n  theme(legend.position = \"bottom\",\n        axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n\n\n\n\n\n\nDensity plots\n\nbike_stan_samples |> \n  gather_draws(beta0, beta1, sigma) |> \n  ggplot(aes(x = .value, color = factor(.chain))) +\n  geom_density() +\n  labs(color = \"Chain\") +\n  facet_wrap(vars(.variable), scales = \"free\") +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "bayes-rules/09-chapter.html#interpreting-the-posterior",
    "href": "bayes-rules/09-chapter.html#interpreting-the-posterior",
    "title": "Reading notes",
    "section": "9.4: Interpreting the posterior",
    "text": "9.4: Interpreting the posterior\n\nParameter summaries\n\nrstanarmbrmsStan\n\n\n\ntidy(bike_rstanarm, effects = c(\"fixed\", \"aux\"), \n     conf.int = TRUE, conf.level = 0.8)\n## # A tibble: 4 × 5\n##   term        estimate std.error conf.low conf.high\n##   <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n## 1 (Intercept)   3487.      58.0    3413.     3561. \n## 2 temp_feel_c     82.2      5.08     75.7      88.7\n## 3 sigma         1282.      40.9    1231.     1336. \n## 4 mean_PPD      3487.      82.0    3382.     3593.\n\n\nbike_rstanarm |> \n  gather_draws(`(Intercept)`, temp_feel_c, sigma) |> \n  ungroup() |> \n  mutate(.variable = fct_relevel(factor(.variable), c(\"(Intercept)\", \"temp_feel_c\", \"sigma\"))) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = c(clrs[1], clrs[3], clrs[4]), guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\") +\n  labs(x = \"Parameter posterior\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\ntidy(bike_brms, conf.int = TRUE, conf.level = 0.8) |> \n  select(-c(effect, component, group))\n## # A tibble: 3 × 5\n##   term            estimate std.error conf.low conf.high\n##   <chr>              <dbl>     <dbl>    <dbl>     <dbl>\n## 1 (Intercept)       3487.      57.5    3414.     3561. \n## 2 temp_feel_c         82.1      5.08     75.6      88.6\n## 3 sd__Observation   1283.      40.3    1232.     1336.\n\n\nbike_brms |> \n  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = c(clrs[1], clrs[3], clrs[4]), guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\") +\n  labs(x = \"Parameter posterior\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nbike_stan_samples$print(variables = c(\"beta0\", \"beta1\", \"sigma\"), \n                        \"mean\", \"median\", \"sd\", ~quantile(.x, probs = c(0.1, 0.9)))\n##  variable    mean  median    sd     10%     90%\n##     beta0 3487.16 3486.85 57.13 3414.32 3560.02\n##     beta1   82.12   82.10  5.06   75.68   88.58\n##     sigma 1282.72 1281.84 40.44 1231.39 1335.31\n\n\nbike_stan_samples |> \n  gather_draws(beta0, beta1, sigma) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = c(clrs[1], clrs[3], clrs[4]), guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\") +\n  labs(x = \"Parameter posterior\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nFitted draws\n\nrstanarmbrmsStan\n\n\n\nbikes |> \n  add_linpred_draws(bike_rstanarm, ndraws = 100) |> \n  ggplot(aes(x = temp_feel, y = rides)) +\n  geom_point(data = bikes, size = 0.5) +\n  geom_line(aes(y = .linpred, group = .draw), alpha = 0.2, size = 0.5, color = clrs[6]) +\n  labs(x = \"Temperature\", y = \"Rides\")\n\n\n\n\n\n\n\nbikes |> \n  add_linpred_draws(bike_brms, ndraws = 100) |> \n  ggplot(aes(x = temp_feel, y = rides)) +\n  geom_point(data = bikes, size = 0.5) +\n  geom_line(aes(y = .linpred, group = .draw), alpha = 0.2, size = 0.5, color = clrs[6]) +\n  labs(x = \"Temperature\", y = \"Rides\")\n\n\n\n\n\n\n\nbike_stan_samples |> \n  spread_draws(mu[i]) |> \n  mean_qi() |> \n  bind_cols(bikes) |> \n  ggplot(aes(x = temp_feel, y = rides)) +\n  geom_point(size = 0.5) +\n  geom_line(aes(y = mu), color = clrs[6], size = 1) +\n  geom_ribbon(aes(ymin = .lower, ymax = .upper), fill = clrs[6], alpha = 0.2) +\n  labs(x = \"Temperature\", y = \"Rides\")\n\n\n\n\nThere’s no easy way to replicate add_linpred_draws(..., ndraws = BLAH) with raw Stan like this without running the model again and generating a bunch of simulated mus based on some variable like n_sim that we build into the Stan model, but we can use the original 500 rows of data and use geom_lineribbon() instead of a spaghetti plot.\n\n\n\n\n\nIs β1 > 0?\nEasily.\n\nrstanarmbrmsStan\n\n\n\nbike_rstanarm |> \n  spread_draws(temp_feel_c) |> \n  count(temp_feel_c > 0) |> \n  mutate(prob = n / sum(n))\n## # A tibble: 1 × 3\n##   `temp_feel_c > 0`     n  prob\n##   <lgl>             <int> <dbl>\n## 1 TRUE              20000     1\n\n\n\n\nbike_brms |> \n  spread_draws(b_temp_feel_c) |> \n  count(b_temp_feel_c > 0) |> \n  mutate(prob = n / sum(n))\n## # A tibble: 1 × 3\n##   `b_temp_feel_c > 0`     n  prob\n##   <lgl>               <int> <dbl>\n## 1 TRUE                20000     1\n\n\n\n\nbike_stan_samples |> \n  spread_draws(beta1) |> \n  count(beta1 > 0) |> \n  mutate(prob = n / sum(n))\n## # A tibble: 1 × 3\n##   `beta1 > 0`     n  prob\n##   <lgl>       <int> <dbl>\n## 1 TRUE        20000     1"
  },
  {
    "objectID": "bayes-rules/09-chapter.html#posterior-prediction",
    "href": "bayes-rules/09-chapter.html#posterior-prediction",
    "title": "Reading notes",
    "section": "9.5: Posterior prediction",
    "text": "9.5: Posterior prediction\nWe could plug in some temperature, like 75, and get a predicted count of riders (values from the rstanarm model):\n\nvalues_rstanarm <- bike_rstanarm |> \n  tidy() |> \n  split(~term)\n\nb0 <- values_rstanarm$`(Intercept)`$estimate\nb1 <- values_rstanarm$temp_feel_c$estimate\ntemp_mean <- temp_details$scaled_center\n\nb0 + (b1 * (75 - temp_mean))\n## [1] 3968.317\n\nBut this ignores two types of uncertainty:\n\nSampling variability in the data, or in \\(Y\\)\nPosterior variability in parameters, or in \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\)\n\n\nrstanarmbrmsStan\n\n\n\np1 <- bike_rstanarm |> \n  linpred_draws(newdata = tibble(temp_feel_c = (75 - temp_mean))) |> \n  ggplot(aes(x = .linpred)) +\n  stat_halfeye(fill = clrs[6]) +\n  labs(title = \"Predicted riders at 75˚\",\n       subtitle = \"µ only; posterior_linpred()\",\n       x = \"Predicted riders\", y = NULL)\n\np2 <- bike_rstanarm |> \n  predicted_draws(newdata = tibble(temp_feel_c = (75 - temp_mean))) |> \n  ggplot(aes(x = .prediction)) +\n  stat_halfeye(fill = clrs[5]) +\n  labs(title = \"Predicted riders at 75˚\",\n       subtitle = \"rnorm(µ, σ); posterior_predict()\",\n       x = \"Predicted riders\", y = NULL)\n\np1 | p2\n\n\n\n\n\n\n\np1 <- bike_brms |> \n  linpred_draws(newdata = tibble(temp_feel_c = (75 - temp_mean))) |> \n  ggplot(aes(x = .linpred)) +\n  stat_halfeye(fill = clrs[6]) +\n  labs(title = \"Predicted riders at 75˚\",\n       subtitle = \"µ only; posterior_linpred()\",\n       x = \"Predicted riders\", y = NULL)\n\np2 <- bike_brms |> \n  predicted_draws(newdata = tibble(temp_feel_c = (75 - temp_mean))) |> \n  ggplot(aes(x = .prediction)) +\n  stat_halfeye(fill = clrs[5]) +\n  labs(title = \"Predicted riders at 75˚\",\n       subtitle = \"rnorm(µ, σ); posterior_predict()\",\n       x = \"Predicted riders\", y = NULL)\n\np1 | p2\n\n\n\n\n\n\nAHH SO THIS IS HOW YOU DO newdata = WHATEVER WITH RAW STAN. Build mu (posterior_linpred()) on your own with the coefficients from each draw, then use that mu in rnorm() (posterior_predict()). You can then get the expectation of the posterior (posterior_epred()) by taking the average of that.\n\npredict_75 <- bike_stan_samples |> \n  spread_draws(beta0, beta1, sigma) |> \n  mutate(mu = beta0 + (beta1 * (75 - temp_mean)),  # like posterior_linpred()\n         y_new = rnorm(n(), mean = mu, sd = sigma))  # like posterior_predict()\n\np1 <- predict_75 |> \n  ggplot(aes(x = mu)) +\n  stat_halfeye(fill = clrs[6]) +\n  labs(title = \"Predicted riders at 75˚\",\n       subtitle = \"µ only; like posterior_linpred()\",\n       x = \"Predicted riders\", y = NULL)\n\np2 <- predict_75 |> \n  ggplot(aes(x = y_new)) +\n  stat_halfeye(fill = clrs[5]) +\n  labs(title = \"Predicted riders at 75˚\",\n       subtitle = \"rnorm(µ, σ); like posterior_predict()\",\n       x = \"Predicted riders\", y = NULL)\n\np1 | p2\n\n\n\n\npredict_75 |> \n  summarize(epred = mean(y_new))\n## # A tibble: 1 × 1\n##   epred\n##   <dbl>\n## 1 3968."
  },
  {
    "objectID": "bayes-rules/09-chapter.html#sequential-regression-modeling",
    "href": "bayes-rules/09-chapter.html#sequential-regression-modeling",
    "title": "Reading notes",
    "section": "9.6: Sequential regression modeling",
    "text": "9.6: Sequential regression modeling\nBayesianism is all about updating. What does this relationship between temperature and ridership as data is slowly collected, like after 30 days, 60 days, and 500 days? How does the posterior evolve and settle?\nI’ll do this just with brms:\n\npriors <- c(prior(normal(5000, 1000), class = Intercept),\n            prior(normal(100, 40), class = b, coef = \"temp_feel_c\"),\n            prior(exponential(0.0008), class = sigma))\n\nbike_phases <- tribble(\n  ~phase, ~data,\n  1,      slice(bikes, 1:30),\n  2,      slice(bikes, 1:60),\n  3,      bikes\n) |> \n  mutate(model = map(data, ~{\n    brm(\n      bf(rides ~ temp_feel_c),\n      data = .,\n      family = gaussian(),\n      prior = priors,\n      chains = 4, iter = 5000*2, seed = BAYES_SEED, \n      backend = \"cmdstanr\", refresh = 0\n    )})\n  )\n## Start sampling\n## Start sampling\n## Start sampling\n\n\nbike_phase_draws <- bike_phases |> \n  mutate(draws = map(model, ~spread_draws(., b_temp_feel_c)))\n\nphases_coefs <- bike_phase_draws |> \n  mutate(coef_plot = map2(draws, phase, ~{\n    ggplot(.x, aes(x = b_temp_feel_c)) +\n      stat_halfeye(fill = clrs[3]) +\n      coord_cartesian(xlim = c(-10, 100)) +\n      labs(title = paste(\"Phase\", .y))\n  }))\n\nwrap_plots(phases_coefs$coef_plot)\n\n\n\n\n\nbike_phase_preds <- bike_phases |> \n  mutate(preds = map2(data, model, ~{\n    .x |> \n      add_linpred_draws(.y, ndraws = 50) |> \n      ungroup()\n  }))\n\nphases_preds <- bike_phase_preds |> \n  mutate(pred_plot = pmap(list(data, preds, phase), ~{\n    ggplot(..2, aes(x = temp_feel, y = rides)) +\n      geom_point(data = ..1, size = 0.5) +\n      geom_line(aes(y = .linpred, group = .draw), \n                alpha = 0.2, size = 0.5, color = clrs[6]) +\n      labs(title = paste(\"Phase\", ..3)) +\n      coord_cartesian(xlim = c(40, 90), ylim = c(0, 7000))\n  }))\n\nwrap_plots(phases_preds$pred_plot)"
  },
  {
    "objectID": "bayes-rules/10-chapter.html",
    "href": "bayes-rules/10-chapter.html",
    "title": "Reading notes",
    "section": "",
    "text": "(Original chapter)\n\\[\n\\require{mathtools}\n\\]"
  },
  {
    "objectID": "bayes-rules/10-chapter.html#the-setup",
    "href": "bayes-rules/10-chapter.html#the-setup",
    "title": "Reading notes",
    "section": "The setup",
    "text": "The setup\nBack to the model from chapter 9, modeling Capital Bikeshare rides based on daily temperatures:\n\\[\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\text{, or}  & \\text{[McElreath's syntax]} \\\\\nY_i \\mid \\beta_0, \\beta_1, \\sigma &\\stackrel{\\text{ind}}{\\sim} \\mathcal{N}(\\mu_i, \\sigma^2) & \\text{[Bayes Rules!'s syntax]}\n\\\\\n\\mu_i &= \\beta_{0c} + \\beta_1 X_i \\\\\n\\\\\n\\beta_{0c} &\\sim \\mathcal{N}(5000, 1000) \\\\\n\\beta_{1} &\\sim \\mathcal{N}(100, 40) \\\\\n\\sigma &\\sim \\operatorname{Exponential}(1 / 1250)\n\\end{aligned}\n\\]\n\nrstanarmbrmsStan\n\n\n\nbike_rstanarm <- stan_glm(\n  rides ~ temp_feel_c,\n  data = bikes,\n  family = gaussian(),\n  prior_intercept = normal(5000, 1000),\n  prior = normal(100, 40),\n  prior_aux = exponential(0.0008),\n  chains = 4, iter = 5000*2, seed = 84735, refresh = 0\n)\n\n\n\n\npriors <- c(prior(normal(5000, 1000), class = Intercept),\n            prior(normal(100, 40), class = b, coef = \"temp_feel_c\"),\n            prior(exponential(0.0008), class = sigma))\n\nbike_brms <- brm(\n  bf(rides ~ temp_feel_c),\n  data = bikes,\n  family = gaussian(),\n  prior = priors,\n  chains = 4, iter = 5000*2, seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0\n)\n## Start sampling\n\n\n\n\n\n\n10-stan/bike-better.stan\n\ndata {\n  int<lower = 0> n;\n  vector[n] Y;\n  vector[n] X;\n}\n\nparameters {\n  real beta0;\n  real beta1;\n  real<lower = 0> sigma;\n}\n\ntransformed parameters {\n  vector[n] mu;\n  mu = beta0 + beta1 * X;\n}\n\nmodel {\n  Y ~ normal(mu, sigma);\n  \n  beta0 ~ normal(5000, 1000);\n  beta1 ~ normal(100, 40);\n  sigma ~ exponential(0.0008);\n}\n\ngenerated quantities {\n  vector[n] Y_rep;\n  vector[n] log_lik;\n  \n  for (i in 1:n) {\n    log_lik[i] = normal_lpdf(Y[i] | mu[i], sigma);\n    Y_rep[i] = normal_rng(mu[i], sigma);\n  }\n}\n\n\n\nbike_stan_better <- cmdstan_model(\"10-stan/bike-better.stan\")\n\n\nbike_stan_samples <- bike_stan_better$sample(\n  data = list(n = nrow(bikes), Y = bikes$rides, X = bikes$temp_feel_c),\n  parallel_chains = 4, iter_warmup = 5000, iter_sampling = 5000, \n  refresh = 0, seed = BAYES_SEED\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 2.5 seconds.\n## Chain 2 finished in 2.5 seconds.\n## Chain 3 finished in 2.5 seconds.\n## Chain 4 finished in 2.5 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 2.5 seconds.\n## Total execution time: 2.6 seconds.\n\n\n\n\nResults:\n\nrstanarmbrmsStan\n\n\n\ntidy(bike_rstanarm, effects = c(\"fixed\", \"aux\"), \n     conf.int = TRUE, conf.level = 0.8)\n## # A tibble: 4 × 5\n##   term        estimate std.error conf.low conf.high\n##   <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n## 1 (Intercept)   3487.      58.0    3413.     3561. \n## 2 temp_feel_c     82.2      5.08     75.7      88.7\n## 3 sigma         1282.      40.9    1231.     1336. \n## 4 mean_PPD      3487.      82.0    3382.     3593.\n\n\n\n\ntidy(bike_brms, conf.int = TRUE, conf.level = 0.8) |> \n  select(-c(effect, component, group))\n## # A tibble: 3 × 5\n##   term            estimate std.error conf.low conf.high\n##   <chr>              <dbl>     <dbl>    <dbl>     <dbl>\n## 1 (Intercept)       3487.      57.5    3414.     3561. \n## 2 temp_feel_c         82.1      5.08     75.6      88.6\n## 3 sd__Observation   1283.      40.3    1232.     1336.\n\n\n\n\nbike_stan_samples$print(variables = c(\"beta0\", \"beta1\", \"sigma\"), \n                        \"mean\", \"median\", \"sd\", ~quantile(.x, probs = c(0.1, 0.9)))\n##  variable    mean  median    sd     10%     90%\n##     beta0 3487.16 3486.85 57.13 3414.32 3560.02\n##     beta1   82.12   82.10  5.06   75.68   88.58\n##     sigma 1282.72 1281.84 40.44 1231.39 1335.31"
  },
  {
    "objectID": "bayes-rules/10-chapter.html#how-wrong-is-the-model",
    "href": "bayes-rules/10-chapter.html#how-wrong-is-the-model",
    "title": "Reading notes",
    "section": "10.2: How wrong is the model?",
    "text": "10.2: How wrong is the model?\nThe model is definitely wrong—we just care about how wrong it is. There are three assumptions in this model:\n\\[\n\\begin{aligned}\nY_i \\mid \\beta_0, \\beta_1, \\sigma &\\overbrace{\\stackrel{\\text{ind}}{\\sim}}^{\\mathclap{\\text{Assumption 1}}} \\underbrace{\\mathcal{N}(\\mu_i, \\sigma^2)}_{\\text{Assumption 3}}\\\\\n\\mu_i &= \\underbrace{\\beta_{0c} + \\beta_1 X_i}_{\\text{Assumption 2}}\n\\end{aligned}\n\\]\n\nWhen conditioned on \\(X\\), the observed data \\(Y_i\\) for each case \\(i\\) is independent of the observed data for any other case (like \\(Y_j\\), \\(Y_k\\), etc)\nThe typical \\(Y\\) outcome can be written as a linear function of \\(X\\), or \\(\\mu = \\beta_0 + \\beta_1 X\\)\nAt any \\(X\\) value, \\(Y\\) varies normally around \\(\\mu\\) with a consistent variability of \\(\\sigma\\)\n\nWe can use statsy tests for assumption 1, but we don’t really need to—we can use logic instead. By itself, ridership count \\(Y\\) is highly correlated over time, but after controlling for \\(X\\), it’s likely that the autocorrelation with \\(Y\\) is cancelled out or controlled away. We’re probably reasonably okay.\nFor assumptions 2 and 3, we can use a scatterplot and see if (1) it looks linear and (2) it looks normally distributed around the line:\n\nggplot(bikes, aes(x = temp_feel, y = rides)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nLooks linear to me.\nBut just eyeballing it isn’t great. We can test the assumptions more formally with a posterior predictive check:\n\nIf the combined model assumptions are reasonable, then our posterior model should be able to simulate ridership data that’s similar to the original data.\n\nWe can check that by using the \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\) parameters from the chains to generate predictions for each of the MCMC draws. Here’s how that works behind the scenes:\nWe have 20,000 sets of intercepts, slopes, and sigmas\n\nbike_brms |> \n  spread_draws(b_Intercept, b_temp_feel_c, sigma) |> \n  select(starts_with(\"b_\"), sigma)\n## # A tibble: 20,000 × 3\n##    b_Intercept b_temp_feel_c sigma\n##          <dbl>         <dbl> <dbl>\n##  1       3457.          80.5 1281.\n##  2       3525.          80.3 1240.\n##  3       3470.          80.1 1259.\n##  4       3500.          80.3 1215 \n##  5       3521.          80.7 1336.\n##  6       3569.          86.7 1272.\n##  7       3562.          87.6 1290.\n##  8       3412.          76.7 1271.\n##  9       3475.          87.9 1329.\n## 10       3490.          74.2 1246.\n## # … with 19,990 more rows\n\nLet’s take just the first draw and plug the original dataset into that model to calculate \\(\\mu\\), then draw from a random normal distribution using \\(\\mu\\) and \\(\\sigma\\):\n\nfirst_draw <- bike_brms |> \n  spread_draws(b_Intercept, b_temp_feel_c, sigma) |> \n  slice(1)\n\none_rep <- bikes |> \n  mutate(mu = first_draw$b_Intercept + (first_draw$b_temp_feel_c * temp_feel_c),\n         y_rep = rnorm(500, mu, first_draw$sigma))\n\none_rep |> \n  select(temp_feel, temp_feel_c, rides, y_rep) |> \n  head(5)\n##   temp_feel temp_feel_c rides     y_rep\n## 1  64.72625   -4.417453   654  2885.575\n## 2  49.04645  -20.097253  1229  2652.113\n## 3  51.09098  -18.052723  1454  2775.513\n## 4  52.63430  -16.509403  1518 -1045.352\n## 5  50.79551  -18.348193  1362  1839.174\n\nAnd we can plot the two distributions to compare the model to the actual data:\n\nggplot(one_rep, aes(x = y_rep)) +\n  geom_density(color = \"lightblue\") + \n  geom_density(aes(x = rides), color = \"darkblue\")\n\n\n\n\nChoose a bunch of posterior draws, plug them in, and you’ve got a homegrown pp_check()!\n\nlotsa_draws <- bike_brms |> \n  spread_draws(b_Intercept, b_temp_feel_c, sigma) |> \n  slice_sample(n = 25) |> \n  mutate(id = 1:n())\n\nlotsa_reps <- lotsa_draws |> \n  mutate(mu = map2(b_Intercept, b_temp_feel_c, ~.x + .y * bikes$temp_feel_c),\n         y_rep = map2(mu, sigma, ~rnorm(500, .x, .y))) |> \n  unnest(y_rep)\n\nggplot(lotsa_reps, aes(x = y_rep)) +\n  geom_density(aes(group = id), color = \"lightblue\", size = 0.25) + \n  geom_density(data = bikes, aes(x = rides), \n               color = \"darkblue\", size = 1)\n\n\n\n\nAnd here’s pp_check() for comparison:\n\npp_check(bike_brms, type = \"dens_overlay\", ndraws = 25)\n\n\n\n\nHeck yes.\nThe plot looks okay-ish. It picks up the average and the general range, but it doesn’t pick up the bimodality in ridership."
  },
  {
    "objectID": "bayes-rules/10-chapter.html#how-accurate-are-the-posterior-predictive-models",
    "href": "bayes-rules/10-chapter.html#how-accurate-are-the-posterior-predictive-models",
    "title": "Reading notes",
    "section": "10.3: How accurate are the posterior predictive models?",
    "text": "10.3: How accurate are the posterior predictive models?\nA good model should be able to accurately predict new values of $Y. Here are 3 ways to evaluate the quality of predictions:\n\n10.3.1: Posterior predictive summaries\nHow well does the model predict the data we used to build the model? We can check the fit for October 22, 2012 for fun:\n\noctober22 <- bikes |> \n  filter(date == \"2012-10-22\") |> \n  select(temp_feel, rides)\noctober22\n##   temp_feel rides\n## 1  75.46478  6228\n\nThe temperature that day was 75˚, so let’s simulate the posterior predictive distribution for a day that’s 75˚:\n\nrstanarmbrmsStan\n\n\n\nbike_rstanarm |> \n  predicted_draws(newdata = tibble(temp_feel_c = 75 - temp_details$scaled_center)) |> \n  ggplot(aes(x = .prediction)) +\n  stat_halfeye(fill = clrs[5]) +\n  geom_vline(xintercept = october22$rides, color = \"orange\")\n\n\n\n\n\n\n\nbike_brms |> \n  predicted_draws(newdata = tibble(temp_feel_c = 75 - temp_details$scaled_center)) |> \n  ggplot(aes(x = .prediction)) +\n  stat_halfeye(fill = clrs[5]) +\n  geom_vline(xintercept = october22$rides, color = \"orange\")\n\n\n\n\n\n\n\npredict_75_stan <- bike_stan_samples |> \n  spread_draws(beta0, beta1, sigma) |> \n  mutate(mu = beta0 + (beta1 * (75 - temp_details$scaled_center)),\n         y_new = rnorm(n(), mu, sigma))\n\npredict_75_stan |> \n  ggplot(aes(x = y_new)) +\n  stat_halfeye(fill = clrs[5]) +\n  geom_vline(xintercept = october22$rides, color = \"orange\")\n\n\n\n\n\n\n\nThat orange line is kind of far out there—is that a problem? We can calculate the prediction error, or the distance between the observed \\(Y\\) and the posterior predictive mean \\(Y'\\), or \\(Y - Y'\\). In this case we under-predicted rids. There were 6,228 actual rides; the model only predicted 4,000ish:\n\nbike_brms |> \n  predicted_draws(newdata = tibble(temp_feel_c = 75 - temp_details$scaled_center)) |> \n  ungroup() |> \n  summarize(actual_rides = october22$rides, \n            avg_prediction = mean(.prediction),\n            error = october22$rides - avg_prediction)\n## # A tibble: 1 × 3\n##   actual_rides avg_prediction error\n##          <int>          <dbl> <dbl>\n## 1         6228          3964. 2264.\n\nWe can also think about the relative distance or error by dividing by the standard deviation. In this standardized scale, values beyond 2 or 3 standard deviations are pretty far off. Here we’re 1.76 standard deviations off from the mean, which is fine I guess:\n\nbike_brms |> \n  predicted_draws(newdata = tibble(temp_feel_c = 75 - temp_details$scaled_center)) |> \n  ungroup() |> \n  summarize(actual_rides = october22$rides, \n            avg_prediction = mean(.prediction),\n            error = october22$rides - avg_prediction,\n            error_scaled = error / sd(.prediction))\n## # A tibble: 1 × 4\n##   actual_rides avg_prediction error error_scaled\n##          <int>          <dbl> <dbl>        <dbl>\n## 1         6228          3963. 2265.         1.77\n\nPretty much every observed point falls within the 95% prediction interval, but that range is big (range of ≈4000 rides!)\n\nbike_brms |> \n  add_predicted_draws(newdata = bikes) |> \n  ungroup() |> \n  mutate(error = rides - .prediction) |> \n  summarize(mae = median(abs(error)),\n            mae_scaled = median(abs(error / sd(.prediction))))\n## # A tibble: 1 × 2\n##     mae mae_scaled\n##   <dbl>      <dbl>\n## 1 1251.      0.792\n\n\nbike_brms |> \n  add_predicted_draws(newdata = bikes, ndraws = 100) |> \n  ggplot(aes(x = temp_feel)) +\n  stat_interval(aes(y = .prediction, color_ramp = stat(level)), alpha = 0.25,\n                .width = c(0.5, 0.89, 0.95), color = clrs[3]) +\n  geom_point(aes(y = rides), size = 2, pch = 21, color = \"white\", fill = \"black\")\n\n\n\n\nWe can get more official measures with bayesrules::prediction_summary(), but it only works with rstanarm:\n\nbike_rstanarm |> prediction_summary(data = bikes)\n##        mae mae_scaled within_50 within_95\n## 1 991.2531  0.7658091     0.434     0.968\n\n\n\n10.3.2: Cross validation\nWe can use cross validation with \\(k\\) folds: hold out 50 rows for testing, use 450 rows for training, to that a bunch of times with different holdout rows. Leave-one-out CV builds the model with 499 rows, holding just one out as the test data.\n\nrstanarmbrmsStan\n\n\n\nset.seed(84735)\ncv_procedure <- prediction_summary_cv(\n  model = bike_rstanarm, data = bikes, k = 10)\n\n\ncv_procedure$folds\n##    fold       mae mae_scaled within_50 within_95\n## 1     1  990.2897  0.7710331      0.46      0.98\n## 2     2  965.8851  0.7434397      0.42      1.00\n## 3     3  950.3186  0.7298511      0.42      0.98\n## 4     4 1018.1896  0.7905312      0.46      0.98\n## 5     5 1161.8012  0.9085403      0.36      0.96\n## 6     6  937.3706  0.7322373      0.46      0.94\n## 7     7 1269.8300  1.0054441      0.32      0.96\n## 8     8 1111.8921  0.8606423      0.36      1.00\n## 9     9 1098.8982  0.8676561      0.40      0.92\n## 10   10  786.3265  0.6053804      0.56      0.96\n\n\ncv_procedure$cv\n##       mae mae_scaled within_50 within_95\n## 1 1029.08  0.8014756     0.422     0.968\n\n\n\n\nkfold_brms <- bikes |> \n  crossv_kfold(k = 10) |> \n  mutate(model = map(train, ~{\n    brm(\n      bf(rides ~ temp_feel_c),\n      data = .,\n      family = gaussian(),\n      prior = priors,\n      chains = 4, iter = 5000*2, seed = BAYES_SEED, \n      backend = \"cmdstanr\", refresh = 0\n    )\n  }))\n## Start sampling\n## Start sampling\n## Start sampling\n## Start sampling\n## Start sampling\n## Start sampling\n## Start sampling\n## Start sampling\n## Start sampling\n## Start sampling\n\n\nmae_kfold_brms <- kfold_brms |> \n  mutate(predictions = map2(test, model, ~{\n    .x |> \n      as_tibble() |> \n      add_predicted_draws(.y) |> \n      ungroup()\n  })) |> \n  mutate(mae = map(predictions, ~{\n    .x |> \n      mutate(error = rides - .prediction) |> \n      summarize(mae = median(abs(error)),\n                mae_scaled = median(abs(error / sd(.prediction))))\n  }))\n\n\nmae_kfold_brms |> \n  select(mae) |> \n  unnest(mae)\n## # A tibble: 10 × 2\n##      mae mae_scaled\n##    <dbl>      <dbl>\n##  1 1247.      0.783\n##  2 1249.      0.817\n##  3 1190.      0.753\n##  4 1230.      0.745\n##  5 1254.      0.811\n##  6 1322.      0.833\n##  7 1309.      0.802\n##  8 1298.      0.834\n##  9 1180.      0.747\n## 10 1274.      0.837\n\n\nmae_kfold_brms |> \n  select(mae) |> \n  unnest(mae) |> \n  summarize(across(everything(), mean))\n## # A tibble: 1 × 2\n##     mae mae_scaled\n##   <dbl>      <dbl>\n## 1 1255.      0.796\n\n\n\n\nkfold_stan <- bikes |> \n  crossv_kfold(k = 10) |> \n  mutate(model = map(train, ~{\n    # Stan likes working with data frames, not whatever the kfold split is\n    df <- as_tibble(.)\n    \n    bike_stan_better$sample(\n      data = list(n = nrow(df), Y = df$rides, X = df$temp_feel_c),\n      parallel_chains = 4, iter_warmup = 5000, iter_sampling = 5000, \n      refresh = 0, seed = BAYES_SEED\n    )\n  }))\n\nPhew this is complex and creates a massively huge R object (like multiple GBs when trying to write it as RDS), and it makes Quarto choke when rendering, so I don’t actually run it here. Here’s the code though—it works when running interactively in RStudio (but takes a long time still).\n\nmae_kfold_stan <- kfold_stan |> \n  mutate(predictions = map2(test, model, ~{\n    df <- .x |> as_tibble()\n    \n    draws <- .y |> \n      spread_draws(beta0, beta1, sigma)\n    \n    df |> \n      mutate(mu = map(temp_feel_c, ~draws$beta0 + draws$beta1 * .),\n             yrep = map(mu, ~rnorm(length(.), ., draws$sigma))) |> \n      unnest(yrep)\n  })) |> \n  mutate(mae = map(predictions, ~{\n    .x |> \n      mutate(error = rides - yrep) |> \n      summarize(mae = median(abs(error)),\n                mae_scaled = median(abs(error / sd(yrep))))\n  }))\n\n\nmae_kfold_stan |> \n  select(mae) |> \n  unnest(mae)\n\n\n# This is the saved RDS object that contains mae_kfold_stan |> select(mae) |> unnest(mae)\nmae_kfold_stan_summary\n## # A tibble: 10 × 2\n##      mae mae_scaled\n##    <dbl>      <dbl>\n##  1 1386.      0.896\n##  2 1202.      0.786\n##  3 1246.      0.779\n##  4 1211.      0.736\n##  5 1238.      0.769\n##  6 1266.      0.803\n##  7 1306.      0.843\n##  8 1277.      0.823\n##  9 1207.      0.756\n## 10 1225.      0.787\n\n\nmae_kfold_stan |> \n  select(mae) |> \n  unnest(mae) |> \n  summarize(across(everything(), mean))\n\n\nmae_kfold_stan_summary |> \n  summarize(across(everything(), mean))\n## # A tibble: 1 × 2\n##     mae mae_scaled\n##   <dbl>      <dbl>\n## 1 1256.      0.798\n\n\n\n\n\n\n10.3.3: Expected log-predictive density (ELPD)\nThe intuition behind the expected log-predictive density (or ELPD) is that we want higher values of the pdf at observed data point within the posterior for each prediction. Like, for instance, say we have these two pdfs for two predicted values, with the actual value of \\(Y\\) marked at the line:\n\np1 <- ggplot() +\n  geom_function(fun = ~dnorm(., 0, 1)) +\n  annotate(geom = \"segment\", x = 0.2, xend = 0.2, y = -Inf, yend = dnorm(0.2, 0, 1),\n           linetype = 21) +\n  annotate(geom = \"label\", x = 0.2, y = 0.01, label = \"Actual y\", fontface = \"bold\") +\n  xlim(c(-4, 4)) +\n  theme(axis.text = element_blank(), axis.ticks = element_blank()) +\n  labs(x = \"Posterior predictive distribution for a single Y′\", y = \"Density\",\n       title = \"Scenario 1\")\n\np2 <- ggplot() +\n  geom_function(fun = ~dnorm(., 0, 1)) +\n  annotate(geom = \"segment\", x = 1.8, xend = 1.8, y = -Inf, yend = dnorm(1.8, 0, 1),\n           linetype = 21) +\n  annotate(geom = \"label\", x = 1.8, y = 0.01, label = \"Actual y\", fontface = \"bold\") +\n  xlim(c(-4, 4)) +\n  theme(axis.text = element_blank(), axis.ticks = element_blank()) +\n  labs(x = \"Posterior predictive distribution for a single Y′\", y = \"Density\",\n       title = \"Scenario 2\")\n\np1 | p2\n\n\n\n\nIn this case, scenario 1 is better and more accurate—the actual observed value of y fits more nicely in the posterior predictive distribution for that y. We can assign a numerical value to the length of that line (or the value of the pdf at that point). For whatever reason, Bayesians log that distance, so we want the average log posterior predictive density at each new data point. We do this with leave-one-out CV (using the one hold-out data point as the actual data in the scenario above).\nThese ELPD values are on a weird meaningless scale that you can’t really interpret directly. You can compare them across models, though, and higher is better.\nCalculating the log likelihood is tricky and has to be defined in the Stan model. rstanarm and brms handle this automatically; with raw Stan, it has to be done in the generated quantities block (like Monica Alexander does here)\n\nrstanarmbrmsStan\n\n\n\nloo(bike_rstanarm)\n## \n## Computed from 20000 by 500 log-likelihood matrix\n## \n##          Estimate   SE\n## elpd_loo  -4289.0 13.1\n## p_loo         2.5  0.2\n## looic      8578.1 26.2\n## ------\n## Monte Carlo SE of elpd_loo is 0.0.\n## \n## All Pareto k estimates are good (k < 0.5).\n## See help('pareto-k-diagnostic') for details.\n\n\n\n\nloo(bike_brms)\n## \n## Computed from 20000 by 500 log-likelihood matrix\n## \n##          Estimate   SE\n## elpd_loo  -4289.0 13.1\n## p_loo         2.5  0.2\n## looic      8578.0 26.2\n## ------\n## Monte Carlo SE of elpd_loo is 0.0.\n## \n## All Pareto k estimates are good (k < 0.5).\n## See help('pareto-k-diagnostic') for details.\n\n\n\n\nbike_stan_samples$loo()\n## \n## Computed from 20000 by 500 log-likelihood matrix\n## \n##          Estimate   SE\n## elpd_loo  -4289.0 13.1\n## p_loo         2.5  0.2\n## looic      8578.0 26.2\n## ------\n## Monte Carlo SE of elpd_loo is 0.0.\n## \n## All Pareto k estimates are good (k < 0.5).\n## See help('pareto-k-diagnostic') for details."
  },
  {
    "objectID": "bayes-rules/10-chapter.html#how-good-is-the-mcmc-simulation-vs.-how-good-is-the-model",
    "href": "bayes-rules/10-chapter.html#how-good-is-the-mcmc-simulation-vs.-how-good-is-the-model",
    "title": "Reading notes",
    "section": "10.4: How good is the MCMC simulation vs. how good is the model?",
    "text": "10.4: How good is the MCMC simulation vs. how good is the model?\nIn general with all these diagnostics, we’re exploring two different questions:\n\nHow good is the MCMC simulation? Is it long enough, are the chains well-mixed, does it converge, etc.?\nHow good is the model? Are the assumptions reasonable, is the model fair, and does it create good predictions?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bayesf22 Notebook",
    "section": "",
    "text": "My notebook for working through the readings and exercises in my Bayesian Statistics readings class in Fall 2022"
  },
  {
    "objectID": "rethinking/03-chapter.html",
    "href": "rethinking/03-chapter.html",
    "title": "Chapter 3 notes",
    "section": "",
    "text": "library(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\nlibrary(patchwork)\nlibrary(posterior)\nlibrary(broom.mixed)\n\nset.seed(1234)\nAssuming 9 globe tosses, 6 are water:\nOr in code:\nGiven this data, what’s the proportion of water on the globe?"
  },
  {
    "objectID": "rethinking/03-chapter.html#grid-approximation",
    "href": "rethinking/03-chapter.html#grid-approximation",
    "title": "Chapter 3 notes",
    "section": "Grid approximation",
    "text": "Grid approximation\nFor each possible value of \\(p\\), compute the product \\(\\operatorname{Pr}(W, L \\mid p) \\times \\operatorname{Pr}(p)\\). The relative sizes of each of those products are the posterior probabilities.\n\nBase R with Rethinking\n\nUniform flat prior\n\n# List of possible explanations of p to consider\np_grid <- seq(from = 0, to = 1, length.out = 10000)\nplot(p_grid, main = \"Possible proportions (p)\")\n#\n\n# Probability of each value of p\n# Super vague uniform prior: just 1 at each possible p\nprob_p_uniform <- rep(1, 10000)\nplot(prob_p_uniform, main = \"Uniform flat prior\")\n#\n\n# Probability of each proportion, given 6/9 water draws\nprob_data <- dbinom(6, size = 9, prob = p_grid)\n\n# Unnormalized posterior\nposterior_raw <- prob_data * prob_p_uniform\nplot(posterior_raw, main = \"Unnormalized posterior\")\n#\n\n# Normalized posterior that sums to 1\nposterior_normalized <- posterior_raw / sum(posterior_raw)\nplot(posterior_normalized, main = \"Normalized posterior\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeta prior\n\n# Beta distribution with 3 / (3 + 1)\nprob_p_beta <- dbeta(p_grid, shape1 = 3, shape2 = 1)\nplot(prob_p_beta, main = \"Beta(3, 1) prior\")\n#\n# Posterior that sums to 1\nposterior_normalized_beta <- (prob_data * prob_p_beta) / sum(posterior_raw)\nplot(posterior_normalized_beta, main = \"Normalized postiorior with beta prior\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidyverse style from Solomon Kurz\n\nglobe_tossing <- tibble(p_grid = seq(from = 0, to = 1, length.out = 1001),\n                        prior_uniform = 1) %>%  # prob_p_uniform from earlier\n  mutate(prior_beta = dbeta(p_grid, shape1 = 3, shape2 = 1)) %>%  # prob_p_beta from earlier\n  mutate(likelihood = dbinom(6, size = 9, prob = p_grid)) %>%   # prob_data from earlier\n  mutate(posterior_uniform = (likelihood * prior_uniform) / sum(likelihood * prior_uniform),\n         posterior_beta = (likelihood * prior_beta) / sum(likelihood * prior_beta))\nglobe_tossing\n## # A tibble: 1,001 × 6\n##    p_grid prior_uniform prior_beta likelihood posterior_uniform posterior_beta\n##     <dbl>         <dbl>      <dbl>      <dbl>             <dbl>          <dbl>\n##  1  0                 1  0           0                 0              0       \n##  2  0.001             1  0.000003    8.37e-17          8.37e-19       1.97e-24\n##  3  0.002             1  0.000012    5.34e-15          5.34e-17       5.04e-22\n##  4  0.003             1  0.0000270   6.07e-14          6.07e-16       1.29e-20\n##  5  0.004             1  0.000048    3.40e-13          3.40e-15       1.28e-19\n##  6  0.005             1  0.000075    1.29e-12          1.29e-14       7.62e-19\n##  7  0.006             1  0.000108    3.85e-12          3.85e-14       3.27e-18\n##  8  0.007             1  0.000147    9.68e-12          9.68e-14       1.12e-17\n##  9  0.008             1  0.000192    2.15e-11          2.15e-13       3.24e-17\n## 10  0.009             1  0.000243    4.34e-11          4.34e-13       8.30e-17\n## # … with 991 more rows\n\n\nglobe_tossing %>% \n  pivot_longer(starts_with(\"posterior\")) %>% \n  ggplot(aes(x = p_grid, y = value, fill = name)) +\n  geom_area(position = position_identity(), alpha = 0.5)"
  },
  {
    "objectID": "rethinking/03-chapter.html#working-with-the-posterior",
    "href": "rethinking/03-chapter.html#working-with-the-posterior",
    "title": "Chapter 3 notes",
    "section": "Working with the posterior",
    "text": "Working with the posterior\nWe now have a posterior! We typically can’t use the posterior alone. We have to average any inference across the entire posterior. This requires calculus, which is (1) hard, and (2) often impossible. So instead, we can use samples from the distribution and make inferences based on those.\n\n3.2: Sampling to summarize\nHere are 10,000 samples from the posterior (based on the uniform flat prior). These are the sampling distributions.\n\nsamples <- sample(p_grid, prob = posterior_normalized, size = 10000, replace = TRUE)\nplot(samples, main = \"10,000 posterior samples\")\n#\n\nplot(density(samples), main = \"Distribution of 10,000 posterior samples\")\n\n\n\n\n\n\n\n\n\n\n\n\nsamples_tidy <- globe_tossing %>% \n  slice_sample(n = 10000, weight_by = posterior_uniform, replace = T)\n\n\n3.2.1: Intervals of defined boundaries\n\nBase RTidyverse\n\n\nWhat’s the probability that the proportion of water is less than 50%?\n\nsum(samples < 0.5) / 10000\n## [1] 0.1745\n\nHow much of the posterior is between 50% and 75%?\n\nsum(samples > 0.5 & samples < 0.75) / 10000\n## [1] 0.6037\n\n\n\nWhat’s the probability that the proportion of water is less than 50%?\n\nglobe_tossing %>% \n  ggplot(aes(x = p_grid, y = posterior_uniform)) +\n  geom_line() +\n  geom_area(data = filter(globe_tossing, p_grid < 0.5))\n\n\n\n\nsamples_tidy %>% \n  count(p_grid < 0.5) %>% \n  mutate(probability = n / sum(n))\n## # A tibble: 2 × 3\n##   `p_grid < 0.5`     n probability\n##   <lgl>          <int>       <dbl>\n## 1 FALSE           8321       0.832\n## 2 TRUE            1679       0.168\n\nHow much of the posterior is between 50% and 75%?\n\nglobe_tossing %>% \n  ggplot(aes(x = p_grid, y = posterior_uniform)) +\n  geom_line() +\n  geom_area(data = filter(globe_tossing, p_grid > 0.5 & p_grid < 0.75))\n\n\n\n\nsamples_tidy %>% \n  count(p_grid > 0.5 & p_grid < 0.75) %>% \n  mutate(probability = n / sum(n))\n## # A tibble: 2 × 3\n##   `p_grid > 0.5 & p_grid < 0.75`     n probability\n##   <lgl>                          <int>       <dbl>\n## 1 FALSE                           4000         0.4\n## 2 TRUE                            6000         0.6\n\n\n\n\n\n\n3.2.2: Intervals of defined mass\n\nBase RTidyverse\n\n\nLower 80% posterior probability lies below this number:\n\nquantile(samples, 0.8)\n##      80% \n## 0.759576\n\nMiddle 80% posterior probability lies between these numbers:\n\nquantile(samples, c(0.1, 0.9))\n##       10%       90% \n## 0.4448445 0.8106911\n\n50% percentile interval vs. 50% HPDI\n\nquantile(samples, c(0.25, 0.75))\n##       25%       75% \n## 0.5416292 0.7387989\nrethinking::HPDI(samples, prob = 0.5)\n##      |0.5      0.5| \n## 0.5659566 0.7592759\n\n\n\nLower 80% posterior probability lies below this number:\n\nsamples_tidy %>% \n  summarize(`80th percentile` = quantile(p_grid, 0.8))\n## # A tibble: 1 × 1\n##   `80th percentile`\n##               <dbl>\n## 1             0.762\n\nMiddle 80% posterior probability lies between these numbers:\n\nsamples_tidy %>% \n  summarize(q = c(0.1, 0.9), percentile = quantile(p_grid, q)) %>% \n  pivot_wider(names_from = q, values_from = percentile)\n## # A tibble: 1 × 2\n##   `0.1` `0.9`\n##   <dbl> <dbl>\n## 1  0.45 0.811\n\n50% percentile interval vs. 50% HPDI\n\nsamples_tidy %>% \n  summarize(q = c(0.25, 0.75), \n            percentile = quantile(p_grid, q),\n            hpdi = HDInterval::hdi(p_grid, 0.5))\n## # A tibble: 2 × 3\n##       q percentile  hpdi\n##   <dbl>      <dbl> <dbl>\n## 1  0.25      0.544 0.563\n## 2  0.75      0.742 0.756\n\n\n\n\n\n\n3.2.3: Point estimates\n\nBase RTidyverse\n\n\n\nmean(samples)\n## [1] 0.6352952\nmedian(samples)\n## [1] 0.6448645\n\n\n\n\nsamples_tidy %>% \n  summarize(mean = mean(p_grid),\n            median = median(p_grid))\n## # A tibble: 1 × 2\n##    mean median\n##   <dbl>  <dbl>\n## 1 0.638  0.646\n\n\n\n\n\n\n\n3.3: Sampling to simulate prediction\n\nBase R\nWe can use the uncertainty inherent in the sampling distributions from above to generate a posterior predictive distribution, based on a 9-toss situation:\n\n# Posterior predictive distribution\nposterior_predictive_dist <- rbinom(10000, size = 9, prob = samples)\nhist(posterior_predictive_dist, breaks = 0:9)\n\n\n\n\n\n\nTidyverse style\n\n# Generate 100,000 samples from the posterior\nsamples_tidy <- globe_tossing %>% \n  slice_sample(n = 100000, weight_by = posterior_uniform, replace = T)\n#\nsamples_tidy %>% \n  mutate(sample_number = 1:n()) %>% \n  ggplot(aes(x = sample_number, y = p_grid)) +\n  geom_point(alpha = 0.05) +\n  labs(title = \"100,000 posterior samples\", x = \"Sample number\")\n#\nsamples_tidy %>% \n  ggplot(aes(x = p_grid)) +\n  geom_density(fill = \"grey50\", color = NA) +\n  labs(title = \"Distribution of 100,000 posterior samples\")\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.6 with ggplot\n\n# Posterior probability\nglobe_smaller <- globe_tossing %>% \n  filter(p_grid %in% c(seq(0.1, 0.9, 0.1), 0.3))\n\npanel_top <- globe_tossing %>% \n  ggplot(aes(x = p_grid, y = posterior_uniform)) + \n  geom_area(fill = \"grey50\", color = NA) +\n  geom_segment(data = globe_smaller, aes(xend = p_grid, yend = 0, size = posterior_uniform)) +\n  geom_point(data = globe_smaller) +\n  scale_size_continuous(range = c(0, 1), guide = \"none\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1)) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(x = \"Proportion/probability of water\",\n       title = \"Posterior probability\") +\n  theme(panel.grid = element_blank(),\n        plot.title = element_text(face = \"bold\"))\n\n# Sampling distributions\nglobe_sample_dists <- tibble(probability = seq(0.1, 0.9, 0.1)) %>% \n  mutate(draws = map(probability, ~{\n    set.seed(1234)\n    rbinom(10000, size = 9, prob = .x)\n  })) %>% \n  unnest(draws) %>% \n  mutate(label = paste0(\"p = \", probability))\n\npanel_middle <- ggplot(globe_sample_dists, aes(x = draws)) +\n  geom_histogram(binwidth = 1, center = 0, color = \"white\", size = 0.1) +\n  scale_x_continuous(breaks = seq(0, 9, 3)) +\n  scale_y_continuous(breaks = NULL) +\n  coord_cartesian(xlim = c(0, 9)) +\n  labs(x = NULL, y = NULL, title = \"Sampling distributions\") +\n  theme(panel.grid = element_blank(),\n        plot.title = element_text(face = \"bold\")) +\n  facet_wrap(vars(label), ncol = 9)\n\n# Posterior predictive distribution\nglobe_samples <- globe_tossing %>% \n  slice_sample(n = 10000, weight_by = posterior_uniform, replace = TRUE) %>% \n  mutate(prediction = map_dbl(p_grid, rbinom, n = 1, size = 9))\n\npanel_bottom <- globe_samples %>% \n  ggplot(aes(x = prediction)) +\n  geom_histogram(binwidth = 1, center = 0, color = \"white\", size = 0.5) +\n  scale_x_continuous(breaks = seq(0, 9, 3)) +\n  scale_y_continuous(breaks = NULL) +\n  coord_cartesian(xlim = c(0, 9)) +\n  labs(x = \"Number of water samples\", y = NULL, title = \"Posterior predictive distribution\") +\n  theme(panel.grid = element_blank(),\n        plot.title = element_text(face = \"bold\"))\n\nlayout <- \"\nAAAAAAAAAAA\n#BBBBBBBBB#\n###CCCCC###\n\"\n\npanel_top / panel_middle / panel_bottom +\n  plot_layout(design = layout)"
  },
  {
    "objectID": "rethinking/03-chapter.html#brms-and-tidybayes-version-of-all-this",
    "href": "rethinking/03-chapter.html#brms-and-tidybayes-version-of-all-this",
    "title": "Chapter 3 notes",
    "section": "brms and tidybayes version of all this",
    "text": "brms and tidybayes version of all this\nOoh neat, you can pass single values as data instead of a data frame! Everything else here looks like regular brms stuff.\n\nmodel_globe <- brm(\n  bf(water | trials(9) ~ 0 + Intercept),\n  data = list(water = 6),\n  family = binomial(link = \"identity\"),\n  # Flat uniform prior\n  prior(beta(1, 1), class = b, lb = 0, ub = 1),\n  iter = 5000, warmup = 1000, seed = 1234,\n  # TODO: Eventually switch to cmdstanr once this issue is fixed\n  # https://github.com/quarto-dev/quarto-cli/issues/2258\n  backend = \"rstan\", cores = 4\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\nCredible intervals / HPDI / etc.\n\n# Using broom.mixed\ntidy(model_globe, effects = \"fixed\",\n     conf.level = 0.5, conf.method = \"HPDinterval\")\n## # A tibble: 1 × 7\n##   effect component term        estimate std.error conf.low conf.high\n##   <chr>  <chr>     <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n## 1 fixed  cond      (Intercept)    0.639     0.137    0.568     0.761\n\n# Using the posterior package\ndraws <- as_draws_array(model_globe)\nsummarize_draws(draws, default_summary_measures()) %>% \n  filter(variable == \"b_Intercept\")\n## # A tibble: 1 × 7\n##   variable     mean median    sd   mad    q5   q95\n##   <chr>       <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>\n## 1 b_Intercept 0.639  0.648 0.137 0.144 0.400 0.848\n\n# Using tidybayes\n# get_variables(model_globe)\nmodel_globe %>% \n  spread_draws(b_Intercept) %>% \n  median_hdci(b_Intercept, .width = c(0.5, 0.89, 0.95))\n## # A tibble: 3 × 6\n##   b_Intercept .lower .upper .width .point .interval\n##         <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1       0.648  0.568  0.761   0.5  median hdci     \n## 2       0.648  0.430  0.864   0.89 median hdci     \n## 3       0.648  0.374  0.892   0.95 median hdci\n\nmodel_globe %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value, y = .variable)) +\n  stat_halfeye()\n\n\n\n\nPredictions\n\nmodel_globe %>% \n  predicted_draws(newdata = tibble(nothing = 1)) %>% \n  ggplot(aes(x = .prediction)) +\n  geom_histogram(binwidth = 1, center = 0, color = \"white\", size = 0.5) +\n  scale_x_continuous(breaks = seq(0, 9, 3)) +\n  scale_y_continuous(breaks = NULL) +\n  coord_cartesian(xlim = c(0, 9)) +\n  labs(x = \"Number of water samples\", y = NULL, title = \"Posterior predictive distribution\") +\n  theme(panel.grid = element_blank(),\n        plot.title = element_text(face = \"bold\"))"
  },
  {
    "objectID": "rethinking/03-practice.html",
    "href": "rethinking/03-practice.html",
    "title": "Chapter 3 exercises",
    "section": "",
    "text": "library(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\nlibrary(ggdist)\nlibrary(broom.mixed)\nlibrary(glue)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nBAYES_SEED <- 1234\nset.seed(1234)\nThis births data shows the sex of the first and second children born to 100 different families (1 = boy, 2 = girl). The first family had a boy then a girl, the second had a girl and then a boy, the thrid had no boys, etc.\nIn these exercises we don’t care about birth order, so we’ll pool all the births into one long 200-birth vector:\nWhat proportion of births were boys?"
  },
  {
    "objectID": "rethinking/03-practice.html#h1",
    "href": "rethinking/03-practice.html#h1",
    "title": "Chapter 3 exercises",
    "section": "3H1",
    "text": "3H1\n\nUsing grid approximation, compute the posterior distribution for the probability of being a boy. Assume a uniform prior probability. Which parameter value maximizes the posterior probability?\n\n\nbirth_grid <- tibble(p_grid = seq(0, 1, length.out = 1001),\n                     prior_uniform = 1) %>% \n  mutate(likelihood = dbinom(n_boys, size = total_births, prob = p_grid)) %>% \n  mutate(posterior_uniform = (likelihood * prior_uniform) / sum(likelihood * prior_uniform))\nbirth_grid\n## # A tibble: 1,001 × 4\n##    p_grid prior_uniform likelihood posterior_uniform\n##     <dbl>         <dbl>      <dbl>             <dbl>\n##  1  0                 1  0                 0        \n##  2  0.001             1  2.48e-275         4.98e-276\n##  3  0.002             1  5.89e-242         1.18e-242\n##  4  0.003             1  1.89e-222         3.81e-223\n##  5  0.004             1  1.28e-208         2.57e-209\n##  6  0.005             1  6.68e-198         1.34e-198\n##  7  0.006             1  3.76e-189         7.56e-190\n##  8  0.007             1  9.28e-182         1.86e-182\n##  9  0.008             1  2.32e-175         4.66e-176\n## 10  0.009             1  1.01e-169         2.03e-170\n## # … with 991 more rows\n\n\nbirth_grid %>% \n  ggplot(aes(x = p_grid, y = posterior_uniform)) +\n  geom_area(fill = clrs[6])\n\n\n\n\nParameter that maximizes the probability:\n\nbirth_grid %>% \n  filter(posterior_uniform == max(posterior_uniform))\n## # A tibble: 1 × 4\n##   p_grid prior_uniform likelihood posterior_uniform\n##    <dbl>         <dbl>      <dbl>             <dbl>\n## 1  0.555             1     0.0567            0.0114\n\n\nWith brms\n\nmodel_births <- brm(\n  bf(boy | trials(total_births) ~ 0 + Intercept),\n  data = list(boy = n_boys, total_births = total_births),\n  family = binomial(link = \"identity\"),\n  prior = prior(beta(1, 1), class = b, lb = 0, ub = 1),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, cores = 4\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\nmodel_births %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value, y = .variable)) +\n  stat_halfeye(fill = clrs[6])\n\n\n\n\n\nmodel_births %>% \n  gather_draws(b_Intercept) %>% \n  summarize(median = median(.value))\n## # A tibble: 1 × 2\n##   .variable   median\n##   <chr>        <dbl>\n## 1 b_Intercept  0.555"
  },
  {
    "objectID": "rethinking/03-practice.html#h2",
    "href": "rethinking/03-practice.html#h2",
    "title": "Chapter 3 exercises",
    "section": "3H2",
    "text": "3H2\n\nUsing the sample function, draw 10,000 random parameter values from the posterior distribution you calculated above. Use these samples to estimate the 50%, 89%, and 97% highest posterior density intervals.\n\n\nbirth_samples <- sample(birth_grid$p_grid, prob = birth_grid$posterior_uniform, \n                        size = 10000, replace = TRUE)\n\ntibble(x = birth_samples) %>% \n  ggplot(aes(x = x)) +\n  stat_slab(\n    aes(fill_ramp = stat(level)),\n        .width = c(0.02, 0.5, 0.89, 0.97, 1),\n    fill = clrs[3]\n  ) +\n  scale_fill_ramp_discrete(range = c(0.2, 1), guide = \"none\")\n\n\n\n\nHDInterval::hdi(birth_samples, credMass = 0.5)\n## lower upper \n## 0.530 0.577 \n## attr(,\"credMass\")\n## [1] 0.5\nHDInterval::hdi(birth_samples, credMass = 0.89)\n## lower upper \n## 0.494 0.605 \n## attr(,\"credMass\")\n## [1] 0.89\nHDInterval::hdi(birth_samples, credMass = 0.97)\n## lower upper \n## 0.473 0.626 \n## attr(,\"credMass\")\n## [1] 0.97\n\n\nWith brms\n\nmodel_births %>% \n  spread_draws(b_Intercept) %>% \n  median_hdci(b_Intercept, .width = c(0.5, 0.89, 0.97))\n## # A tibble: 3 × 6\n##   b_Intercept .lower .upper .width .point .interval\n##         <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1       0.555  0.532  0.578   0.5  median hdci     \n## 2       0.555  0.501  0.612   0.89 median hdci     \n## 3       0.555  0.480  0.629   0.97 median hdci\n\n\nmodel_births %>% \n  tidy_draws() %>% \n  ggplot(aes(x = b_Intercept)) +\n  stat_slab(\n    aes(fill_ramp = stat(level)),\n        .width = c(0.02, 0.5, 0.89, 0.97, 1),\n    fill = clrs[3]\n  ) +\n  scale_fill_ramp_discrete(range = c(0.2, 1), guide = \"none\")"
  },
  {
    "objectID": "rethinking/03-practice.html#h3",
    "href": "rethinking/03-practice.html#h3",
    "title": "Chapter 3 exercises",
    "section": "3H3",
    "text": "3H3\n\nUse rbinom to simulate 10,000 replicates of 200 births. You should end up with 10,000 numbers, each one a acount of boyts out of 200 births. Compare the distribution of predicted numbers of boys to the actual count in the data (111 boys out of 200 births). … Does it look like the model fits the data well? That is, does the distribution of predcitions include the actual observation as a central, likely outcome?\n\nLooks good!\n\n# Posterior predictive distribution\nposterior_pred_births <- rbinom(10000, size = 200, prob = birth_samples)\n\nposterior_pred_births %>% \n  enframe() %>% \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = 2, color = \"white\", size = 0.25, fill = clrs[1]) +\n  geom_vline(xintercept = n_boys, color = \"red\") +\n  labs(caption = glue(\"Red line shows actual observed number of boys ({n_boys})\"))\n\n\n\n\n\nWith brms\n\nmodel_births %>% \n  predicted_draws(newdata = tibble(total_births = 200)) %>% \n  ggplot(aes(x = .prediction)) +\n  geom_histogram(binwidth = 2, color = \"white\", size = 0.25, fill = clrs[1]) +\n  geom_vline(xintercept = n_boys, color = \"red\") +\n  labs(caption = glue(\"Red line shows actual observed number of boys ({n_boys})\"))"
  },
  {
    "objectID": "rethinking/03-practice.html#h4",
    "href": "rethinking/03-practice.html#h4",
    "title": "Chapter 3 exercises",
    "section": "3H4",
    "text": "3H4\n\nNow compare 10,000 counts of boys from 100 simulated first borns only to the number of boys in the first births, birth1. How does the model look in this light?\n\nWe need to just look at first births:\n\nn_boys_first <- sum(birth1)\ntotal_births_first <- length(birth1)\n\nbirth_grid_first <- tibble(p_grid = seq(0, 1, length.out = 1001),\n                           prior_uniform = 1) %>% \n  mutate(likelihood = dbinom(n_boys_first, size = total_births_first, prob = p_grid)) %>% \n  mutate(posterior_uniform = (likelihood * prior_uniform) / sum(likelihood * prior_uniform))\n\nfirst_samples <- sample(birth_grid_first$p_grid, prob = birth_grid_first$posterior_uniform, \n                        size = 10000, replace = TRUE)\n\nposterior_pred_first <- rbinom(10000, size = 100, prob = first_samples)\n\nposterior_pred_first %>% \n  enframe() %>% \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = 2, color = \"white\", size = 0.25, fill = clrs[6]) +\n  geom_vline(xintercept = n_boys_first, color = \"red\") +\n  labs(caption = glue(\"Red line shows actual observed number of firstborn boys ({n_boys_first})\"))\n\n\n\n\nLooks good still!\n\nmodel_births_first <- brm(\n  bf(boy | trials(total_births) ~ 0 + Intercept),\n  data = list(boy = n_boys_first, total_births = total_births_first),\n  family = binomial(link = \"identity\"),\n  prior = prior(beta(1, 1), class = b, lb = 0, ub = 1),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, cores = 4\n)\n## Compiling Stan program...\n## recompiling to avoid crashing R session\n## Trying to compile a simple C file\n## Start sampling\n\n\nWith brms\nLooks the same with brms too:\n\nmodel_births_first %>% \n  predicted_draws(newdata = tibble(total_births = 100)) %>% \n  ggplot(aes(x = .prediction)) +\n  geom_histogram(binwidth = 2, color = \"white\", size = 0.25, fill = clrs[6]) +\n  geom_vline(xintercept = n_boys_first, color = \"red\") +\n  labs(caption = glue(\"Red line shows actual observed number of firstborn boys ({n_boys_first})\"))"
  },
  {
    "objectID": "rethinking/03-practice.html#h5",
    "href": "rethinking/03-practice.html#h5",
    "title": "Chapter 3 exercises",
    "section": "3H5",
    "text": "3H5\n\nThe model assumes that sex of first and second births are independent. To check this assumption, focus now on second births that followed female first borns. Compare 10,000 simulated conts of boys to only those second births that followed girls. To do this correctly, you need to count the number of first borns who were girls and simulate that many births, 10,000 times. Compare the counts of boys in your simulations to the actual observed count of boys following girls. How does the model look in this light? Any guesses what is going on in these data?\n\n\nn_girls_first <- length(birth1) - sum(birth1)\nn_boys_after_girls <- all_births %>%\n  filter(birth1 == 0) %>%  # All families with a firstborn girl\n  summarize(boy_after_girl = sum(birth2)) %>% \n  pull(boy_after_girl)\n\nposterior_pred_first_girl <- rbinom(10000, size = n_girls_first, prob = first_samples)\n\nposterior_pred_first_girl %>% \n  enframe() %>% \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = 2, color = \"white\", size = 0.25, fill = clrs[5]) +\n  geom_vline(xintercept = n_boys_after_girls, color = \"red\") +\n  labs(caption = glue(\"Red line shows actual observed number of boys born after girls ({n_boys_after_girls})\"))\n\n\n\n\n\nWith brms\n\nmodel_births_first_girls <- brm(\n  bf(girl | trials(total_births) ~ 0 + Intercept),\n  data = list(girl = n_girls_first, total_births = total_births_first),\n  family = binomial(link = \"identity\"),\n  prior = prior(beta(1, 1), class = b, lb = 0, ub = 1),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, cores = 4\n)\n## Compiling Stan program...\n## recompiling to avoid crashing R session\n## Trying to compile a simple C file\n## Start sampling\n\n\nmodel_births_first_girls %>% \n  predicted_draws(newdata = tibble(total_births = n_girls_first)) %>% \n  ggplot(aes(x = .prediction)) +\n  geom_histogram(binwidth = 2, color = \"white\", size = 0.25, fill = clrs[5]) +\n  geom_vline(xintercept = n_boys_after_girls, color = \"red\") +\n  labs(caption = glue(\"Red line shows actual observed number of boys born after girls ({n_boys_after_girls})\"))"
  },
  {
    "objectID": "rethinking/03-video.html#linear-regression",
    "href": "rethinking/03-video.html#linear-regression",
    "title": "Video #3 code",
    "section": "Linear regression",
    "text": "Linear regression\nThe general process for drawing the linear regression owl:\n\nQuestion/goal/estimand\nScientific model\nStatistical model(s)\nValidate model\nAnalyze data\n\n\n1. Question/goal/estimand\nWe want to describe the association between adult weight and height\n\nggplot(d, aes(x = height, y = weight)) +\n  geom_point(color = clrs[3])\n\n\n\n\n\n\n2. Scientific model\nHow does height influence weight?\nHeight has a causal relationship with weight:\n\\[\nH \\rightarrow W\n\\]\nWeight is a function of height. Plug in some value of height, get some weight:\n\\[\nW = f(H)\n\\]\nWe need to write down that model somehow. The normal \\(y = mx + b\\) way of writing a linear model looks like this, where \\(\\alpha\\) is the intercept and \\(\\beta\\) is the slope:\n\\[\ny_i = \\alpha + \\beta x_i\n\\]\nWe can also write it like this, where \\(\\mu\\) is the expectation (\\(E(y \\mid x) = \\mu\\)), and \\(\\sigma\\) is the standard deviation:\n\\[\n\\begin{aligned}\ny_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta x_i\n\\end{aligned}\n\\]\nSo, we can think of a generative model for height causing weight like this:\n\\[\n\\begin{aligned}\nW_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta H_i\n\\end{aligned}\n\\]\nThis can map directly to code:\n\nset.seed(1234)\n\nalpha <- 0\nbeta <- 0.5\nsigma <- 5\nn_individuals <- 100\n\nfake_people <- tibble(height = runif(n_individuals, 130, 170),\n                      mu = alpha + beta*height,\n                      weight = rnorm(n_individuals, mu, sigma))\n\nlm(weight ~ height, data = fake_people) %>% \n  tidy()\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)    1.22     6.37       0.191 8.49e- 1\n## 2 height         0.494    0.0431    11.5   7.64e-20\n\nggplot(fake_people, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n3: Statistical model\n\nSimulating and checking the priors\nWe don’t actually know \\(\\alpha\\), \\(\\beta\\), and \\(\\sigma\\) - they all have priors and limits and bounds. For instance, \\(\\sigma\\) is a scale parameter - it shifts distributions up and down - it has to be positive (hence the uniform distribution here). We can write a generic model like this:\n\\[\n\\begin{aligned}\ny_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta x_i \\\\\n\\\\\n\\alpha &\\sim \\mathcal{N}(0, 1) \\\\\n\\beta &\\sim \\mathcal{N}(0, 1) \\\\\n\\sigma &\\sim \\operatorname{Uniform}(0, 1)\n\\end{aligned}\n\\]\nBut if we sample from that prior distribution, we get lines that are all over the place!\n\nset.seed(1234)\n\nn_samples <- 10\n\ntibble(alpha = rnorm(n_samples, 0, 1),\n       beta = rnorm(n_samples, 0, 1)) %>% \n  ggplot() +\n  geom_abline(aes(slope = beta, intercept = alpha)) +\n  xlim(c(-2, 2)) + ylim(c(-2, 2))\n\n\n\n\nInstead, we can set some more specific priors and rescale variables so that the intercept makes more sense.\n\\[\n\\begin{aligned}\nW_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta (H_i - \\bar{H}) \\\\\n\\\\\n\\alpha &\\sim \\mathcal{N}(60, 10) \\\\\n\\beta &\\sim \\mathcal{N}(0, 10) \\\\\n\\sigma &\\sim \\operatorname{Uniform}(0, 10)\n\\end{aligned}\n\\]\nHere’s what those priors look like:\n\nPlain old ggplotbrms::prior() and ggdist::parse_dist()\n\n\n\nplot_prior_alpha <- ggplot() +\n  stat_function(fun = ~dnorm(., 60, 10), geom = \"area\", fill = clrs[1]) +\n  xlim(c(30, 90)) +\n  labs(title = \"Normal(60, 10)\", subtitle = \"Prior for intercept (α)\", caption = \"Average adult weight\")\n\nplot_prior_beta <- ggplot() +\n  stat_function(fun = ~dnorm(., 0, 10), geom = \"area\", fill = clrs[2]) +\n  xlim(c(-30, 30)) +\n  labs(title = \"Normal(0, 10)\", subtitle = \"Prior for slope (β)\", caption = \"kg per cm\")\n\nplot_prior_sigma <- ggplot() +\n  stat_function(fun = ~dunif(., 0, 10), geom = \"area\", fill = clrs[3]) +\n  xlim(c(0, 10)) +\n  labs(title = \"Uniform(0, 10)\", subtitle = \"Prior for sd (σ)\")\n\nplot_prior_alpha | plot_prior_beta | plot_prior_sigma\n\n\n\n\n\n\n\npriors <- c(prior(normal(60, 10), class = Intercept),\n            prior(normal(0, 10), class = b),\n            prior(uniform(0, 10), class = sigma, lb = 0, ub = 10))\n\npriors %>% \n  parse_dist() %>% \n  ggplot(aes(y = 0, dist = .dist, args = .args, fill = prior)) +\n  stat_slab() +\n  scale_fill_manual(values = clrs[1:3]) +\n  facet_wrap(vars(prior), scales = \"free\")\n\n\n\n\n\n\n\nLet’s see how well those priors work!\n\nManual plottingbrms and sample_prior = \"only\"\n\n\n\nset.seed(1234)\n\nn <- 100\nHbar <- 150\nHseq <- seq(130, 170, length.out = 30)\n\ntibble(alpha = rnorm(n, 60, 10),\n       beta = rnorm(n, 0, 10)) %>% \n  mutate(weight = map2(alpha, beta, ~.x + .y*(Hseq - Hbar)),\n         height = list(Hseq),\n         id = 1:n) %>% \n  unnest(c(weight, height)) %>% \n  ggplot(aes(x = height, y = weight)) + \n  geom_line(aes(group = id), alpha = 0.2) +\n  coord_cartesian(xlim = c(130, 170), ylim = c(10, 100))\n\n\n\n\n\n\n\npriors <- c(prior(normal(60, 10), class = Intercept),\n            prior(normal(0, 10), class = b),\n            prior(uniform(0, 10), class = sigma, lb = 0, ub = 10))\n\nheight_weight_prior_only_normal <- brm(\n  bf(weight ~ 1 + height_z),\n  data = d,\n  family = gaussian(),\n  prior = priors,\n  sample_prior = \"only\"\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\ndraws_prior <- tibble(height_z = seq((130 - height_scale$scaled_center) / height_scale$scaled_scale, \n                                     (170 - height_scale$scaled_center) / height_scale$scaled_scale, \n                                     length.out = 100)) %>% \n  add_epred_draws(height_weight_prior_only_normal, ndraws = 100) %>% \n  mutate(height_unscaled = (height_z * height_scale$scaled_scale) + height_scale$scaled_center)\n\ndraws_prior %>% \n  ggplot(aes(x = height_unscaled, y = .epred)) +\n  geom_line(aes(group = .draw), alpha = 0.2) +\n  coord_cartesian(xlim = c(130, 170), ylim = c(10, 100))\n\n\n\n\n\n\n\nLots of those lines are completely implausible, so we’ll use a lognormal β prior instead:\n\\[\n\\begin{aligned}\nW_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta (H_i - \\bar{H}) \\\\\n\\\\\n\\alpha &\\sim \\mathcal{N}(60, 10) \\\\\n\\beta &\\sim \\operatorname{LogNormal}(0, 1) \\\\\n\\sigma &\\sim \\operatorname{Uniform}(0, 10)\n\\end{aligned}\n\\]\nThe lognormal distribution forces βs to be > 0 and it’s clusttered down at low values like 1ish:\n\nggplot() +\n  stat_function(fun = ~dlnorm(., 0, 1), geom = \"area\", fill = clrs[1]) +\n  xlim(c(0, 5)) +\n  labs(x = \"Simulated β values\", y = \"Density\")\n\n\n\n\n\nManual plottingbrms and sample_prior = \"only\"\n\n\n\nset.seed(1234)\n\nn <- 100\nHbar <- 150\nHseq <- seq(130, 170, length.out = 30)\n\ntibble(alpha = rnorm(n, 60, 10),\n       beta = rlnorm(n, 0, 1)) %>% \n  mutate(weight = map2(alpha, beta, ~.x + .y*(Hseq - Hbar)),\n         height = list(Hseq),\n         id = 1:n) %>% \n  unnest(c(weight, height)) %>% \n  ggplot(aes(x = height, y = weight)) + \n  geom_line(aes(group = id), alpha = 0.2) +\n  coord_cartesian(xlim = c(130, 170), ylim = c(10, 100))\n\n\n\n\n\n\n\npriors <- c(prior(normal(60, 10), class = Intercept),\n            prior(lognormal(0, 1), class = b, lb = 0),\n            prior(uniform(0, 10), class = sigma, lb = 0, ub = 10))\n\nheight_weight_prior_only_lognormal <- brm(\n  bf(weight ~ 1 + height_z),\n  data = d,\n  family = gaussian(),\n  prior = priors,\n  sample_prior = \"only\",\n  chains = 4, cores = 4, seed = BAYES_SEED\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\ndraws_prior <- tibble(height_z = seq((130 - height_scale$scaled_center) / height_scale$scaled_scale, \n                                     (170 - height_scale$scaled_center) / height_scale$scaled_scale, \n                                     length.out = 100)) %>% \n  add_epred_draws(height_weight_prior_only_lognormal, ndraws = 100) %>% \n  mutate(height_unscaled = (height_z * height_scale$scaled_scale) + height_scale$scaled_center)\n\ndraws_prior %>% \n  ggplot(aes(x = height_unscaled, y = .epred)) +\n  geom_line(aes(group = .draw), alpha = 0.2) +\n  coord_cartesian(xlim = c(130, 170), ylim = c(10, 100))\n\n\n\n\n\n\n\n\n\nFitting the model\nFitting the model is super complex because it’s the joint posterior of all those distributions:\n\\[\n\\begin{aligned}\n\\operatorname{Pr}(\\alpha, \\beta, \\sigma \\mid W, H) \\propto~ & \\mathcal{N}(W \\mid \\mu, \\sigma) \\\\\n&\\times \\mathcal{N}(\\alpha \\mid 60, 10) \\\\\n&\\times \\operatorname{LogNormal}(\\beta \\mid 0, 1) \\\\\n&\\times \\operatorname{Uniform}(\\sigma \\mid 0, 10)\n\\end{aligned}\n\\]\nIf we do this with grid approximation, 100 values of each parameter = 1 million calculations. In the book he shows it with grid approximation and with quadratic approximation.\nI’ll do it with brms and Stan instead.\n\nbrmsStan\n\n\n\npriors <- c(prior(normal(60, 10), class = Intercept),\n            prior(lognormal(0, 1), class = b, lb = 0),\n            prior(uniform(0, 10), class = sigma, lb = 0, ub = 10))\n\nheight_weight_lognormal <- brm(\n  bf(weight ~ 1 + height_z),\n  data = d,\n  family = gaussian(),\n  prior = priors,\n  chains = 4, cores = 4, seed = BAYES_SEED\n)\n## Compiling Stan program...\n## recompiling to avoid crashing R session\n## Trying to compile a simple C file\n## Start sampling\n\n\nprint(height_weight_lognormal)\n##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: weight ~ 1 + height_z \n##    Data: d (Number of observations: 346) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept    45.05      0.23    44.61    45.50 1.00     3979     3023\n## height_z      4.83      0.23     4.38     5.29 1.00     3802     2716\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     4.27      0.17     3.96     4.62 1.00     4119     2987\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\nThis is a little trickier because add_epred_draws() and predicted_draws() and all those nice functions don’t work with raw Stan samples, by design.\nInstead, we need to generate predictions that incorporate sigma using a generated quantities block in Stan (see the official Stan documentation and this official example and this neat blog post by Monica Alexander and this Medium post).\nHere we return two different but similar things: weight_rep[i] for the posterior predictive (which corresponds to predicted_draws() in tidybayes) and mu[i] for the expectation of the posterior predictive (which corresponds to epred_draws() in tidybayes):\n\ndata {\n  // Stuff from R\n  int<lower=1> n;\n  vector[n] height;  // Explanatory variable\n  vector[n] weight;  // Outcome variable\n  real height_bar;   // Average height\n}\n\nparameters {\n  // Things to estimate\n  real<lower=0, upper=10> sigma;\n  real beta;\n  real alpha;\n}\n\ntransformed parameters {\n  // Regression-y model of mu with scaled height\n  vector[n] mu;\n  mu = alpha + beta * (height - height_bar);\n}\n\nmodel {\n  // Likelihood\n  weight ~ normal(mu, sigma);\n  \n  // Priors\n  alpha ~ normal(60, 10);\n  beta ~ lognormal(0, 1);\n  sigma ~ uniform(0, 10);\n}\n\ngenerated quantities {\n  // Generate a posterior predictive distribution\n  vector[n] weight_rep;\n\n  for (i in 1:n) {\n    // Calculate a new predicted mu for each iteration here\n    real mu_hat_n = alpha + beta * (height[i] - height_bar);\n    weight_rep[i] = normal_rng(mu_hat_n, sigma);\n    \n    // Alternatively, we can use mu[i] from the transformed parameters\n    // weight_rep[i] = normal_rng(mu[i], sigma);\n  }\n}\n\n\n# compose_data listifies things for Stan\n# stan_data <- d %>% compose_data()\n# stan_data$height_bar <- mean(stan_data$height)\n\n# Or we can manually build the list\nstan_data <- list(n = nrow(d),\n                  weight = d$weight,\n                  height = d$height,\n                  height_bar = mean(d$height))\n\nmodel_lognormal_stan <- rstan::sampling(\n  object = lognormal_stan,\n  data = stan_data,\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, chains = 4, cores = 4\n)\n\n\nprint(model_lognormal_stan, \n      pars = c(\"sigma\", \"beta\", \"alpha\", \"mu[1]\", \"mu[2]\"))\n## Inference for Stan model: 3c0d0064926253eea8547fd513e8019e.\n## 4 chains, each with iter=5000; warmup=1000; thin=1; \n## post-warmup draws per chain=4000, total post-warmup draws=16000.\n## \n##        mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\n## sigma  4.27       0 0.16  3.97  4.16  4.27  4.38  4.60 13529    1\n## beta   0.62       0 0.03  0.57  0.60  0.62  0.64  0.68 15170    1\n## alpha 45.06       0 0.23 44.61 44.90 45.05 45.21 45.51 15781    1\n## mu[1] 43.26       0 0.24 42.78 43.09 43.26 43.42 43.74 15594    1\n## mu[2] 35.72       0 0.50 34.73 35.39 35.72 36.06 36.69 15326    1\n## \n## Samples were drawn using NUTS(diag_e) at Thu Sep  8 13:44:25 2022.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\n\n\n\n\n\n\n\n4 & 5: Validate model and analyze data\n\nbrmsStan\n\n\nExpectation of the posterior (plotting uncertainty of the mean):\n\ndraws_posterior_epred <- tibble(height_z = seq(min(d$height_z), max(d$height_z), length.out = 100)) %>% \n  add_epred_draws(height_weight_lognormal, ndraws = 50) %>% \n  mutate(height_unscaled = (height_z * height_scale$scaled_scale) + height_scale$scaled_center)\n\nggplot() +\n  geom_point(data = d, aes(x = height, y = weight), alpha = 0.5, size = 1) +\n  geom_line(data = draws_posterior_epred,\n            aes(x = height_unscaled, y = .epred, group = .draw), alpha = 0.2, color = clrs[6]) +\n  coord_cartesian(ylim = c(30, 65))\n\n\n\n\nPosterior predictions (plotting uncertainty of the predictions):\n\ndraws_posterior_pred <- tibble(height_z = seq(min(d$height_z), max(d$height_z), length.out = 500)) %>% \n  add_predicted_draws(height_weight_lognormal, ndraws = 100) %>%\n  mutate(height_unscaled = (height_z * height_scale$scaled_scale) + height_scale$scaled_center)\n\nggplot() +\n  geom_point(data = d, aes(x = height, y = weight), alpha = 0.5, size = 1) +\n  stat_lineribbon(data = draws_posterior_pred,\n                  aes(x = height_unscaled, y = .prediction), .width = 0.95, \n                  alpha = 0.2, color = clrs[5], fill = clrs[5]) +\n  coord_cartesian(ylim = c(30, 65))\n\n\n\n\nAnd here’s the posterior predictive check, just for fun:\n\npp_check(height_weight_lognormal, type = \"dens_overlay\", ndraws = 25)\n\n\n\n\n\n\nSummarized predictions:\n\npredicted_values_lognormal <- model_lognormal_stan %>% \n  spread_draws(mu[i], weight_rep[i]) %>%\n  mean_qi() %>%\n  mutate(weight = d$weight,\n         height = d$height)\n\nExpectation of the posterior (plotting uncertainty of the mean):\n\nggplot(predicted_values_lognormal, aes(x = height, y = weight)) +\n  geom_point(alpha = 0.5, size = 1) +\n  geom_line(aes(y = mu), color = clrs[6]) +\n  geom_ribbon(aes(ymin = mu.lower, ymax = mu.upper), alpha = 0.2, fill = clrs[6]) +\n  coord_cartesian(ylim = c(30, 65))\n\n\n\n\nPosterior predictions (plotting uncertainty of the predictions):\n\nggplot(predicted_values_lognormal, aes(x = height, y = weight)) +\n  geom_point(alpha = 0.5, size = 1) +\n  geom_line(aes(y = mu), color = clrs[5]) +\n  geom_ribbon(aes(ymin = weight_rep.lower, ymax = weight_rep.upper), alpha = 0.2, fill = clrs[5]) +\n  coord_cartesian(ylim = c(30, 65))\n\n\n\n\nAnd here’s the posterior predictive check, just for fun:\n\nyrep1 <- rstan::extract(model_lognormal_stan)[[\"weight_rep\"]]\nsamp25 <- sample(nrow(yrep1), 25)\nbayesplot::ppc_dens_overlay(d$weight, yrep1[samp25, ])"
  },
  {
    "objectID": "rethinking/04-video.html",
    "href": "rethinking/04-video.html",
    "title": "Video #4 code",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(brms)\nlibrary(tidybayes)\nlibrary(ggdist)\nlibrary(ggdag)\nlibrary(splines)\nlibrary(lubridate)\nlibrary(patchwork)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nBAYES_SEED <- 1234\nset.seed(1234)\n\n# Data\ndata(Howell1, package = \"rethinking\")\n\nd <- Howell1 %>% \n  filter(age > 18) %>% \n  # Stan doesn't like working with columns with attributes, but I want to keep\n  # the attributes for unscaling later, so there are two scaled height columns\n  mutate(height_scaled = scale(height),\n         height_z = as.numeric(height_scaled)) %>% \n  mutate(sex = factor(male),\n         sex_nice = factor(male, labels = c(\"Female\", \"Male\")))\n\nheight_scale <- attributes(d$height_scaled) %>% \n  set_names(janitor::make_clean_names(names(.)))\n\n\nhead(Howell1)\n##    height   weight age male\n## 1 151.765 47.82561  63    1\n## 2 139.700 36.48581  63    0\n## 3 136.525 31.86484  65    0\n## 4 156.845 53.04191  41    1\n## 5 145.415 41.27687  51    0\n## 6 163.830 62.99259  35    1\n\nggplot(d, aes(x = height, y = weight, color = sex_nice)) +\n  geom_point() +\n  scale_color_manual(values = clrs[1:2]) +\n  labs(x = \"Height (cm)\", y = \"Weight (kg)\", color = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nSex only\n\\[\n\\begin{aligned}\nW_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha_{S[i]} \\\\\n\\\\\n\\alpha_j &\\sim \\mathcal{N}(60, 10) \\\\\n\\sigma &\\sim \\operatorname{Uniform}(0, 10)\n\\end{aligned}\n\\]\n\nbrmsStan\n\n\nCreate a model with no intercept; use a factor version of sex to get the indexes like he does with \\(\\alpha_{S[i]}\\).\n\npriors <- c(prior(normal(60, 10), class = b),\n            prior(uniform(0, 10), class = sigma, lb = 0, ub = 10))\n\nsex_weight <- brm(\n  bf(weight ~ 0 + sex),\n  data = d,\n  family = gaussian(),\n  prior = priors,\n  chains = 4, cores = 4, seed = BAYES_SEED\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\nsex_weight\n##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: weight ~ 0 + sex \n##    Data: d (Number of observations: 346) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sex0    41.87      0.41    41.08    42.65 1.00     3580     3109\n## sex1    48.63      0.43    47.81    49.49 1.00     4090     2920\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     5.52      0.22     5.12     5.98 1.00     4135     2820\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPosterior mean weights:\n\nsw_post_means <- sex_weight %>% \n  gather_draws(b_sex0, b_sex1)\n\nsw_post_means %>% \n  mean_hdci()\n## # A tibble: 2 × 7\n##   .variable .value .lower .upper .width .point .interval\n##   <chr>      <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 b_sex0      41.9   41.1   42.7   0.95 mean   hdci     \n## 2 b_sex1      48.6   47.7   49.4   0.95 mean   hdci\n\nsw_post_means %>% \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye() +\n  scale_fill_manual(values = clrs[1:2]) +\n  labs(x = \"Posterior mean weight (kg)\\n(Coefficient for sex)\", y = \"Density\", fill = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nPosterior mean contrast in weights:\n\nsw_post_means_wide <- sex_weight %>% \n  spread_draws(b_sex0, b_sex1) %>% \n  mutate(diff = b_sex1 - b_sex0)\n\nsw_post_means_wide %>% \n  select(diff) %>% \n  mean_hdci()\n## # A tibble: 1 × 6\n##    diff .lower .upper .width .point .interval\n##   <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1  6.77   5.63   7.95   0.95 mean   hdci\n\nsw_post_means_wide %>% \n  ggplot(aes(x = diff)) +\n  stat_halfeye(fill = clrs[3]) +\n  labs(x = \"Posterior mean weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\nPosterior predicted weights:\n\nsw_post_pred <- tibble(sex = c(\"0\", \"1\")) %>% \n  add_predicted_draws(sex_weight, ndraws = 1000)\n\nsw_post_pred %>% \n  mean_hdci()\n## # A tibble: 2 × 8\n##   sex    .row .prediction .lower .upper .width .point .interval\n##   <chr> <int>       <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 0         1        41.6   30.7   50.9   0.95 mean   hdci     \n## 2 1         2        49.0   38.2   59.3   0.95 mean   hdci\n\nsw_post_pred %>% \n  ungroup() %>% \n  mutate(sex_nice = factor(sex, labels = c(\"Female\", \"Male\"))) %>% \n  ggplot(aes(x = .prediction, fill = sex_nice)) +\n  stat_halfeye(alpha = 0.75) +\n  scale_fill_manual(values = clrs[1:2]) +\n  labs(x = \"Posterior predicted weight (kg)\", y = \"Density\", fill = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nPosterior predicted contrast in weights:\n\nsw_post_pred_diff <- tibble(sex = c(\"0\", \"1\")) %>% \n  add_predicted_draws(sex_weight, ndraws = 1000) %>% \n  compare_levels(variable = .prediction, by = sex)\n\nsw_post_pred_diff %>% \n  mean_hdci()\n## # A tibble: 1 × 7\n##   sex   .prediction .lower .upper .width .point .interval\n##   <chr>       <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 1 - 0        7.21  -7.29   21.9   0.95 mean   hdci\n\nsw_post_pred_diff %>% \n  ggplot(aes(x = .prediction)) +\n  stat_halfeye(aes(fill = stat(x > 0))) +\n  geom_vline(xintercept = 0) +\n  scale_fill_manual(values = c(colorspace::lighten(clrs[3], 0.5), clrs[3]),\n                    guide = \"none\") +\n  labs(x = \"Posterior weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\n\n\nsw_stan.stan\n\ndata {\n  // Stuff from R\n  int<lower=1> n;\n  vector[n] weight;\n  int sex[n];\n}\n\nparameters {\n  // Things to estimate\n  real<lower=0, upper=10> sigma;\n  vector[2] a;\n}\n\ntransformed parameters {\n  vector[n] mu;\n  mu = a[sex];\n}\n\nmodel {\n  // Likelihood\n  weight ~ normal(mu, sigma);\n  \n  // Priors\n  sigma ~ uniform(0, 10);\n  a ~ normal(60, 10);\n}\n\ngenerated quantities {\n  real diff;\n  matrix[n, 2] weight_rep;\n  vector[n] diff_rep;\n  \n  // Calculate the contrasts / difference between group means\n  diff = a[2] - a[1];\n  \n  // Generate a posterior predictive distribution for each sex\n  // To do this we have to create a matrix, with a column per sex\n  for (j in 1:2) {\n    for (i in 1:n) {\n      weight_rep[i, j] = normal_rng(a[j], sigma);\n    }\n  }\n  \n  // Generate a posterior predictive distribution of group contrasts\n  for (i in 1:n) {\n    diff_rep[i] = normal_rng(a[2], sigma) - normal_rng(a[1], sigma);\n  }\n}\n\n\nstan_data <- list(n = nrow(d),\n                  weight = d$weight,\n                  sex = d$male + 1)\n\nmodel_sw_stan <- rstan::sampling(\n  object = sw_stan,\n  data = stan_data,\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, chains = 4, cores = 4\n)\n\n\nprint(model_sw_stan,\n      pars = c(\"sigma\", \"a[1]\", \"a[2]\", \"diff\"))\n## Inference for Stan model: ce4f92ccf1e48f603c1b01a6bf1ee94d.\n## 4 chains, each with iter=5000; warmup=1000; thin=1; \n## post-warmup draws per chain=4000, total post-warmup draws=16000.\n## \n##        mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\n## sigma  5.52       0 0.21  5.12  5.37  5.51  5.66  5.96 14336    1\n## a[1]  41.86       0 0.41 41.05 41.58 41.86 42.14 42.67 14671    1\n## a[2]  48.63       0 0.43 47.79 48.34 48.64 48.92 49.49 15314    1\n## diff   6.77       0 0.60  5.60  6.37  6.77  7.17  7.94 14697    1\n## \n## Samples were drawn using NUTS(diag_e) at Thu Sep 15 01:54:27 2022.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\n\nPosterior mean weights:\n\nsw_stan_post_means <- model_sw_stan %>% \n  gather_draws(a[i])\n## Warning: `gather_()` was deprecated in tidyr 1.2.0.\n## Please use `gather()` instead.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\nsw_stan_post_means %>% \n  mean_hdci()\n## # A tibble: 2 × 8\n##       i .variable .value .lower .upper .width .point .interval\n##   <int> <chr>      <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1     1 a           41.9   41.1   42.7   0.95 mean   hdci     \n## 2     2 a           48.6   47.7   49.4   0.95 mean   hdci\n\nsw_stan_post_means %>% \n  ungroup() %>% \n  mutate(nice_i = factor(i, labels = c(\"a_female\", \"a_male\"))) %>% \n  ggplot(aes(x = .value, fill = nice_i)) +\n  stat_halfeye() +\n  scale_fill_manual(values = clrs[1:2]) +\n  labs(x = \"Posterior mean weight (kg)\\n(Coefficient for sex)\", y = \"Density\", fill = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nPosterior mean contrast in weights:\n\nsw_stan_post_diff_means <- model_sw_stan %>% \n  gather_draws(diff)\n\nsw_stan_post_diff_means %>% \n  mean_hdci()\n## # A tibble: 1 × 7\n##   .variable .value .lower .upper .width .point .interval\n##   <chr>      <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 diff        6.77   5.58   7.92   0.95 mean   hdci\n\nsw_stan_post_diff_means %>% \n  ggplot(aes(x = .value)) +\n  stat_halfeye(fill = clrs[3]) +\n  labs(x = \"Posterior mean weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\nPosterior predicted weights:\n\npredicted_weights_stan <- model_sw_stan %>% \n  spread_draws(weight_rep[i, sex])\n\npredicted_weights_stan %>% \n  group_by(sex) %>% \n  mean_hdci()\n## # A tibble: 2 × 10\n##     sex     i i.lower i.upper weight_rep weight_…¹ weigh…² .width .point .inte…³\n##   <int> <dbl>   <int>   <int>      <dbl>     <dbl>   <dbl>  <dbl> <chr>  <chr>  \n## 1     1  174.       1     329       41.9      30.9    52.7   0.95 mean   hdci   \n## 2     2  174.       1     329       48.6      37.8    59.5   0.95 mean   hdci   \n## # … with abbreviated variable names ¹​weight_rep.lower, ²​weight_rep.upper,\n## #   ³​.interval\n\npredicted_weights_stan %>% \n  ungroup() %>% \n  mutate(sex_nice = factor(sex, labels = c(\"Female\", \"Male\"))) %>% \n  ggplot(aes(x = weight_rep, fill = sex_nice)) +\n  stat_halfeye(alpha = 0.75) +\n  scale_fill_manual(values = clrs[1:2]) +\n  labs(x = \"Posterior predicted weight (kg)\", y = \"Density\", fill = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nPosterior predicted contrast in weights:\n\nsw_post_pred_diff_stan <- model_sw_stan %>% \n  gather_draws(diff_rep[i])\n\nsw_post_pred_diff_stan %>%\n  group_by(.variable) %>%\n  mean_hdci() %>% \n  select(-starts_with(\"i\"))\n## # A tibble: 1 × 7\n##   .variable .value .value.lower .value.upper .width .point .interval\n##   <chr>      <dbl>        <dbl>        <dbl>  <dbl> <chr>  <chr>    \n## 1 diff_rep    6.77        -8.63         22.1   0.95 mean   hdci\n\nsw_post_pred_diff_stan %>% \n  ggplot(aes(x = .value)) +\n  stat_halfeye(aes(fill = stat(x > 0))) +\n  geom_vline(xintercept = 0) +\n  scale_fill_manual(values = c(colorspace::lighten(clrs[3], 0.5), clrs[3]),\n                    guide = \"none\") +\n  labs(x = \"Posterior weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\n\n\n\n\n\nSex + height\n\\[\n\\begin{aligned}\nW_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha_{S[i]} + \\beta_{S[i]}(H_i - \\bar{H}) \\\\\n\\\\\n\\alpha_j &\\sim \\mathcal{N}(60, 10) \\\\\n\\beta_j &\\sim \\operatorname{LogNormal}(0, 1) \\\\\n\\sigma &\\sim \\operatorname{Uniform}(0, 10)\n\\end{aligned}\n\\]\n\nbrmsStan\n\n\nThis is the wonkiest syntax ever, but it works! We can hack the nl capabilities of brms to create indexed parameters.\nAlternatively you can avoid this nl syntax! Use bf(weight ~ 0 + sex + sex:height_z), instead. Note the : for the interaction term instead of the more standard *. If you use *, you’ll get a more standard interaction term (i.e. the change in the slope when one group is active); if you use :, you’ll get slopes for each group. It’s a little subtlety in R’s formula syntax. The * is a shortcut for complete crossing of the terms, so x * z really turns into x + z + x:z behind the scenes. The : only does the interaction of the two terms, so that x:z is just \\(x \\times z\\).\n\npriors <- c(prior(normal(60, 10), class = b, nlpar = a),\n            prior(lognormal(0, 1), class = b, nlpar = b, lb = 0),\n            prior(uniform(0, 10), class = sigma, lb = 0, ub = 10))\n\nmodel_height_sex <- brm(\n  bf(weight ~ 0 + a + b * height_z,\n     a ~ 0 + sex,\n     b ~ 0 + sex,\n     nl = TRUE),\n  data = d,\n  family = gaussian(),\n  prior = priors,\n  chains = 4, cores = 4, seed = BAYES_SEED\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\nmodel_height_sex\n##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: weight ~ 0 + a + b * height_z \n##          a ~ 0 + sex\n##          b ~ 0 + sex\n##    Data: d (Number of observations: 346) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## a_sex0    45.10      0.46    44.19    45.99 1.00     3021     3038\n## a_sex1    45.19      0.47    44.30    46.11 1.00     2828     2799\n## b_sex0     4.90      0.50     3.88     5.89 1.00     3018     2442\n## b_sex1     4.65      0.45     3.79     5.53 1.00     2964     2861\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     4.28      0.17     3.97     4.62 1.00     3600     2789\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nsex_height_weight_post_pred <- expand_grid(\n  height_z = seq(min(d$height_z), max(d$height_z), length.out = 50),\n  sex = 0:1\n) %>% \n  add_predicted_draws(model_height_sex) %>%\n  compare_levels(variable = .prediction, by = sex, comparison = list(c(\"0\", \"1\"))) %>% \n  mutate(height_unscaled = (height_z * height_scale$scaled_scale) + height_scale$scaled_center)\n\nOverall distribution of predictive posterior contrasts:\n\nggplot(sex_height_weight_post_pred, aes(x = .prediction)) +\n  stat_halfeye(fill = clrs[3]) +\n  labs(x = \"Posterior mean weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\nDistribution of predictive posterior contrasts across range of heights:\n\nggplot(sex_height_weight_post_pred, aes(x = height_unscaled, y = .prediction)) +\n  stat_lineribbon(aes(fill_ramp = stat(.width)), .width = ppoints(50),\n                  fill = clrs[3], color = colorspace::darken(clrs[3], 0.5), \n                  show.legend = FALSE) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  scale_fill_ramp_continuous(from = \"transparent\", range = c(1, 0)) +\n  labs(x = \"Height (cm)\", y = \"Posterior weight contrast (kg)\\nWomen − Men\")\n\n\n\n\n\n\n\n\n\n\n\n\nExtracting Stan code from Rethinking models\n\n\n\n\n\nThe ulam() function is super helpful for translating McElreath’s quap() syntax into Stan!\n\nm_SHW <- rethinking::quap(\n  alist(\n    W ~ dnorm(mu, sigma),\n    mu <- a[S] + b[S] * (H - Hbar),\n    a[S] ~ dnorm(60, 10),\n    b[S] ~ dlnorm(0, 1),\n    sigma ~ dunif(0, 10)\n  ), \n  data = list(\n    W = d$weight,\n    H = d$height,\n    Hbar = mean(d$height),\n    S = d$male + 1\n  )\n)\n\ncat(rethinking::ulam(m_SHW, sample = FALSE)$model)\n## data{\n##     vector[346] W;\n##     real Hbar;\n##     vector[346] H;\n##     int S[346];\n## }\n## parameters{\n##     vector[2] a;\n##     vector<lower=0>[2] b;\n##     real<lower=0,upper=10> sigma;\n## }\n## model{\n##     vector[346] mu;\n##     sigma ~ uniform( 0 , 10 );\n##     b ~ lognormal( 0 , 1 );\n##     a ~ normal( 60 , 10 );\n##     for ( i in 1:346 ) {\n##         mu[i] = a[S[i]] + b[S[i]] * (H[i] - Hbar);\n##     }\n##     W ~ normal( mu , sigma );\n## }\n\n\n\n\nsex_height.stan\n\ndata {\n  // Stuff from R\n  int<lower=1> n;\n  vector[n] weight;\n  vector[n] height;\n  int sex[n];\n}\n\ntransformed data {\n  // Center and standardize height\n  vector[n] height_z;\n  height_z = (height - mean(height)) / sd(height);\n}\n\nparameters {\n  // Things to estimate\n  real<lower=0, upper=10> sigma;\n  vector[2] a;\n  vector<lower=0>[2] b;\n}\n\nmodel {\n  vector[n] mu;\n  \n  // Model for mu with intercepts (a) and coefficients (b) for each sex\n  for (i in 1:n) {\n    mu[i] = a[sex[i]] + b[sex[i]] * height_z[i];\n  }\n\n  // Likelihood\n  weight ~ normal(mu, sigma);\n  \n  // Priors\n  sigma ~ uniform(0, 10);\n  a ~ normal(60, 10);\n  b ~ lognormal(0, 1);\n}\n\ngenerated quantities {\n  matrix[n, 2] weight_rep;\n  vector[n] diff_rep;\n  \n  // Generate a posterior predictive distribution for each sex\n  // To do this we have to create a matrix, with a column per sex\n  for (j in 1:2) {\n    for (i in 1:n) {\n      real mu_hat_n = a[sex[i]] + b[sex[i]] * height_z[i];\n      weight_rep[i, j] = normal_rng(mu_hat_n, sigma);\n    }\n  }\n  \n  // Generate a posterior predictive distribution of group contrasts\n  for (i in 1:n) {\n    diff_rep[i] = weight_rep[i, 1] - weight_rep[i, 2];\n  }\n}\n\n\nstan_data <- list(n = nrow(d),\n                  weight = d$weight,\n                  height = d$height,\n                  sex = d$male + 1)\n\nmodel_sex_height_stan <- rstan::sampling(\n  object = sex_height_stan,\n  data = stan_data,\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, chains = 4, cores = 4\n)\n\n\nprint(model_sex_height_stan,\n      pars = c(\"sigma\", \"a[1]\", \"a[2]\", \"b[1]\", \"b[2]\"))\n## Inference for Stan model: f8b7828023f48992dd5011f1f1fa456e.\n## 4 chains, each with iter=5000; warmup=1000; thin=1; \n## post-warmup draws per chain=4000, total post-warmup draws=16000.\n## \n##        mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\n## sigma  4.28       0 0.17  3.97  4.17  4.28  4.39  4.62 15332    1\n## a[1]  45.10       0 0.45 44.22 44.80 45.10 45.41 45.99 10776    1\n## a[2]  45.20       0 0.46 44.29 44.89 45.20 45.51 46.09 10499    1\n## b[1]   4.91       0 0.49  3.95  4.57  4.91  5.24  5.86 10718    1\n## b[2]   4.65       0 0.43  3.80  4.36  4.65  4.95  5.50 10394    1\n## \n## Samples were drawn using NUTS(diag_e) at Thu Sep 15 01:55:38 2022.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\n\n\noriginal_hw <- tibble(height = d$height,\n                      weight = d$weight) %>% \n  mutate(i = 1:n())\n\npredicted_diffs_sex_height_stan <- model_sex_height_stan %>% \n  spread_draws(diff_rep[i]) %>% \n  left_join(original_hw, by = \"i\")\n\nOverall distribution of predictive posterior contrasts:\n\nggplot(predicted_diffs_sex_height_stan, aes(x = diff_rep)) +\n  stat_halfeye(fill = clrs[3]) +\n  labs(x = \"Posterior mean weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\nDistribution of predictive posterior contrasts across range of heights:\n(The y-values are way off from the video here :shrug:)\n\nggplot(predicted_diffs_sex_height_stan, aes(x = height, y = diff_rep)) +\n  stat_lineribbon(aes(fill_ramp = stat(.width)), .width = ppoints(50),\n                  fill = clrs[3], color = colorspace::darken(clrs[3], 0.5), \n                  show.legend = FALSE) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  scale_fill_ramp_continuous(from = \"transparent\", range = c(1, 0)) +\n  labs(x = \"Height (cm)\", y = \"Posterior weight contrast (kg)\\nWomen − Men\")\n\n\n\n\n\n\n\n\n\nFull luxury Bayes!\nGiven this DAG:\n\nheight_sex_dag <- dagify(\n  x ~ z,\n  y ~ x + z,\n  exposure = \"x\",\n  outcome = \"y\",\n  labels = c(x = \"Height\", y = \"Weight\", z = \"Sex\"),\n  coords = list(x = c(x = 1, y = 3, z = 2),\n                y = c(x = 1, y = 1, z = 2))) %>% \n  tidy_dagitty() %>% \n  node_status()\n\nggplot(height_sex_dag, aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges() +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_text(aes(label = label), size = 3.5) +\n  scale_color_manual(values = clrs[c(1, 4)], guide = \"none\") +\n  theme_dag()\n\n\n\n\n\n\n\n\n…what’s the causal effect of sex on weight? Or:\n\\[\nE(\\text{Weight} \\mid \\operatorname{do}(\\text{Sex}))\n\\]\nHere’s the official model:\n\\[\n\\begin{aligned}\nH_i &\\sim \\mathcal{N}(\\nu_i, \\tau) \\\\\nW_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\nu_i &= h_{S[i]} \\\\\n\\mu_i &= \\alpha_{S[i]} + \\beta_{S[i]}(H_i - \\bar{H}) \\\\\n\\\\\nh_j &\\sim \\mathcal{N}(160, 10) \\\\\n\\alpha_j &\\sim \\mathcal{N}(60, 10) \\\\\n\\beta_j &\\sim \\operatorname{LogNormal}(0, 1) \\\\\n\\sigma, \\tau &\\sim \\operatorname{Uniform}(0, 10)\n\\end{aligned}\n\\]\nThe results should look something like this, from the slides:\n\n\n\n\n\n\n\n\n\n\nbrmsStan\n\n\n\npriors <- c(prior(normal(60, 10), resp = weight, class = b, nlpar = a),\n            prior(lognormal(0, 1), resp = weight, class = b, nlpar = b, lb = 0),\n            prior(uniform(0, 10), resp = weight, class = sigma, lb = 0, ub = 10),\n            # prior(normal(160, 10), resp = height, class = b),\n            prior(normal(0, 1), resp = heightz, class = b),\n            prior(uniform(0, 10), resp = heightz, class = sigma, lb = 0, ub = 10))\n\nmodel_luxury <- brm(\n  bf(weight ~ 0 + a + b * height_z,\n     a ~ 0 + sex,\n     b ~ 0 + sex,\n     nl = TRUE) + \n    bf(height_z ~ 0 + sex) + \n    set_rescor(TRUE),\n  data = d,\n  family = gaussian(),\n  prior = priors,\n  chains = 4, cores = 4, seed = BAYES_SEED\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n\n\nmodel_luxury\n##  Family: MV(gaussian, gaussian) \n##   Links: mu = identity; sigma = identity\n##          mu = identity; sigma = identity \n## Formula: weight ~ 0 + a + b * height_z \n##          a ~ 0 + sex\n##          b ~ 0 + sex\n##          height_z ~ 0 + sex \n##    Data: d (Number of observations: 346) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## weight_a_sex0    42.58      0.64    41.52    44.07 1.01      598      285\n## weight_a_sex1    47.97      0.64    46.49    49.02 1.01      552      313\n## weight_b_sex0     1.09      0.77     0.17     3.02 1.01      565      255\n## weight_b_sex1     0.89      0.70     0.12     2.73 1.01      491      275\n## heightz_sex0     -0.66      0.05    -0.77    -0.55 1.00     2384     1681\n## heightz_sex1      0.74      0.06     0.62     0.85 1.00     2806     2528\n## \n## Family Specific Parameters: \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma_weight      5.13      0.29     4.49     5.67 1.01      666      291\n## sigma_heightz     0.72      0.03     0.67     0.77 1.00     3262     1965\n## \n## Residual Correlations: \n##                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n## rescor(weight,heightz)     0.54      0.09     0.32     0.65 1.01      560\n##                        Tail_ESS\n## rescor(weight,heightz)      265\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n\nPosterior mean contrast in weights:\n\nluxury_post_mean_diff <- expand_grid(\n  height_z = seq(min(d$height_z), max(d$height_z), length.out = 50),\n  sex = 0:1\n) %>% \n  add_epred_draws(model_luxury) %>%\n  compare_levels(variable = .epred, by = sex, comparison = list(c(\"1\", \"0\")))\n\nluxury_post_mean_diff %>% \n  filter(.category == \"weight\") %>% \n  ggplot(aes(x = .epred)) +\n  stat_halfeye(fill = clrs[3]) +\n  labs(x = \"Posterior mean weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\nPosterior predicted contrast in weights:\n\nluxury_post_pred_diff <- expand_grid(\n  height_z = seq(min(d$height_z), max(d$height_z), length.out = 50),\n  sex = 0:1\n) %>% \n  add_predicted_draws(model_luxury) %>%\n  compare_levels(variable = .prediction, by = sex, comparison = list(c(\"1\", \"0\")))\n\nluxury_post_pred_diff %>% \n  filter(.category == \"weight\") %>% \n  ggplot(aes(x = .prediction)) +\n  stat_halfeye(aes(fill = stat(x > 0))) +\n  geom_vline(xintercept = 0) +\n  scale_fill_manual(values = c(colorspace::lighten(clrs[3], 0.5), clrs[3]),\n                    guide = \"none\") +\n  labs(x = \"Posterior weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\n\nExtracting Stan code from Rethinking models\n\n\n\n\n\n\nm_SHW_full <- rethinking::quap(\n  alist(\n    # Weight\n    W ~ dnorm(mu, sigma),\n    mu <- a[S] + b[S] * (H - Hbar),\n    a[S] ~ dnorm(60, 10),\n    b[S] ~ dlnorm(0, 1),\n    sigma ~ dunif(0, 10),\n    \n    # Height\n    H ~ dnorm(nu, tau),\n    nu <- h[S],\n    h[S] ~ dnorm(160, 10),\n    tau ~ dunif(0, 10)\n  ), data = list(\n    W = d$weight,\n    H = d$height,\n    Hbar = mean(d$height),\n    S = d$male + 1\n  )\n)\n\ncat(rethinking::ulam(m_SHW_full, sample = FALSE)$model)\n\n\n\n\nluxury_stan.stan\n\ndata {\n  // Stuff from R\n  int<lower=1> n;\n  vector[n] weight;\n  real Hbar;\n  vector[n] height;\n  int sex[n];\n}\n\nparameters {\n  // Things to estimate\n  vector[2] a;\n  vector<lower=0>[2] b;\n  real<lower=0,upper=10> sigma;\n  vector[2] h;\n  real<lower=0,upper=10> tau;\n}\n\nmodel {\n  vector[n] mu;\n  vector[n] nu;\n  \n  // Height model\n  tau ~ uniform(0, 10);\n  h ~ normal(160, 10);\n  \n  for (i in 1:n) {\n    nu[i] = h[sex[i]];\n  }\n  \n  // Weight model\n  height ~ normal(nu , tau);\n  sigma ~ uniform(0, 10);\n  b ~ lognormal(0, 1);\n  a ~ normal(60, 10);\n  \n  for (i in 1:n) {\n    mu[i] = a[sex[i]] + b[sex[i]] * (height[i] - Hbar);\n  }\n  \n  weight ~ normal(mu, sigma);\n}\n\ngenerated quantities {\n  matrix[n, 2] weight_rep;\n  matrix[n, 2] height_rep;\n  vector[n] w_do_s;\n  vector[2] mu_sex;\n  real mu_diff;\n  \n  for (i in 1:2) {\n    mu_sex[i] = a[sex[i]] + b[sex[i]] * (h[sex[i]] - Hbar);\n  }\n  \n  mu_diff = mu_sex[1] - mu_sex[2];\n  \n  // Generate a posterior predictive distribution for each sex\n  // To do this we have to create a matrix, with a column per sex\n  for (j in 1:2) {\n    for (i in 1:n) {\n      height_rep[i, j] = normal_rng(h[sex[j]], tau);\n      weight_rep[i, j] = normal_rng(a[sex[j]] + b[sex[j]] * (height_rep[i, j] - Hbar), sigma);\n    }\n  }\n  \n  // Generate a posterior predictive distribution of group contrasts\n  for (i in 1:n) {\n    w_do_s[i] = weight_rep[i, 1] - weight_rep[i, 2];\n  }\n}\n\n\nstan_data <- list(n = nrow(d),\n                  weight = d$weight,\n                  height = d$height,\n                  Hbar = mean(d$height),\n                  sex = d$male + 1)\n\nmodel_luxury_stan <- rstan::sampling(\n  object = luxury_stan,\n  data = stan_data,\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, chains = 4, cores = 4\n)\n\n\nprint(model_luxury_stan,\n      pars = c(\"a[1]\", \"a[2]\", \"b[1]\", \"b[2]\", \"sigma\", \"h[1]\", \"h[2]\", \"tau\", \n               \"mu_sex[1]\", \"mu_sex[2]\", \"mu_diff\"))\n## Inference for Stan model: 2ac72225665508fb4100c7f800818c3a.\n## 4 chains, each with iter=5000; warmup=1000; thin=1; \n## post-warmup draws per chain=4000, total post-warmup draws=16000.\n## \n##             mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat\n## a[1]       45.18       0 0.46  44.28  44.87  45.17  45.48  46.08 12392    1\n## a[2]       45.14       0 0.46  44.25  44.83  45.14  45.45  46.03 12553    1\n## b[1]        0.65       0 0.06   0.52   0.60   0.65   0.69   0.77 12075    1\n## b[2]        0.61       0 0.06   0.50   0.57   0.61   0.65   0.72 13048    1\n## sigma       4.28       0 0.16   3.97   4.17   4.28   4.39   4.62 21039    1\n## h[1]      149.50       0 0.41 148.70 149.21 149.50 149.78 150.30 22463    1\n## h[2]      160.37       0 0.44 159.52 160.08 160.37 160.67 161.22 22320    1\n## tau         5.57       0 0.21   5.18   5.43   5.56   5.71   6.01 19301    1\n## mu_sex[1]  48.63       0 0.42  47.79  48.35  48.63  48.92  49.46 21139    1\n## mu_sex[2]  41.85       0 0.42  41.04  41.57  41.85  42.13  42.67 21824    1\n## mu_diff     6.78       0 0.59   5.62   6.37   6.78   7.18   7.94 20965    1\n## \n## Samples were drawn using NUTS(diag_e) at Thu Sep 15 01:56:43 2022.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\n\nPosterior mean contrast in weights:\n\nluxury_post_mean_diff_stan <- model_luxury_stan %>% \n  spread_draws(mu_diff)\n\nluxury_post_mean_diff_stan %>% \n  mean_hdci()\n## # A tibble: 1 × 6\n##   mu_diff .lower .upper .width .point .interval\n##     <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1    6.78   5.64   7.95   0.95 mean   hdci\n\nggplot(luxury_post_mean_diff_stan, aes(x = mu_diff)) +\n  stat_halfeye(fill = clrs[3]) +\n  labs(x = \"Posterior mean weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\n\nluxury_post_pred_diff_stan <- model_luxury_stan %>% \n  spread_draws(w_do_s[i])\n\nluxury_post_pred_diff_stan %>% \n  mean_hdci()\n## # A tibble: 346 × 7\n##        i w_do_s .lower .upper .width .point .interval\n##    <int>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n##  1     1   6.79  -8.96   21.5   0.95 mean   hdci     \n##  2     2   6.86  -8.69   22.2   0.95 mean   hdci     \n##  3     3   6.79  -8.46   22.6   0.95 mean   hdci     \n##  4     4   6.86  -9.38   21.3   0.95 mean   hdci     \n##  5     5   6.71  -8.26   22.7   0.95 mean   hdci     \n##  6     6   6.85  -8.15   22.8   0.95 mean   hdci     \n##  7     7   6.78  -8.74   22.4   0.95 mean   hdci     \n##  8     8   6.85  -8.36   22.6   0.95 mean   hdci     \n##  9     9   6.82  -8.79   21.9   0.95 mean   hdci     \n## 10    10   6.80  -8.53   21.8   0.95 mean   hdci     \n## # … with 336 more rows\n\nggplot(luxury_post_pred_diff_stan, aes(x = w_do_s)) +\n  stat_halfeye(aes(fill = stat(x > 0))) +\n  geom_vline(xintercept = 0) +\n  scale_fill_manual(values = c(colorspace::lighten(clrs[3], 0.5), clrs[3]),\n                    guide = \"none\") +\n  labs(x = \"Posterior weight contrast (kg)\\nWomen − Men\", y = \"Density\")\n\n\n\n\n\n\n\n\n\nCurvy linear models\nThe full data isn’t linear, but linear models can be fit to curvy data, but in geocentric, purposely wrong ways\n\nggplot(Howell1, aes(x = height, y = weight)) +\n  geom_point()\n\n\n\n\n\nPolynomials\nWe can use a squared term like:\n\\[\n\\mu_i = \\alpha + \\beta_1 H_i + \\beta_2 H_i^2\n\\]\nAnd that fits okay, but it does weird things on the edges of the data, like weight increasing when height gets really small\n\nggplot(Howell1, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), fullrange = TRUE) +\n  xlim(c(40, 200))\n\n\n\n\nWe can throw in more terms too:\n\\[\n\\mu_i = \\alpha + \\beta_1 H_i + \\beta_2 H_i^2 + \\beta_3 H_i^3 + \\beta_4 H_i^4\n\\]\nAnd the line fits better, but it does really weird things on the edges, like dropping precipitously after the max height:\n\nggplot(Howell1, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), fullrange = TRUE) +\n  xlim(c(40, 200))\n\n\n\n\nWeirdly, logging works really well because of biological reasons (that he’ll explain in chapter 19)\n\nggplot(Howell1, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", formula = y ~ x,\n              method.args = list(family = gaussian(link = \"log\"))) +\n  scale_x_log10()\n\n\n\n\n\n\nSplines\n\ndata(cherry_blossoms, package = \"rethinking\")\n\ncherry_blossoms <- cherry_blossoms %>% \n  filter(complete.cases(doy)) %>% \n  mutate(idx = 1:n()) %>% \n  arrange(year)\n\nnum_knots <- 3\nknot_list <- seq(from = min(cherry_blossoms$year), \n                 to = max(cherry_blossoms$year), \n                 length.out = num_knots)\n\ncherry_splines <- cherry_blossoms %>% \n  nest(data = everything()) %>% \n  mutate(basis_matrix = purrr::map(data, ~{\n    t(bs(.$year, knots = knot_list, degree = 2, intercept = FALSE))\n  })) %>% \n  mutate(weights = purrr::map(basis_matrix, ~rep(c(1,-1), length = nrow(.)))) \n\ncherry_splines_mu <- cherry_splines %>% \n  mutate(mu = purrr::map2(weights, basis_matrix, ~as.vector(.x %*% .y))) %>% \n  unnest(c(data, mu))\n\ncherry_basis <- cherry_splines %>% \n  unnest(weights) %>% \n  mutate(row = 1:n()) %>% \n  filter(row != 5) %>% \n  mutate(basis = purrr::pmap(list(basis_matrix, weights, row), ~{\n    ..1[..3,] * ..2\n  })) %>% \n  mutate(row = glue::glue(\"Basis {row} (w = {weights})\")) %>% \n  unnest(c(data, basis)) \n  \nggplot(data = cherry_splines_mu, aes(x = year)) +\n  geom_line(aes(y = mu), size = 2) +\n  geom_line(data = cherry_basis, aes(y = basis, color = row), size = 1) +\n  labs(y = \"Weighted basis function\", color = NULL) +\n  theme(axis.text.x = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.line.x = element_blank())\n\n\n\n\nPlot from book cover, for fun:\n\nmodel_doy <- brm(\n  bf(doy ~ 1 + s(year, bs = \"bs\", k = 30)),\n  family = gaussian(),\n  data = cherry_blossoms,\n  prior = c(prior(normal(100, 10), class = Intercept),\n                prior(normal(0, 10), class = b),\n                prior(student_t(3, 0, 5.9), class = sds),\n                prior(exponential(1), class = sigma)),\n  chains = 4, cores = 4, seed = BAYES_SEED\n)\n\n\nplot_doy <- cherry_blossoms %>% \n  add_epred_draws(model_doy) %>% \n  summarize(mean_hdci(.epred, .width = 0.89)) %>% \n  ungroup() %>% \n  mutate(day_of_year = as.Date(doy, origin = \"2021-12-31\"))\n\npanel_bottom <- plot_doy %>% \n  ggplot(aes(x = year)) +\n  geom_point(aes(y = doy), pch = 8, size = 3.5, color = \"#FF4136\", alpha = 0.5) +\n  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = \"#111111\", alpha = 0.5) +\n  scale_x_continuous(breaks = c(900, 1400, 2000),\n                     labels = function(x) paste(x, \"CE\")) +\n  scale_y_continuous(labels = function(y) format(as.Date(y, origin = \"2021-12-31\"), \"%B %e\"),\n                     breaks = yday(ymd(c(\"2022-04-01\", \"2022-05-01\")))) +\n  labs(x = NULL, y = \"Day of first blossom\")\npanel_bottom\n\n\n\n\nThe cover uses imputed data for the missing values. I’m assuming that’ll get covered later in the book, but in the meantime, here’s a partial version of the top panel of the front cover plot:\n\npanel_top <- cherry_blossoms %>% \n  drop_na(temp) %>% \n  ggplot(aes(x = year, y = temp)) +\n  geom_point(color = \"#001f3f\", size = 3, alpha = 0.3) +\n  scale_x_continuous(breaks = c(900, 1400, 2000),\n                     labels = function(x) paste(x, \"CE\")) +\n  scale_y_continuous(labels = function(y) paste0(y, \"°C\"),\n                     breaks = c(5, 8)) +\n  labs(x = NULL, y = \"March temperature\")\npanel_top\n\n\n\n\nAll together:\n\npanel_top / \n  (panel_bottom + \n     theme(axis.text.x = element_blank(),\n           axis.ticks.x = element_blank()))"
  },
  {
    "objectID": "rethinking/05-video.html",
    "href": "rethinking/05-video.html",
    "title": "Video #5 code",
    "section": "",
    "text": "\\[\n\\newcommand{\\ind}{\\perp\\!\\!\\!\\perp}\n\\newcommand{\\notind}{\\not\\!\\perp\\!\\!\\!\\perp}\n\\]\n\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\nlibrary(ggdag)\nlibrary(ggrepel)\nlibrary(patchwork)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nBAYES_SEED <- 1234\nset.seed(1234)\n\n\nThe fork (confounders)\n\\[\nX \\leftarrow Z \\rightarrow Y\n\\]\n\\(Z\\) connects \\(X\\) and \\(Y\\) so that \\(Y \\notind X\\)\n\nSimulated example\nWe can make some data to prove that they’re connected:\n\nn <- 1000\n\nfork_sim <- tibble(Z = rbinom(n, 1, prob = 0.5)) %>% \n  # When Z is 0, there's a 10% chance of X or Y being 1\n  # When Z is 1, there's a 90% chance of X or Y being 1\n  mutate(X = rbinom(n, 1, prob = ((1 - Z) * 0.1) + (Z * 0.9)),\n         Y = rbinom(n, 1, prob = ((1 - Z) * 0.1) + (Z * 0.9)))\n\nfork_sim %>% \n  select(-Z) %>% \n  table()\n##    Y\n## X     0   1\n##   0 390 101\n##   1  82 427\n\nfork_sim %>% \n  summarize(cor = cor(X, Y))\n## # A tibble: 1 × 1\n##     cor\n##   <dbl>\n## 1 0.634\n\nBut if we stratify by (or adjust for) \\(Z\\), we can see that \\(Y \\ind X \\mid Z\\):\n\nfork_sim %>% \n  select(X, Y, Z) %>% \n  table()\n## , , Z = 0\n## \n##    Y\n## X     0   1\n##   0 388  56\n##   1  36   2\n## \n## , , Z = 1\n## \n##    Y\n## X     0   1\n##   0   2  45\n##   1  46 425\n\nfork_sim %>% \n  group_by(Z) %>% \n  summarize(cor = cor(X, Y))\n## # A tibble: 2 × 2\n##       Z     cor\n##   <int>   <dbl>\n## 1     0 -0.0609\n## 2     1 -0.0546\n\nHere’s a continuous version too. When looking at all values of \\(Z\\), there’s a positive slope and relationship; when looking within each group, the relationship is 0 and flat.\n\nn <- 300\n\nfork_sim_cont <- tibble(Z = rbinom(n, 1, 0.5)) %>% \n  mutate(X = rnorm(n, 2 * Z - 1),\n         Y = rnorm(n, 2 * Z - 1))\n\nggplot(fork_sim_cont, aes(x = X, y = Y, color = factor(Z))) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_smooth(aes(color = NULL), method = \"lm\")\n\n\n\n\n\n\nWaffle House example\n\ndata(WaffleDivorce, package = \"rethinking\")\n\nWaffleDivorce <- WaffleDivorce %>% \n  mutate(across(c(Marriage, Divorce, MedianAgeMarriage), ~scale(.), .names = \"{col}_scaled\")) %>% \n  mutate(across(c(Marriage, Divorce, MedianAgeMarriage), ~as.numeric(scale(.)), .names = \"{col}_z\"))\n\nWhat is the causal effect of marriage on divorce?\n\nheight_sex_dag <- dagify(\n  x ~ z,\n  y ~ x + z,\n  exposure = \"x\",\n  outcome = \"y\",\n  labels = c(x = \"Marriage\", y = \"Divorce\", z = \"Age\"),\n  coords = list(x = c(x = 1, y = 3, z = 2),\n                y = c(x = 1, y = 1, z = 2))) %>% \n  tidy_dagitty() %>% \n  node_status()\n\nggplot(height_sex_dag, aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges() +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_text(aes(label = label), size = 3.5, color = \"black\") +\n  scale_color_manual(values = clrs[c(1, 4)], guide = \"none\") +\n  theme_dag()\n\n\n\n\n\n\n\n\nWe can look at the relationship of all three of these arrows\n\nAge → MarriageAge → DivorceMarriage → Divorce\n\n\n\nggplot(WaffleDivorce, aes(x = MedianAgeMarriage, y = Marriage)) +\n  geom_point(aes(fill = factor(South)), size = 4, pch = 21, color = \"white\") +\n  geom_smooth(method = \"lm\") +\n  geom_text_repel(aes(label = Loc), max.overlaps = 2) +\n  scale_fill_manual(values = clrs[c(1, 3)], guide = \"none\") +\n  labs(x = \"Median age of marriage\", y = \"Marriage rate\")\n\n\n\n\n\n\n\nggplot(WaffleDivorce, aes(x = MedianAgeMarriage, y = Divorce)) +\n  geom_point(aes(fill = factor(South)), size = 4, pch = 21, color = \"white\") +\n  geom_smooth(method = \"lm\") +\n  geom_text_repel(aes(label = Loc), max.overlaps = 2) +\n  scale_fill_manual(values = clrs[c(1, 3)], guide = \"none\") +\n  labs(x = \"Median age of marriage\", y = \"Divorce rate\")\n\n\n\n\n\n\n\nggplot(WaffleDivorce, aes(x = Marriage, y = Divorce)) +\n  geom_point(aes(fill = factor(South)), size = 4, pch = 21, color = \"white\") +\n  geom_smooth(method = \"lm\") +\n  geom_text_repel(aes(label = Loc), max.overlaps = 2) +\n  scale_fill_manual(values = clrs[c(1, 3)], guide = \"none\") +\n  labs(x = \"Marriage rate\", y = \"Divorce rate\")\n\n\n\n\n\n\n\nHow do we stratify by a continuous variable though? Regression!\n\\[\n\\begin{aligned}\nD_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta_M M_i + \\beta_A A_i\n\\end{aligned}\n\\]\n\nPrior predictive simulation\n\\[\n\\begin{aligned}\nD_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta_M M_i + \\beta_A A_i \\\\\n\\\\\n\\alpha &\\sim \\mathcal{N}(0, 0.2) \\\\\n\\beta_M &\\sim \\mathcal{N}(0, 0.5) \\\\\n\\beta_A &\\sim \\mathcal{N}(0, 0.5) \\\\\n\\sigma &\\sim \\operatorname{Exponential}(1)\n\\end{aligned}\n\\]\n\npriors <- c(prior(normal(0, 0.2), class = Intercept),\n            prior(normal(0, 0.5), class = b, coef = \"Marriage_z\"),\n            prior(normal(0, 0.5), class = b, coef = \"MedianAgeMarriage_z\"),\n            prior(exponential(1), class = sigma))\n\nmarriage_divorce_prior_only <- brm(\n  bf(Divorce_z ~ Marriage_z + MedianAgeMarriage_z),\n  data = WaffleDivorce,\n  family = gaussian(),\n  prior = priors,\n  sample_prior = \"only\",\n  chains = 4, cores = 4, seed = BAYES_SEED\n)\n## Compiling Stan program...\n## Start sampling\n\n\ndraws_prior <- tibble(MedianAgeMarriage_z = seq(-2, 2, length.out = 100),\n                      Marriage_z = 0) %>% \n  add_epred_draws(marriage_divorce_prior_only, ndraws = 100)\n\ndraws_prior %>% \n  ggplot(aes(x = MedianAgeMarriage_z, y = .epred)) +\n  geom_line(aes(group = .draw), alpha = 0.2) +\n  labs(x = \"Median age of marriage (standardized)\",\n       y = \"Divorce rate (standardized)\",\n       caption = \"Standardized marriage rate held constant at 0\")\n\n\n\n\n\n\nActual model\nBased on these models,\n\nOnce we know median age at marriage for a state, there is little or no additional predictive power in also knowing the rate of marriage in that state. (p. 134)\n\n\nbrmsStan\n\n\n\npriors <- c(prior(normal(0, 0.2), class = Intercept),\n            prior(normal(0, 0.5), class = b, coef = \"Marriage_z\"),\n            prior(normal(0, 0.5), class = b, coef = \"MedianAgeMarriage_z\"),\n            prior(exponential(1), class = sigma))\n\nmarriage_divorce_actual <- brm(\n  bf(Divorce_z ~ Marriage_z + MedianAgeMarriage_z),\n  data = WaffleDivorce,\n  family = gaussian(),\n  prior = priors,\n  chains = 4, cores = 4, seed = BAYES_SEED\n)\n## Compiling Stan program...\n## recompiling to avoid crashing R session\n## Start sampling\n\n\nprint(marriage_divorce_actual)\n##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Divorce_z ~ Marriage_z + MedianAgeMarriage_z \n##    Data: WaffleDivorce (Number of observations: 50) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept              -0.00      0.10    -0.20     0.20 1.00     3824     2317\n## Marriage_z             -0.07      0.15    -0.36     0.24 1.00     3087     2922\n## MedianAgeMarriage_z    -0.62      0.16    -0.92    -0.31 1.00     2894     2655\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     0.83      0.09     0.68     1.01 1.00     3630     2543\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n# get_variables(marriage_divorce_actual)\n\nmarriage_divorce_actual %>% \n  gather_draws(b_Intercept, b_Marriage_z, b_MedianAgeMarriage_z, sigma) %>% \n  ggplot(aes(x = .value, y = fct_rev(.variable))) +\n  stat_halfeye() +\n  coord_cartesian(xlim = c(-1, 1))\n\n\n\n\n\n\nmarriage_divorce_stan.stan\n\ndata {\n  int<lower=1> n;  // Observations\n  vector[n] Divorce_z;  // Outcome: divorce rate\n  vector[n] Marriage_z;  // \"Treatment\": marriage rate\n  vector[n] MedianAgeMarriage_z;  // Confounder: age\n}\n\nparameters {\n  real a;\n  real bM;\n  real bA;\n  real<lower=0> sigma;\n}\n\ntransformed parameters {\n  vector[n] mu;\n  mu = a + bM*Marriage_z + bA*MedianAgeMarriage_z;\n}\n\nmodel {\n  // Likelihood\n  Divorce_z ~ normal(mu, sigma);\n  \n  // Priors\n  a ~ normal(0, 0.2);\n  bM ~ normal(0, 0.5);\n  bA ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n}\n\ngenerated quantities {\n  vector[n] Divorce_z_rep;\n  \n  for (i in 1:n) {\n    Divorce_z_rep[i] = normal_rng(mu[i], sigma);\n  }\n}\n\n\nstan_data <- WaffleDivorce %>% \n  select(Divorce_z, Marriage_z, MedianAgeMarriage_z) %>% \n  compose_data()\n\nmodel_marriage_divorce_stan <- rstan::sampling(\n  object = marriage_divorce_stan,\n  data = stan_data,\n  iter = 2000, warmup = 1000, seed = BAYES_SEED, chains = 4, cores = 4\n)\n\n\nprint(model_marriage_divorce_stan,\n      pars = c(\"a\", \"bM\", \"bA\", \"sigma\"))\n## Inference for Stan model: 8cc6e06905b678b9147ee76469c82d06.\n## 4 chains, each with iter=2000; warmup=1000; thin=1; \n## post-warmup draws per chain=1000, total post-warmup draws=4000.\n## \n##        mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\n## a      0.00       0 0.10 -0.19 -0.07  0.00  0.07  0.20  3754    1\n## bM    -0.06       0 0.15 -0.36 -0.17 -0.06  0.04  0.24  2518    1\n## bA    -0.61       0 0.15 -0.91 -0.71 -0.61 -0.51 -0.31  2568    1\n## sigma  0.83       0 0.09  0.68  0.76  0.82  0.88  1.02  3049    1\n## \n## Samples were drawn using NUTS(diag_e) at Wed Sep 21 11:06:44 2022.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\n\n\n# get_variables(model_marriage_divorce_stan)\n\nmodel_marriage_divorce_stan %>% \n  gather_draws(a, bM, bA, sigma) %>% \n  mutate(.variable = factor(.variable, levels = c(\"a\", \"bM\", \"bA\", \"sigma\"))) %>% \n  ggplot(aes(x = .value, y = fct_rev(.variable))) +\n  stat_halfeye() +\n  coord_cartesian(xlim = c(-1, 1))\n\n\n\n\n\n\n\n\n\nSimulating causal effects\nWe can make counterfactual plots if we model the whole system, just like the “full luxury Bayes” model from video 4.\nWe want to know the causal effect of the marriage rate on the divorce rate, or:\n\\[\nE(\\text{Divorce rate} \\mid \\operatorname{do}(\\text{Marriage rate}))\n\\]\nHere’s model for the whole system:\n\\[\n\\begin{aligned}\nM_i &\\sim \\mathcal{N}(\\nu_i, \\tau) \\\\\nD_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\nu_i &= \\alpha_M + \\beta_{AM} A_i \\\\\n\\mu_i &= \\alpha + \\beta_M M_i + \\beta_A A_i \\\\\n\\\\\n\\alpha_M &\\sim \\mathcal{N}(0, 0.2) \\\\\n\\alpha &\\sim \\mathcal{N}(0, 0.2) \\\\\n\\beta_{AM} &\\sim \\mathcal{N}(0, 0.5) \\\\\n\\beta_M &\\sim \\mathcal{N}(0, 0.5) \\\\\n\\beta_A &\\sim \\mathcal{N}(0, 0.5) \\\\\n\\tau &\\sim \\operatorname{Exponential}(1) \\\\\n\\sigma &\\sim \\operatorname{Exponential}(1)\n\\end{aligned}\n\\]\n\nbrmsStan\n\n\n\npriors <- c(prior(normal(0, 0.2), class = Intercept, resp = Divorcez),\n            prior(normal(0, 0.5), class = b, coef = \"Marriage_z\", resp = Divorcez),\n            prior(normal(0, 0.5), class = b, coef = \"MedianAgeMarriage_z\", resp = Divorcez),\n            prior(exponential(1), class = sigma, resp = Divorcez),\n            \n            prior(normal(0, 0.2), class = Intercept, resp = Marriagez),\n            prior(normal(0, 0.5), class = b, coef = \"MedianAgeMarriage_z\", resp = Marriagez),\n            prior(exponential(1), class = sigma, resp = Marriagez))\n\nmodel_dag_full <- brm(\n  bf(Divorce_z ~ Marriage_z + MedianAgeMarriage_z) +\n    bf(Marriage_z ~ MedianAgeMarriage_z) + \n    set_rescor(FALSE),\n  data = WaffleDivorce,\n  family = gaussian(),\n  prior = priors,\n  chains = 4, cores = 4, seed = BAYES_SEED\n)\n## Compiling Stan program...\n## Start sampling\n\n\nprint(model_dag_full)\n##  Family: MV(gaussian, gaussian) \n##   Links: mu = identity; sigma = identity\n##          mu = identity; sigma = identity \n## Formula: Divorce_z ~ Marriage_z + MedianAgeMarriage_z \n##          Marriage_z ~ MedianAgeMarriage_z \n##    Data: WaffleDivorce (Number of observations: 50) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                               Estimate Est.Error l-95% CI u-95% CI Rhat\n## Divorcez_Intercept                0.00      0.10    -0.20     0.19 1.00\n## Marriagez_Intercept               0.00      0.09    -0.18     0.19 1.00\n## Divorcez_Marriage_z              -0.06      0.16    -0.36     0.25 1.00\n## Divorcez_MedianAgeMarriage_z     -0.61      0.16    -0.91    -0.29 1.00\n## Marriagez_MedianAgeMarriage_z    -0.69      0.10    -0.89    -0.48 1.00\n##                               Bulk_ESS Tail_ESS\n## Divorcez_Intercept                5471     2861\n## Marriagez_Intercept               5718     2909\n## Divorcez_Marriage_z               3565     3160\n## Divorcez_MedianAgeMarriage_z      3484     2710\n## Marriagez_MedianAgeMarriage_z     4943     2673\n## \n## Family Specific Parameters: \n##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma_Divorcez      0.83      0.09     0.68     1.02 1.00     4322     2680\n## sigma_Marriagez     0.71      0.07     0.58     0.87 1.00     4992     3220\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nsim_age_divorce <- tibble(MedianAgeMarriage_z = seq(from = -2, to = 2, length.out = 40),\n                          Marriage_z = 0) %>% \n  add_predicted_draws(model_dag_full, resp = \"Divorcez\")\n\nggplot(sim_age_divorce, aes(x = MedianAgeMarriage_z, y = .prediction)) +\n  stat_lineribbon(.width = 0.89, color = clrs[5], fill = clrs[5], alpha = 0.5) +\n  labs(title = \"Total counterfactual effect of age on divorce rate\",\n       subtitle = \"A → D in the DAG\")\n\n\n\n\n\nsim_age_marriage <- tibble(MedianAgeMarriage_z = seq(from = -2, to = 2, length.out = 40)) %>% \n  add_predicted_draws(model_dag_full, resp = \"Marriagez\")\n\nggplot(sim_age_marriage, aes(x = MedianAgeMarriage_z, y = .prediction)) +\n  stat_lineribbon(.width = 0.89, color = clrs[6], fill = clrs[6], alpha = 0.5) +\n  labs(title = \"Counterfactual effect of age on marriage rate\",\n       subtitle = \"A → M in the DAG\")\n\n\n\n\n\nsim_age_marriage_divorce <- tibble(Marriage_z = seq(from = -2, to = 2, length.out = 40),\n                                   MedianAgeMarriage_z = 0) %>% \n  add_predicted_draws(model_dag_full, resp = \"Marriagez\")\n\nggplot(sim_age_marriage_divorce, aes(x = Marriage_z, y = .prediction)) +\n  stat_lineribbon(.width = 0.89, color = clrs[3], fill = clrs[3], alpha = 0.5) +\n  labs(title = \"Total counterfactual effect of marriage rate on divorce rate\",\n       subtitle = \"M → D, after adjusting for A in the DAG, or E(D | do(M))\")\n\n\n\n\n\n\nmarriage_dag_full_stan.stan\n\ndata {\n  int<lower=1> n;  // Observations\n  vector[n] Divorce_z;  // Outcome: divorce rate\n  vector[n] Marriage_z;  // \"Treatment\": marriage rate\n  vector[n] MedianAgeMarriage_z;  // Confounder: age\n}\n\nparameters {\n  // Age -> Marriage\n  real aM;\n  real bAM;\n  real<lower=0> tau;\n\n  // Age -> Divorce <- Marriage\n  real a;\n  real bM;\n  real bA;\n  real<lower=0> sigma;\n}\n\nmodel {\n  vector[n] nu;\n  vector[n] mu;\n  \n  // Age -> Marriage\n  aM ~ normal(0, 0.2);\n  bAM ~ normal(0, 0.5);\n  tau ~ exponential(1);\n  \n  nu = aM + bAM*MedianAgeMarriage_z;\n  \n  Marriage_z ~ normal(nu, tau);\n\n  // Age -> Divorce <- Marriage\n  a ~ normal(0, 0.2);\n  bM ~ normal(0, 0.5);\n  bA ~ normal(0, 0.5);\n  sigma ~ exponential(1);\n  \n  mu = a + bM*Marriage_z + bA*MedianAgeMarriage_z;\n\n  Divorce_z ~ normal(mu, sigma);\n}\n\ngenerated quantities {\n  vector[n] Divorce_z_rep;\n  vector[n] Marriage_z_rep;\n  vector[n] divorce_do_marriage;\n  \n  for (i in 1:n) {\n    real nu_hat_n = aM + bAM*MedianAgeMarriage_z[i];\n    real mu_hat_n = a + bM*Marriage_z[i] + bA*MedianAgeMarriage_z[i];\n\n    Marriage_z_rep[i] = normal_rng(nu_hat_n, tau);\n    Divorce_z_rep[i] = normal_rng(mu_hat_n, sigma);\n    divorce_do_marriage[i] = normal_rng(a + bM*Marriage_z_rep[i] + bA*0, sigma);\n  }\n}\n\n\nstan_data <- WaffleDivorce %>% \n  select(Divorce_z, Marriage_z, MedianAgeMarriage_z) %>% \n  compose_data()\n\nmodel_marriage_dag_full_stan <- rstan::sampling(\n  object = marriage_dag_full_stan,\n  data = stan_data,\n  iter = 2000, warmup = 1000, seed = BAYES_SEED, chains = 4, cores = 4\n)\n\n\nprint(model_marriage_dag_full_stan,\n      pars = c(\"aM\", \"bAM\", \"tau\", \"a\", \"bM\", \"bA\", \"sigma\"))\n## Inference for Stan model: ea32b2c9a1ab179009a8845d85ea5d42.\n## 4 chains, each with iter=2000; warmup=1000; thin=1; \n## post-warmup draws per chain=1000, total post-warmup draws=4000.\n## \n##        mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat\n## aM     0.00       0 0.09 -0.18 -0.07  0.00  0.06  0.18  5552    1\n## bAM   -0.69       0 0.10 -0.88 -0.75 -0.69 -0.63 -0.50  5583    1\n## tau    0.71       0 0.08  0.58  0.66  0.70  0.76  0.88  5465    1\n## a      0.00       0 0.10 -0.20 -0.07  0.00  0.07  0.20  5541    1\n## bM    -0.06       0 0.16 -0.37 -0.17 -0.06  0.05  0.25  2842    1\n## bA    -0.61       0 0.16 -0.92 -0.71 -0.61 -0.50 -0.29  3314    1\n## sigma  0.83       0 0.09  0.68  0.77  0.82  0.88  1.03  5675    1\n## \n## Samples were drawn using NUTS(diag_e) at Wed Sep 21 11:07:06 2022.\n## For each parameter, n_eff is a crude measure of effective sample size,\n## and Rhat is the potential scale reduction factor on split chains (at \n## convergence, Rhat=1).\n\n\nstan_age_divorce <- model_marriage_dag_full_stan %>% \n  spread_draws(Divorce_z_rep[i]) %>% \n  mean_hdci() %>% \n  mutate(age = WaffleDivorce$MedianAgeMarriage_z)\n\nggplot(stan_age_divorce, aes(x = age, y = Divorce_z_rep)) +\n  geom_line(color = clrs[5]) +\n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.2, fill = clrs[5]) +\n  coord_cartesian(xlim = c(-2, 2)) +\n  labs(title = \"Total counterfactual effect of age on divorce rate\",\n       subtitle = \"A → D in the DAG\")\n\n\n\n\n\nstan_age_marriage <- model_marriage_dag_full_stan %>% \n  spread_draws(Marriage_z_rep[i]) %>% \n  mean_hdci() %>% \n  mutate(age = WaffleDivorce$MedianAgeMarriage_z)\n\nggplot(stan_age_marriage, aes(x = age, y = Marriage_z_rep)) +\n  geom_line(color = clrs[6]) +\n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.2, fill = clrs[6]) +\n  coord_cartesian(xlim = c(-2, 2)) +\n  labs(title = \"Counterfactual effect of age on marriage rate\",\n       subtitle = \"A → M in the DAG\")\n\n\n\n\n\nstan_age_marriage_divorce <- model_marriage_dag_full_stan %>% \n  spread_draws(divorce_do_marriage[i]) %>% \n  mean_hdci() %>% \n  mutate(age = WaffleDivorce$MedianAgeMarriage_z)\n\nggplot(stan_age_marriage_divorce, aes(x = age, y = divorce_do_marriage)) +\n  geom_line(color = clrs[3]) +\n  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.2, fill = clrs[3]) +\n  coord_cartesian(xlim = c(-2, 2)) +\n  labs(title = \"Total counterfactual effect of marriage rate on divorce rate\",\n       subtitle = \"M → D, after adjusting for A in the DAG, or E(D | do(M))\")\n\n\n\n\n\n\n\n\n\n\n\nThe pipe (mediators)\n\\[\nX \\rightarrow Z \\rightarrow Y\n\\]\n\\(X\\) and \\(Y\\) are associated (\\(Y \\notind X\\)) because influence of \\(X\\) is passed to \\(Y\\) through \\(Z\\). After adjusting for \\(Z\\), though, there’s no association, or \\(Y \\ind X \\mid Z\\).\n\nSimulated example\n\nn <- 1000\n\npipe_sim <- tibble(X = rbinom(n, 1, prob = 0.5)) %>% \n  # When X is 0, there's a 10% chance of Z being 1\n  # When X is 1, there's a 90% chance of Z being 1\n  # When Z is 0, there's a 10% chance of Y being 1\n  # When Z is 1, there's a 90% chance of Y being 1\n  mutate(Z = rbinom(n, 1, prob = ((1 - X) * 0.1) + (X * 0.9)),\n         Y = rbinom(n, 1, prob = ((1 - Z) * 0.1) + (Z * 0.9)))\n\npipe_sim %>% \n  select(-Z) %>% \n  table()\n##    Y\n## X     0   1\n##   0 403  92\n##   1  73 432\n\npipe_sim %>% \n  summarize(cor = cor(X, Y))\n## # A tibble: 1 × 1\n##     cor\n##   <dbl>\n## 1 0.670\n\nBut if we adjust for \\(Z\\), \\(Y \\ind X \\mid Z\\):\n\npipe_sim %>% \n  select(X, Y, Z) %>%\n  table()\n## , , Z = 0\n## \n##    Y\n## X     0   1\n##   0 401  58\n##   1  33   4\n## \n## , , Z = 1\n## \n##    Y\n## X     0   1\n##   0   2  34\n##   1  40 428\n\npipe_sim %>% \n  group_by(Z) %>% \n  summarize(cor = cor(X, Y))\n## # A tibble: 2 × 2\n##       Z     cor\n##   <int>   <dbl>\n## 1     0 -0.0145\n## 2     1 -0.0279\n\nThis also works with continuous data. When looking at all values of \\(Z\\), there’s a positive slope and relationship; when looking within each group, the relationship is 0 and flat.\n\nn <- 300\n\npipe_sim_cont <- tibble(X = rnorm(n, 0, 1)) %>% \n  mutate(Z = rbinom(n, 1, plogis(X)),\n         Y = rnorm(n, (2 * Z - 1), 1))\n\nggplot(pipe_sim_cont, aes(x = X, y = Y, color = factor(Z))) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_smooth(aes(color = NULL), method = \"lm\")\n\n\n\n\n\n\nFungus experiment example\nWith this DAG, we shouldn’t adjust for \\(F\\), since that would block the effect of the fungus, which in this case is super important since the causal mechanism pretty much only flows through \\(F\\). If we adjust for \\(F\\), we’ll get the causal effect of the treatment on height without the effect of the fungus, which is weird and probably 0.\n\nplant_fungus_dag <- dagify(\n  h1 ~ t + f + h0,\n  f ~ t,\n  exposure = \"t\",\n  outcome = \"h1\",\n  labels = c(t = \"Treatment\", h1 = \"Height, t=1\", f = \"Fungus\", h0 = \"Height, t=0\"),\n  coords = list(x = c(t = 1, h1 = 3, f = 2, h0 = 3),\n                y = c(t = 1, h1 = 1, f = 2, h0 = 2))) %>% \n  tidy_dagitty() %>% \n  node_status()\n\nggplot(plant_fungus_dag, aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges() +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_text(aes(label = label), size = 3.5, color = \"black\") +\n  scale_color_manual(values = clrs[c(1, 4)], guide = \"none\") +\n  theme_dag()\n\n\n\n\n\n\n\n\nIn general this is called post-treatment bias and it is bad.\n\n\n\nThe collider (colliders, obvs)\n\\[\nX \\rightarrow Z \\leftarrow Y\n\\]\n\\(X\\) and \\(Y\\) are not associated (\\(Y \\ind X\\)), but they both influence \\(Z\\). Once you adjust for \\(Z\\), \\(X\\) and \\(Y\\) become associated and \\(Y \\notind X \\mid Z\\).\nWhen we learn about \\(Z\\) (or stratify by \\(Z\\), or only look at specific values of \\(Z\\)), we necessarily learn something about \\(X\\) and \\(Y\\), since they helped generate \\(Z\\)\n\nSimulated example\n\nn <- 1000\n\ncollider_sim <- tibble(X = rbinom(n, 1, prob = 0.5),\n                       Y = rbinom(n, 1, prob = 0.5)) %>% \n  # If either X and Y are 1, there's a 90% chance that Z will be 1\n  mutate(Z = rbinom(n, 1, prob = ifelse(X + Y > 0, 0.9, 0.2)))\n\n# These are independent\ncollider_sim %>% \n  select(-Z) %>% \n  table()\n##    Y\n## X     0   1\n##   0 248 253\n##   1 240 259\n\n# No correlation\ncollider_sim %>% \n  summarize(cor = cor(X, Y))\n## # A tibble: 1 × 1\n##      cor\n##    <dbl>\n## 1 0.0141\n\nWhen we adjust for \\(Z\\), though, \\(Y \\notind X \\mid Z\\):\n\ncollider_sim %>% \n  select(X, Y, Z) %>%\n  table()\n## , , Z = 0\n## \n##    Y\n## X     0   1\n##   0 206  25\n##   1  27  17\n## \n## , , Z = 1\n## \n##    Y\n## X     0   1\n##   0  42 228\n##   1 213 242\n\n# They're correlated!\ncollider_sim %>% \n  group_by(Z) %>% \n  summarize(cor = cor(X, Y))\n## # A tibble: 2 × 2\n##       Z    cor\n##   <int>  <dbl>\n## 1     0  0.283\n## 2     1 -0.316\n\nAs with the others, this works with continuous data too. When ignoring values of \\(Z\\), there’s no relationship between \\(X\\) and \\(Y\\). But once we adjust for or stratify by \\(Z\\), there’s a relationship within each group.\n\nn <- 300\n\ncollider_sim_cont <- tibble(X = rnorm(n, 0, 1),\n                            Y = rnorm(n, 0, 1)) %>% \n  mutate(Z = rbinom(n, 1, plogis(2*X + 2*Y - 2)))\n\nggplot(collider_sim_cont, aes(x = X, y = Y, color = factor(Z))) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_smooth(aes(color = NULL), method = \"lm\")\n\n\n\n\n\n\nGrant selection example\n\nset.seed(1914)\n\nn <- 200\n\ngrants <- tibble(newsworthiness = rnorm(n, 0, 1),\n                 trustworthiness = rnorm(n, 0, 1)) %>% \n  mutate(total = newsworthiness + trustworthiness) %>% \n  # Select just the top 10%\n  mutate(q = quantile(total, 1 - 0.1)) %>% \n  mutate(selected = total >= q)\n\n# No relationship\ngrants %>% \n  summarize(cor = cor(newsworthiness, trustworthiness))\n## # A tibble: 1 × 1\n##       cor\n##     <dbl>\n## 1 -0.0672\n\n# Relationship!\ngrants %>% \n  group_by(selected) %>% \n  summarize(cor = cor(newsworthiness, trustworthiness))\n## # A tibble: 2 × 2\n##   selected    cor\n##   <lgl>     <dbl>\n## 1 FALSE    -0.274\n## 2 TRUE     -0.768\n\nggplot(grants, aes(x = newsworthiness, y = trustworthiness, color = selected)) +\n  geom_point() +\n  geom_smooth(data = filter(grants, selected), method = \"lm\") +\n  geom_smooth(aes(color = \"Full sample\"), method = \"lm\")\n\n\n\n\n\n\n\nThe descendant\nLike a confounder if it comes from a confounder; like a mediator if it comes from a mediator; like a collider if it comes from a collider.\n\\(X\\) and \\(Y\\) are causally associated through \\(Z\\), which implies that \\(Y \\notind X\\). \\(A\\) contains information about \\(Z\\), so once we stratify by or adjust for \\(A\\), \\(X\\) and \\(Y\\) become less associated (if \\(A\\) is strong enough), implying \\(Y \\ind X \\mid A\\)\nThat can be good (if \\(A\\) is confounder-flavored) or bad (if \\(A\\) is mediator- or collider-flavored).\n\ndesc_confounder_dag <- dagify(\n  Y ~ Z,\n  X ~ Z,\n  A ~ Z,\n  coords = list(x = c(X = 1, Y = 3, Z = 2, A = 2),\n                y = c(X = 1, Y = 1, Z = 1, A = 0))) %>% \n  tidy_dagitty()\n\ndesc_mediator_dag <- dagify(\n  Y ~ Z,\n  Z ~ X,\n  A ~ Z,\n  coords = list(x = c(X = 1, Y = 3, Z = 2, A = 2),\n                y = c(X = 1, Y = 1, Z = 1, A = 0))) %>% \n  tidy_dagitty()\n\ndesc_collider_dag <- dagify(\n  Z ~ X + Y,\n  A ~ Z,\n  coords = list(x = c(X = 1, Y = 3, Z = 2, A = 2),\n                y = c(X = 1, Y = 1, Z = 1, A = 0))) %>% \n  tidy_dagitty()\n\nplot_desc_confounder <- ggplot(desc_confounder_dag, \n                               aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges() +\n  geom_dag_point() +\n  geom_dag_text(aes(label = name), size = 3.5, color = \"white\") +\n  ylim(c(-0.25, 1.25)) +\n  labs(subtitle = \"Confounder-flavored descendant\") +\n  theme_dag() +\n  theme(plot.subtitle = element_text(hjust = 0.5, face = \"bold\"))\n\nplot_desc_mediator <- ggplot(desc_mediator_dag, \n                             aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges() +\n  geom_dag_point() +\n  geom_dag_text(aes(label = name), size = 3.5, color = \"white\") +\n  ylim(c(-0.25, 1.25)) +\n  labs(subtitle = \"Mediator-flavored descendant\") +\n  theme_dag() +\n  theme(plot.subtitle = element_text(hjust = 0.5, face = \"bold\"))\n\nplot_desc_collider <- ggplot(desc_collider_dag, \n                             aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges() +\n  geom_dag_point() +\n  geom_dag_text(aes(label = name), size = 3.5, color = \"white\") +\n  ylim(c(-0.25, 1.25)) +\n  labs(subtitle = \"Collider-flavored descendant\") +\n  theme_dag() +\n  theme(plot.subtitle = element_text(hjust = 0.5, face = \"bold\"))\n\nplot_desc_confounder + plot_desc_mediator + plot_desc_collider"
  },
  {
    "objectID": "rethinking/06-video.html",
    "href": "rethinking/06-video.html",
    "title": "Video #6 code",
    "section": "",
    "text": "No code here; the lecture is a good overview of DAGs and good/bad controls.\n\nlibrary(tidyverse)\nlibrary(furrr)\nlibrary(ggdag)\nlibrary(ggraph)\nlibrary(patchwork)\n\n# Parallel stuff\nplan(multisession, workers = 4)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nset.seed(1234)\n\n\nPost-treatment mediator\nIf we have this DAG, where \\(Z\\) is a mediator between \\(X\\) and \\(Y\\), and \\(u\\) is some unobserved confounding, should we control for \\(Z\\)? No!\n\n\nCode\ndagify(\n  Y ~ Z + u,\n  Z ~ X + u,\n  exposure = \"X\",\n  outcome = \"Y\",\n  latent = \"u\",  \n  coords = list(x = c(X = 1, Y = 4, Z = 2, u = 3),\n                y = c(X = 1, Y = 1, Z = 1, u = 2))) %>% \n  tidy_dagitty() %>% \n  node_status() %>% \n  as_tibble() %>% \n  left_join(tribble(\n    ~name, ~to, ~coef,\n    \"X\",   \"Z\", 1,\n    \"u\",   \"Z\", 1,\n    \"u\",   \"Y\", 1,\n    \"Z\",   \"Y\", 1\n  ), by = c(\"name\", \"to\")) %>% \n  mutate(latent = status == \"latent\",\n         latent = ifelse(is.na(latent), FALSE, latent)) %>% \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges(aes(edge_linetype = latent, label = coef), \n                 angle_calc = \"along\", label_dodge = grid::unit(10, 'points')) +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_text(aes(label = name), size = 3.5, color = \"white\") +\n  scale_color_manual(values = c(clrs[1], \"grey50\", clrs[4]), \n                     na.value = \"black\", guide = \"none\") +\n  scale_edge_linetype_manual(values = c(\"solid\", \"43\"), guide = \"none\") +\n  ylim(c(0.9, 2.1)) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\nHere’s a simulation to show why. It uses completely random and independent values for \\(X\\) and \\(u\\), and \\(Z\\) and \\(Y\\) are determined by coefficients (1 in this case). When using the model Y ~ X, \\(X\\) has the correct coefficient (0); when using the model Y ~ X + Z, the coefficient for \\(X\\) is super wrong and negative:\n\nn <- 100\nbXZ <- 1\nbZY <- 1\n\nsim <- tibble(sim_id = 1:1000) %>% \n  mutate(sim = future_map(sim_id, ~{\n    tibble(\n      X = rnorm(n),\n      u = rnorm(n),\n      Z = rnorm(n, bXZ*X + u),\n      Y = rnorm(n, bZY*Z + u)\n    )\n  }, .options = furrr_options(seed = TRUE))) %>% \n  mutate(bX = future_map_dbl(sim, ~coef(lm(Y ~ X, data = .))[\"X\"]),\n         bXZ = future_map_dbl(sim, ~coef(lm(Y ~ X + Z, data = .))[\"X\"]))\n\nsim %>%\n  select(-sim) %>%\n  pivot_longer(starts_with(\"b\")) %>% \n  mutate(correct = ifelse(name == \"bX\", \"Correct\", \"Wrong\"),\n         name = recode(name, \"bX\" = \"Y ~ X\", \"bXZ\" = \"Y ~ X + Z\")) %>%\n  ggplot(aes(x = value, color = name, linetype = correct)) +\n  geom_density(size = 1) +\n  scale_color_manual(values = c(clrs[5], clrs[2])) +\n  scale_linetype_manual(values = c(\"solid\", \"dotted\")) +\n  xlim(c(-1.5, 2)) +\n  labs(x = \"β for X\", linetype = NULL, color = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nWe can see the same thing even if the coefficient between \\(Z\\) and \\(Y\\) is set to zero:\n\n\nCode\ndagify(\n  Y ~ Z + u,\n  Z ~ X + u,\n  exposure = \"X\",\n  outcome = \"Y\",\n  latent = \"u\",  \n  coords = list(x = c(X = 1, Y = 4, Z = 2, u = 3),\n                y = c(X = 1, Y = 1, Z = 1, u = 2))) %>% \n  tidy_dagitty() %>% \n  node_status() %>% \n  as_tibble() %>% \n  left_join(tribble(\n    ~name, ~to, ~coef,\n    \"X\",   \"Z\", 1,\n    \"u\",   \"Z\", 1,\n    \"u\",   \"Y\", 1,\n    \"Z\",   \"Y\", 0\n  ), by = c(\"name\", \"to\")) %>% \n  mutate(latent = status == \"latent\",\n         latent = ifelse(is.na(latent), FALSE, latent)) %>% \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges(aes(edge_linetype = latent, label = coef), \n                 angle_calc = \"along\", label_dodge = grid::unit(10, 'points')) +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_text(aes(label = name), size = 3.5, color = \"white\") +\n  scale_color_manual(values = c(clrs[1], \"grey50\", clrs[4]), \n                     na.value = \"black\", guide = \"none\") +\n  scale_edge_linetype_manual(values = c(\"solid\", \"43\"), guide = \"none\") +\n  ylim(c(0.9, 2.1)) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\nn <- 100\nbXZ <- 1\nbZY <- 0\n\nsim <- tibble(sim_id = 1:1000) %>% \n  mutate(sim = future_map(sim_id, ~{\n    tibble(\n      X = rnorm(n),\n      u = rnorm(n),\n      Z = rnorm(n, bXZ*X + u),\n      Y = rnorm(n, bZY*Z + u)\n    )\n  }, .options = furrr_options(seed = TRUE))) %>% \n  mutate(bX = future_map_dbl(sim, ~coef(lm(Y ~ X, data = .))[\"X\"]),\n         bXZ = future_map_dbl(sim, ~coef(lm(Y ~ X + Z, data = .))[\"X\"]))\n\nsim %>%\n  select(-sim) %>%\n  pivot_longer(starts_with(\"b\")) %>% \n  mutate(correct = ifelse(name == \"bX\", \"Correct\", \"Wrong\"),\n         name = recode(name, \"bX\" = \"Y ~ X\", \"bXZ\" = \"Y ~ X + Z\")) %>%\n  ggplot(aes(x = value, color = name, linetype = correct)) +\n  geom_density(size = 1) +\n  scale_color_manual(values = c(clrs[5], clrs[2])) +\n  scale_linetype_manual(values = c(\"solid\", \"dotted\")) +\n  xlim(c(-1.5, 2)) +\n  labs(x = \"β for X\", linetype = NULL, color = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nCase-control bias\nHere \\(Z\\) comes after the outcome, like if \\(X\\) is education, \\(Y\\) is occupation, and \\(Z\\) is income. Should we control for \\(Z\\)? Surely that’s harmless?\nNope!\n\n\nCode\ndagify(\n  Y ~ X,\n  Z ~ Y,\n  exposure = \"X\",\n  outcome = \"Y\",\n  coords = list(x = c(X = 1, Y = 2, Z = 3),\n                y = c(X = 1, Y = 1, Z = 1))) %>% \n  tidy_dagitty() %>% \n  node_status() %>% \n  as_tibble() %>% \n  left_join(tribble(\n    ~name, ~to, ~coef,\n    \"X\",   \"Y\", 1,\n    \"Y\",   \"Z\", 1\n  ), by = c(\"name\", \"to\")) %>% \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges(aes(label = coef), \n                 angle_calc = \"along\", label_dodge = grid::unit(10, 'points')) +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_text(aes(label = name), size = 3.5, color = \"white\") +\n  scale_color_manual(values = c(clrs[1], clrs[4]), \n                     na.value = \"black\", guide = \"none\") +\n  xlim(c(0.75, 3.25)) + ylim(c(0.9, 1.1)) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\nn <- 100\nbXY <- 1\nbYZ <- 1\n\nsim <- tibble(sim_id = 1:1000) %>% \n  mutate(sim = future_map(sim_id, ~{\n    tibble(\n      X = rnorm(n),\n      Z = rnorm(n, bXY*X),\n      Y = rnorm(n, bYZ*Z)\n    )\n  }, .options = furrr_options(seed = TRUE))) %>% \n  mutate(bX = future_map_dbl(sim, ~coef(lm(Y ~ X, data = .))[\"X\"]),\n         bXZ = future_map_dbl(sim, ~coef(lm(Y ~ X + Z, data = .))[\"X\"]))\n\nsim %>%\n  select(-sim) %>%\n  pivot_longer(starts_with(\"b\")) %>% \n  mutate(correct = ifelse(name == \"bX\", \"Correct\", \"Wrong\"),\n         name = recode(name, \"bX\" = \"Y ~ X\", \"bXZ\" = \"Y ~ X + Z\")) %>%\n  ggplot(aes(x = value, color = name, linetype = correct)) +\n  geom_density(size = 1) +\n  scale_color_manual(values = c(clrs[5], clrs[2])) +\n  scale_linetype_manual(values = c(\"solid\", \"dotted\")) +\n  xlim(c(-1, 2)) +\n  labs(x = \"β for X\", linetype = NULL, color = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nPrecision parasite\nHere \\(Z\\) comes before the treatment and doesn’t open any backdoors. Should we control for it? Again, it should be harmless?\nIn this case, it doesn’t distort the effect, but it does reduce the precision of the estimate\n\n\nCode\ndagify(\n  Y ~ X,\n  X ~ Z,\n  exposure = \"X\",\n  outcome = \"Y\",\n  coords = list(x = c(X = 2, Y = 3, Z = 1),\n                y = c(X = 1, Y = 1, Z = 1))) %>% \n  tidy_dagitty() %>% \n  node_status() %>% \n  as_tibble() %>% \n  left_join(tribble(\n    ~name, ~to, ~coef,\n    \"X\",   \"Y\", 1,\n    \"Z\",   \"X\", 1\n  ), by = c(\"name\", \"to\")) %>% \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges(aes(label = coef), \n                 angle_calc = \"along\", label_dodge = grid::unit(10, 'points')) +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_text(aes(label = name), size = 3.5, color = \"white\") +\n  scale_color_manual(values = c(clrs[1], clrs[4]), \n                     na.value = \"black\", guide = \"none\") +\n  xlim(c(0.75, 3.25)) + ylim(c(0.9, 1.1)) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\nn <- 100\nbZX <- 1\nbXY <- 1\n\nsim <- tibble(sim_id = 1:1000) %>% \n  mutate(sim = future_map(sim_id, ~{\n    tibble(\n      Z = rnorm(n),\n      X = rnorm(n, bZX*Z),\n      Y = rnorm(n, bXY*X)\n    )\n  }, .options = furrr_options(seed = TRUE))) %>% \n  mutate(bX = future_map_dbl(sim, ~coef(lm(Y ~ X, data = .))[\"X\"]),\n         bXZ = future_map_dbl(sim, ~coef(lm(Y ~ X + Z, data = .))[\"X\"]))\n\nsim %>%\n  select(-sim) %>%\n  pivot_longer(starts_with(\"b\")) %>% \n  mutate(correct = ifelse(name == \"bX\", \"Correct\", \"Wrong\"),\n         name = recode(name, \"bX\" = \"Y ~ X\", \"bXZ\" = \"Y ~ X + Z\")) %>%\n  ggplot(aes(x = value, color = name, linetype = correct)) +\n  geom_density(size = 1) +\n  scale_color_manual(values = c(clrs[5], clrs[2])) +\n  scale_linetype_manual(values = c(\"solid\", \"dotted\")) +\n  xlim(c(0.5, 1.5)) +\n  labs(x = \"β for X\", linetype = NULL, color = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nBias amplification\nLike the precision parasite situation, but with an unobserved confounder \\(u\\). Really bad stuff happens here (“something truly awful” in the lecture). The true coefficient between \\(X\\) and \\(Y\\) here is 0, but the estimate is wrong with both models!\nIncluding causes of the exposure is generally a really bad idea. Covariation in \\(X\\) and \\(Y\\) requires variation in their causes, but within different levels of \\(Z\\) (since we’re stratifying by or adjusting for \\(Z\\)), there’s less variation in \\(X\\). That makes the unobserved \\(u\\) confounder more important when determining \\(X\\).\n\n\nCode\ndagify(\n  Y ~ X + u,\n  X ~ Z + u,\n  exposure = \"X\",\n  outcome = \"Y\",\n  latent = \"u\",  \n  coords = list(x = c(X = 2, Y = 4, Z = 1, u = 3),\n                y = c(X = 1, Y = 1, Z = 1, u = 2))) %>% \n  tidy_dagitty() %>% \n  node_status() %>% \n  as_tibble() %>% \n  left_join(tribble(\n    ~name, ~to, ~coef,\n    \"X\",   \"Y\", 0,\n    \"u\",   \"X\", 1,\n    \"u\",   \"Y\", 1,\n    \"Z\",   \"X\", 1\n  ), by = c(\"name\", \"to\")) %>% \n  mutate(latent = status == \"latent\",\n         latent = ifelse(is.na(latent), FALSE, latent)) %>% \n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges(aes(edge_linetype = latent, label = coef), \n                 angle_calc = \"along\", label_dodge = grid::unit(10, 'points')) +\n  geom_dag_point(aes(color = status)) +\n  geom_dag_text(aes(label = name), size = 3.5, color = \"white\") +\n  scale_color_manual(values = c(clrs[1], \"grey50\", clrs[4]), \n                     na.value = \"black\", guide = \"none\") +\n  scale_edge_linetype_manual(values = c(\"solid\", \"43\"), guide = \"none\") +\n  ylim(c(0.9, 2.1)) +\n  theme_dag()\n\n\n\n\n\n\n\n\n\n\nn <- 100\nbZX <- 1\nbXY <- 0\n\nsim <- tibble(sim_id = 1:1000) %>% \n  mutate(sim = future_map(sim_id, ~{\n    tibble(\n      Z = rnorm(n),\n      u = rnorm(n),\n      X = rnorm(n, bZX*Z + u),\n      Y = rnorm(n, bXY*X + u)\n    )\n  }, .options = furrr_options(seed = TRUE))) %>% \n  mutate(bX = future_map_dbl(sim, ~coef(lm(Y ~ X, data = .))[\"X\"]),\n         bXZ = future_map_dbl(sim, ~coef(lm(Y ~ X + Z, data = .))[\"X\"]))\n\nsim %>%\n  select(-sim) %>%\n  pivot_longer(starts_with(\"b\")) %>% \n  mutate(correct = ifelse(name == \"bX\", \"Wrong\", \"Wrong but worse\"),\n         name = recode(name, \"bX\" = \"Y ~ X\", \"bXZ\" = \"Y ~ X + Z\")) %>%\n  ggplot(aes(x = value, color = name, linetype = correct)) +\n  geom_density(size = 1) +\n  scale_color_manual(values = c(clrs[5], clrs[2])) +\n  scale_linetype_manual(values = c(\"dashed\", \"dotted\")) +\n  geom_vline(xintercept = 0) +\n  annotate(geom = \"text\", x = -0.02, y = 2.5, label = \"Actual value\", angle = 90) +\n  xlim(c(-0.15, 1)) +\n  labs(x = \"β for X\", linetype = NULL, color = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nThis whole idea that controlling for \\(Z\\) in the presence of unmeasured confounding amplifies the bias is really weird. Here’s another simulation from McElreath’s slides, where there is no relationship between \\(X\\) and \\(Y\\). There is a slight relationship between \\(X\\) and \\(Y\\) because of \\(u\\), but once we stratify by \\(Z\\), those slopes get bigger within each group!\n\ntibble(Z = rbinom(1000, 1, 0.5),\n       u = rnorm(1000)) %>% \n  mutate(X = rnorm(1000, 7*Z + u),\n         Y = rnorm(1000, 0*X + u)) %>% \n  ggplot(aes(x = X, y = Y, color = factor(Z))) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  geom_smooth(aes(color = NULL), method = \"lm\")"
  },
  {
    "objectID": "rethinking/index.html",
    "href": "rethinking/index.html",
    "title": "Statistical Rethinking",
    "section": "",
    "text": "General schedule:\n\n\n\n\n\n\n\n\n\nWeek\nTopic\nReading\nVideos\n\n\n\n\n1\nBayesian inference\nChapters 1, 2, 3\n1, 2\n\n\n2\nLinear models & causal inference\nChapter 4\n3, 4\n\n\n3\nCauses, confounds, & colliders\nChapters 5, 6\n5, 6\n\n\n4\nOverfitting & interactions\nChapters 7, 8\n7, 8\n\n\n5\nMCMC & generalized linear models\nChapters 9, 10, 11\n9, 10\n\n\n6\nIntegers & other monsters\nChapters 11, 12\n11, 12\n\n\n7\nMultilevel models I\nChapter 13\n13, 14\n\n\n8\nMultilevel models II\nChapter 14\n15, 16\n\n\n9\nMeasurement & missingness\nChapter 15\n17, 18\n\n\n10\nGeneralized linear madness\nChapter 16\n19, 20"
  },
  {
    "objectID": "bayes-rules/06-stan/why.html",
    "href": "bayes-rules/06-stan/why.html",
    "title": "`bayesf22` Notebook",
    "section": "",
    "text": "# Make it so Stan chunks in Rmd files use cmdstanr instead of rstan\n# This works when knitting, but not when running RStudio interactively\n# register_knitr_engine()\n\n# See ?register_knitr_engine for more on how to make it work interactively\n#\n# For interactive work, we can use override = FALSE and then specify engine =\n# \"cmdstan\" in the stan chunk options\nregister_knitr_engine(override = FALSE)"
  }
]