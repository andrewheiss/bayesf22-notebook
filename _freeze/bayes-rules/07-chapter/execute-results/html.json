{
  "hash": "5fbe4374eac43f4dbfdb733523e4f8f7",
  "result": {
    "markdown": "---\ntitle: \"Reading notes\"\nsubtitle: \"MCMC under the Hood\"\ndate: \"September 27, 2022\"\n---\n\n\n[(Original chapter)](https://www.bayesrulesbook.com/chapter-7.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nset.seed(1234)\n```\n:::\n\n\n# 7.1: The Big Idea\n\n*(SO EXCITED FOR THIS)*\n\nStan uses Hamiltonian Monte Carlo sampling; JAGS uses Gibbs sampling. Both of these are enhanced versions of the fundamental Metropolis-Hastings algorithm for sampling, which we'll implement here (yay!)\n\nThink of Markov chains as a tour around the range of posterior possible values of a parameter (like µ or π or whatever). The chains move around that parameter and hopefully converge around it, but the chains need a tour manager to do that properly.\n\n**Trace plots show the tour route; density plots show the relative amount of time spent at each stop or parameter region during the tour.**\n\nThe tour manager's goal is \"to ensure that the density of tour stops in each μ region is proportional to its posterior plausibility\"\n\nWe can automate the tour managing process with an algorithm, like the Metropolis-Hastings algorithm, which consists of two steps. \n\nAssume the Markov chain is at location $\\mu^{(i)}$ currently. In order to choose the next tour stop, or $\\mu^{(i + 1)}$, follow this process:\n\n1. Propose a random location for the next tour stop: $\\mu^\\prime$\n2. Decide whether to go to $\\mu^\\prime$ or stay at the current location $\\mu^{(i)}$ for another iteration\n\nThat's it. This simplified special version of Metropolis-Hastings is called the Monte Carlo algorithm.\n\nHere's how to implement it. Assume we have a *posterior* (calculated with magical conjugate prior families) like this:\n\n$$\n\\mu \\sim \\mathcal{N}(4, 0.6^2)\n$$\n\nWe can draw random values from that distribution and tour it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc_tour <- tibble(\n  mu = rnorm(5000, mean = 4, sd = 0.6)\n) |> \n  mutate(.iteration = 1:n())\n\n# Trace plot\nmc_tour |> \n  ggplot(aes(x = .iteration, y = mu)) +\n  geom_line(size = 0.1, alpha = 0.75)\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Density plot\nmc_tour |> \n  ggplot(aes(x = mu)) +\n  geom_histogram(aes(y = ..density..),binwidth = 0.25, \n                  color = \"white\", fill = clrs[2]) +\n  geom_function(fun = ~dnorm(., 4, 0.6), color = clrs[3])\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\nNeat! The trace plot shows that the tour was stable and had good coverage; the density plot shows that most of the time was spent around 4.\n\nBut this Monte Carlo algorithm is way too easy. We already know the posterior here! MCMC is great for approximating the posterior when math is too hard; if we can get the posterior through conjugate magic, there's no need to then randomly sample and tour the posterior. \n\nSo what do we do if we don't know the true posterior? We *do* know *some* of the posterior—the whole point of Bayes' rule is that the posterior is proportional to the prior and the likelihood:\n\n$$\n\\begin{aligned}\n\\text{Posterior} &\\propto \\text{Prior} \\times \\text{Likelihood} \\\\\nf(\\mu \\mid y = 6.25) &\\propto f(\\mu) \\times L(\\mu \\mid y = 6.25)\n\\end{aligned}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_data <- tibble(mu = seq(1, 7, length.out = 101)) |> \n  mutate(likelihood = dnorm(6.25, mean = mu, sd = 0.75),\n         prior = dnorm(mu, 0, 1)) |> \n  mutate(unnormalized = likelihood * prior)\n\nggplot(plot_data, aes(x = mu, y = unnormalized)) + \n  geom_area(fill = clrs[1]) +\n  labs(x = \"µ\", y = NULL,\n       title = \"Unnormalized posterior distribution\",\n       subtitle = \"Prior × L(µ | y = 6.25)\")\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis distribution isn't quite correct—it's not scaled correctly—but it does \"preserve the shape, central tendency, and variability of the actual posterior\". So we know *something* about the posterior that we can work with, and that can influence the sampling procedure.\n\nMetropolis-Hastings also does another neat thing. Instead of just choosing a new stop at random, it uses a proposal model to propose possible stops. There are lots of possible proposal models—in Bayes Rules they use a uniform proposal model with a half-width parameter $w$ that adds a window, or range, or neighborhood around the current µ location in the chain, or the current stop.\n\nSo if we're currently at $\\mu^{(i)}$, the proposal for the next stop will be drawn from a window of $\\mu^{(i)} \\pm w$, or more formally:\n\n$$\n\\mu^\\prime \\sim \\operatorname{Uniform}(\\mu^{(i)} - w, \\mu^{(i)} + w)\n$$\n\nIf we're currently at $\\mu = 3$, for instance, and we're using a half-width $w$ of 1, the proposal for the next draw will come from `runif(n = 1, min = 2, max = 4)`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(plot_data, aes(x = mu, y = unnormalized)) + \n  geom_area(fill = clrs[1]) +\n  labs(x = \"µ\", y = NULL,\n       title = \"Unnormalized posterior distribution\",\n       subtitle = \"Prior × L(µ | y = 6.25)\") +\n  scale_x_continuous(breaks = 1:7) +\n  annotate(geom = \"segment\", x = 2, xend = 4, y = 2e-7, yend = 2e-7) + \n  annotate(geom = \"segment\", x = 3, xend = 3, y = 2e-7, yend = 0, linetype = \"21\")\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nThe second step in the algorithm then decides if the proposal should be accepted or rejected. If the proposed $\\mu^\\prime$ is bad, the chain will hang out for a round before making another proposal, checking if it's good, and then maybe moving on.\n\nIf we're currently at 3 and we draw from $\\operatorname{Uniform}(2, 4)$ and get a 3.8, is that good? Yeah. That fits nicely in the unnormalized posterior distribution, so we should go there. If the uniform distribution proposes a 2, that's probably not great—that's really rare.\n\n# 7.2: The Metropolis-Hastings algorithm\n\nSo in general, Metropolis-Hastings does this:\n\n1. Propose a random location for the next tour stop, $\\mu^\\prime$, by drawing it from a proposal model\n2. Decide whether to go to $\\mu^\\prime$ or stay at the current location $\\mu^{(i)}$ for another iteration, based on this process:\n  - If the unnormalized posterior plausibility of $\\mu^\\prime > \\mu^{(i)}$, then **definitely go there**\n  - Otherwise **maybe go there**\n\nThat \"maybe go there\" part is determined based on an *acceptance* probability $\\alpha$. It's like a weighted coin flip—if it's heads, which has probability $\\alpha$, go there; if it's tails, which has probability $1 - \\alpha$, stay:\n\n$$\n\\mu^{(i+1)} = \n \\begin{cases}\n \\mu^\\prime & \\text{ with probability } \\alpha \\\\\n \\mu & \\text{ with probability } 1 - \\alpha\n \\end{cases}\n$$\n\nFormally, the weightedness of this coin flip (or the acceptance model in general) comes from the Metropolis algorithm, which has a symmetric proposal model. It looks like this:\n\n$$\n\\alpha = \\min\\left\\lbrace 1, \\; \\frac{f(\\mu^\\prime)\\ L(\\mu^\\prime \\mid y)}{f(\\mu)\\ L(\\mu \\mid y)} \\right\\rbrace\n$$\n\nOof that's a mess. Through some algebra (dividing the numerator and denominator by $f(y)$), we get this:\n\n$$\n\\alpha = \\min\\left\\lbrace 1, \\; \\frac{f(\\mu^\\prime)\\ L(\\mu^\\prime \\mid y)\\ /\\ f(y)}{f(\\mu)\\ L(\\mu \\mid y)\\ /\\ f(y)} \\right\\rbrace = \\min\\left\\lbrace 1, \\; \\frac{f(\\mu^\\prime \\mid y)}{f(\\mu \\mid y)} \\right\\rbrace\n$$\n\nThe key part is $f(\\mu^\\prime \\mid y)$ and $f(\\mu \\mid y)$, or how well $\\mu$ and $\\mu^\\prime$ fit in the unnormalized posterior. We look at the ratio of their plausibilities: \n\n$$\n\\frac{\\text{Plausibility of proposed } \\mu^\\prime \\text{ in unnormalized posterior}}{\\text{Plausibility of current } \\mu \\text{ in unnormalized posterior}}\n$$\n\nThere are two possible outcomes with this ratio:\n\n1. If the plausibility of the proposed draw is ≥ the current draw ($f(\\mu^\\prime \\mid y) \\geq f(\\mu \\mid y)$), $\\alpha$ will be 1, since the ratio will be > 1 (like 0.5 / 0.3 would be 1.666; 4 / 3.9 would be 1.02; and so on). The decision rule says to take the minimum of 1 and the plausibility ratio, so here the minimum is 1 and so $\\alpha$ is 1. This is the \"Definitely go there\" part of the algorithm.\n\n2. If the plausibility of the proposed draw is < the current draw ($f(\\mu^\\prime \\mid y) \\lt f(\\mu \\mid y)$), then the ratio will be less than 1 (like 0.3 / 0.5 would be 0.6; 3.9 / 4 would be 0.975; and so on), so $\\alpha$ would be that ratio and not 1 (again, we're taking the minimum of the two). That ratio then becomes our probability of going to the new draw. The closer the proposed plausibility is to the current plausibility, the higher the chances of visiting there. This is the \"Maybe go there\" part of the algorithm. \n\nWe can write this algorithm with code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\none_mh_iteration <- function(w, current) {\n  # Step 1\n  # Propose the next mu by choosing a value from a uniform distribution with a\n  # window of ±w around the current mu\n  proposal <- runif(1, min = current - w, max = current + w)\n  \n  # Step 2\n  # Decide whether or not to go there\n  # The plausibility is the prior * likelihood\n  proposal_plausibility <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)\n  current_plausibility <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)\n  \n  # Calculate the alpha, taking the minimum of 1 or the ratio of plausiblities\n  alpha <- min(1, proposal_plausibility / current_plausibility)\n  \n  # Determine the next stop based on the alpha\n  next_stop <- sample(c(proposal, current), size = 1, prob = c(alpha, 1 - alpha))\n  \n  return(tibble(proposal, alpha, next_stop))\n}\n```\n:::\n\n\nSo if we're currently at 3, let's figure out a next stop with a window of ±1:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(8)\none_mh_iteration(w = 1, current = 3)\n## # A tibble: 1 × 3\n##   proposal alpha next_stop\n##      <dbl> <dbl>     <dbl>\n## 1     2.93 0.824      2.93\n```\n:::\n\n\nThis iteration proposes going to 2.93. The ratio of plausibilities is less than one here, so we get an alpha of 0.82. The probability of deciding to move from 3 to 2.93 is thus also 0.82. In this case, we accept the proposal and decide to move on, so the next stop is 2.93.\n\nIn this case, if we're at 3 and we get a proposal of 2.018, the ratio is really small (0.02), so the probability when deciding to \"maybe move on\" is tiny. We end up staying at 3.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(83)\none_mh_iteration(w = 1, current = 3)\n## # A tibble: 1 × 3\n##   proposal  alpha next_stop\n##      <dbl>  <dbl>     <dbl>\n## 1     2.02 0.0171         3\n```\n:::\n\n\n# 7.3: Implementing the Metropolis-Hastings algorithm\n\nThat's the hard part! The rest involves just looping through a bunch of values. We'll do that with a function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmh_tour <- function(start = 3, N, w) {\n  # Step 1\n  # Start the chain at some location\n  current <- start\n  \n  # Step 2\n  # Create an empty vector with enough slots to hold all these draws\n  mu <- rep(0, N)\n  \n  # Step 3\n  # Markov chain time\n  for (i in 1:N) {\n    # Do one iteration\n    where_next <- one_mh_iteration(w = w, current = current)\n    \n    # Save this in the vector\n    mu[i] <- where_next$next_stop\n    \n    # Tell the algorithm where we are now\n    current <- where_next$next_stop\n  }\n  \n  # Step 4\n  # Return all the chain values\n  # (use tidybayes name conventions)\n  return(tibble(.iteration = c(1:N), mu))\n}\n```\n:::\n\n\nHere we go! Let's make a chain with 5000 values with a uniform proposal model with a window $w$ of ±1:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\ntour_1 <- mh_tour(start = 3, N = 5000, w = 1)\n\n# Trace plot\ntour_1 |> \n  ggplot(aes(x = .iteration, y = mu)) +\n  geom_line(size = 0.1, alpha = 0.75)\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Density plot\ntour_1 |> \n  ggplot(aes(x = mu)) +\n  geom_histogram(aes(y = ..density..),binwidth = 0.25, \n                  color = \"white\", fill = clrs[2]) +\n  geom_function(fun = ~dnorm(., 4, 0.6), color = clrs[3])\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n\nAHHHHHHH THAT'S AWESOME!!!!!!!!!11!!1!1!!\n\n## Fun times with parallel chains\n\nFor bonus fun and excitement, I'll do four parallel chains with 4 random starting values drawn from $\\operatorname{Uniform}(0, 10)$ (because why not)\n\n\n::: {.cell hash='07-chapter_cache/html/parallel-tours-fun-times_e97b1141a5e36141962c86875ff1dd2c'}\n\n```{.r .cell-code}\nlibrary(furrr)\nplan(multisession, workers = 4)\n\nset.seed(123)\nfour_tours <- tibble(.chain = 1:4) |> \n  mutate(start = runif(n(), 0, 10)) |> \n  mutate(tour = future_map(start, ~mh_tour(start = ., N = 5000, w = 1),\n                           .options = furrr_options(seed = TRUE)))\nfour_tours\n## # A tibble: 4 × 3\n##   .chain start tour                \n##    <int> <dbl> <list>              \n## 1      1  2.88 <tibble [5,000 × 2]>\n## 2      2  7.88 <tibble [5,000 × 2]>\n## 3      3  4.09 <tibble [5,000 × 2]>\n## 4      4  8.83 <tibble [5,000 × 2]>\n```\n:::\n\n\nLOOK AT THIS TRACE PLOT\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfour_tours |> \n  unnest(tour) |> \n  filter(.chain < 2500) |> \n  ggplot(aes(x = .iteration, y = mu, color = factor(.chain))) +\n  geom_line(size = 0.1, alpha = 0.75) +\n  labs(color = \"Chain\")\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nLOOK AT THIS TRANK PLOT\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfour_tours |> \n  unnest(tour) |> \n  mutate(draw_rank = rank(mu)) |> \n  ggplot(aes(x = draw_rank)) +\n  stat_bin(aes(color = factor(.chain)), geom = \"step\", binwidth = 500,\n           position = position_identity(), boundary = 0) +\n  labs(color = \"Chain\") +\n  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nLOOK AT THE DENSITIES ACROSS CHAINS\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Density plot\nfour_tours |> \n  unnest(tour) |> \n  ggplot(aes(x = mu, color = factor(.chain))) +\n  geom_density() +\n  labs(color = \"Chain\")\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nThis even works with **posterior** functions like `ess_basic`. Our effective sample size ratio isn't that great—our 20,000 Markov chain values are as useful as only 2,400 independent samples(0.12 × 20000).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_mu <- four_tours |> unnest(tour) |> pull(mu)\nposterior::ess_basic(posterior_mu)\n## [1] 2379.859\n\n# neff_ratio\nposterior::ess_basic(posterior_mu) / 20000\n## [1] 0.118993\n```\n:::\n\n\nAnd we can look at autocorrelation, which isn't great. It takes a while for the chains to settle and the chains have a longer memory—we don't hit 0ish correlation until 13 lags!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautocor_manual <- four_tours |> \n  unnest(tour) |> \n  group_by(.chain) |> \n  nest() |> \n  summarize(autocor = map(data, ~{\n    x <- acf(.$mu, plot = FALSE, lag.max = 20)\n    tibble(lag = x$lag, acf = x$acf)\n  })) |>\n  unnest(autocor)\n\nggplot(autocor_manual, aes(x = lag, y = acf, color = factor(.chain))) +\n  geom_line() +\n  scale_x_continuous(breaks = 0:20) +\n  labs(x = \"Lag\", y = \"Autocorrelation\", color = \"Chain\") +\n  theme(panel.grid.minor = element_blank())\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nFinally, here's the overall simulated posterior, after throwing away the first 2,500 draws in each chain as warmups (just like we do with Stan):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfour_tours |> \n  unnest(tour) |> \n  filter(.iteration > 2500) |> \n  ggplot(aes(x = mu)) +\n  geom_density(aes(fill = \"Simulated posterior\"), color = FALSE) +\n  geom_function(fun = ~dnorm(., 4, 0.6), aes(color = \"True posterior\")) +\n  scale_fill_manual(values = c(clrs[2]), name = NULL) +\n  scale_color_manual(values = c(clrs[3]), name = NULL)\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nSO SO COOL!\n\n\n# 7.4: Tuning the Metropolis-Hastings algorithm\n\nPhew. One final wrinkle to play with. We arbitrarily set $w = 1$ here for the window, which defines how wide the neighborhood of possible proposals is. That $w$ term matters a lot—too wide and we'll bounce around way too much and never settle; too narrow and we'll get stuck around the initial value.\n\nThis $w$ is equivalent to the **step size**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(7)\nsim_too_wide <- mh_tour(N = 5000, w = 100)\n\nset.seed(84735)\nsim_too_narrow <- mh_tour(N = 5000, w = 0.01)\n\ntoo_wide <- ggplot(sim_too_wide, aes(x = .iteration, y = mu)) + \n  geom_line(color = clrs[4]) + \n  geom_hline(yintercept = 4, color = clrs[2], linetype = \"dotted\") +\n  ylim(c(1.6, 6.4)) +\n  labs(title = \"w too wide\")\n\ntoo_narrow <- ggplot(sim_too_narrow, aes(x = .iteration, y = mu)) + \n  geom_line(color = clrs[5]) + \n  geom_hline(yintercept = 4, color = clrs[2], linetype = \"dotted\") +\n  ylim(c(1.6, 6.4)) +\n  labs(title = \"w too narrow\")\n\ntoo_narrow | too_wide\n```\n\n::: {.cell-output-display}\n![](07-chapter_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}