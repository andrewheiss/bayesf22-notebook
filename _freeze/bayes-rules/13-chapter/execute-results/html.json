{
  "hash": "19d5f92bcdcd8f4a32bc2882033c02ea",
  "result": {
    "markdown": "---\ntitle: \"13: Logistic regression\"\nsubtitle: \"Reading notes\"\ndate: \"October 12, 2022\"\n---\n\n\n[(Original chapter)](https://www.bayesrulesbook.com/chapter-13.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(cmdstanr)\nlibrary(rstanarm)\nlibrary(marginaleffects)\nlibrary(broom)\nlibrary(broom.mixed)\nlibrary(parameters)\nlibrary(tidybayes)\nlibrary(ggdist)\nlibrary(patchwork)\nlibrary(latex2exp)\nlibrary(scales)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Tell bayesplot to use the Lakota palette for things like pp_check()\n# bayesplot::color_scheme_set(clrs)\n\n# Tell bayesplot to use the viridis rocket palette for things like pp_check()\nviridisLite::viridis(6, option = \"rocket\", end = 0.85, direction = -1) |> \n  # Take off the trailing \"FF\" in the hex codes\n  map_chr(~str_sub(., 1, 7)) |> \n  bayesplot::color_scheme_set()\n\n# Seed stuff\nset.seed(1234)\nBAYES_SEED <- 1234\n\n# Data\ndata(weather_perth, package = \"bayesrules\")\n\nweather <- weather_perth %>% \n  select(day_of_year, raintomorrow, humidity9am, humidity3pm, raintoday) |> \n  mutate(across(c(humidity9am, humidity3pm), \n                ~scale(., scale = FALSE), .names = \"{col}_centered\")) |> \n  mutate(across(c(humidity9am, humidity3pm), \n                ~as.numeric(scale(., scale = FALSE)), .names = \"{col}_c\")) |> \n  mutate(raintomorrow_num = as.numeric(raintomorrow) - 1)\n\nextract_attributes <- function(x) {\n  attributes(x) %>%\n    set_names(janitor::make_clean_names(names(.))) %>%\n    as_tibble() %>%\n    slice(1)\n}\n\nunscaled <- weather %>%\n  select(ends_with(\"_centered\")) |> \n  summarize(across(everything(), ~extract_attributes(.))) |> \n  pivot_longer(everything()) |> \n  unnest(value) |> \n  split(~name)\n\n# Access these things like so:\n# unscaled$humidity3pm_centered$scaled_center\n```\n:::\n\n\n# The general setup\n\nIn this example we want to model if it's going to rain tomorrow (`raintomorrow`) based on three predictors:\n\n- $X_1$ (`humidity9am`): today's humidity at 9 AM\n- $X_2$ (`humitidy3pm`): today's humidity at 3 PM\n- $X_3$ (`raintoday``): binary indicator if it rained today\n\n\n# 13.1: Pause: odds and probability\n\n**Probability** is the percent chance that something will happen, or $\\pi$. \n\nThe **odds** of an event is the ratio of the probability that it will happen vs. the probability that it won't happen, or \n\n$$\n\\text{odds} = \\frac{\\pi}{1 - \\pi}\n$$\n\nProbabilities are limited to 0–1. Odds can range from 0 to infinity. This makes interpretation a little weird.\n\nIf the probability of rain tomorrow is $\\pi = 2/3$, the probability that it doesn't rain is $1 - \\pi$, or $1/3$. The odds are thus\n\n$$\n\\frac{2/3}{1/3} = 2\n$$\n\n…which means that it's twice as likely to rain than not rain.\n\nIf the probability of rain tomorrow is $\\pi = 1/3$, the probability that it doesn't rain is $1 - \\pi = 2/3$, so the odds are\n\n$$\n\\frac{1/3}{2/3} = \\frac{1}{2}\n$$\n\n…which means that it's half as likely to rain than not rain\n\nAnd if the probability is $\\pi = 1/2$, the probability that it doesn't rain is $1 - \\pi = 1/2$, so the odds are\n\n$$\n\\frac{1/2}{1/2} = 1\n$$\nIn general:\n\n- If odds are < 1, $\\pi < 0.5$\n- If odds are > 1, $\\pi > 0.5$\n- If odds are 1, $\\pi = 0.5$\n\n\n# 13.2: Building the logistic regression model\n\n## Prelude: Intuition behind GLM links\n\nIn general GLMs let us model non-linear data in linear ways by transforming the outcome to a more linear scale. With Poisson, we logged $\\lambda$ to force it to be above zero. With logistic regression, raw probabilities tend to be really curvy and sigmoidal, and they're bound between 0 and 1, and linear regression can't handle bounds like that. \n\nWe can convert the probabilities to odds to get out of the 0–1 world, but we still face substantial nonlinearities (since high probabilities approach infinity and low probabilities approach zero). We can log the odds to force the data to be more linear. Our GLM link is thus a logit function:\n\n$$\n\\log \\left( \\frac{\\pi_i}{1 - \\pi_i} \\right) = \\beta_0 + \\beta_1 X_{i1} + \\beta_2 X_{i2} + \\dots\n$$\n\nOr more simply:\n\n$$\n\\operatorname{logit}(\\pi_i) = \\beta_0 + \\beta_1 X_{i1} + \\beta_2 X_{i2} + \\dots\n$$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlogit_df <- tibble(humidity9am = seq(0, 100, length.out = 101),\n                   logits = seq(-4, 6, length.out = 101)) |> \n  mutate(odds = exp(logits)) |> \n  mutate(probs = plogis(logits))\n\np1 <- ggplot(logit_df, aes(x = humidity9am, y = probs)) +\n  geom_line(size = 1, color = clrs[3]) +\n  labs(title = \"Probabilities\", \n       subtitle = \"Can't be modeled linearly; too curvy and bound between 0–1\",\n       x = \"9 AM humidity\",\n       y = TeX(\"$\\\\pi$\")) +\n  theme(plot.title = element_text(face = \"bold\"),\n        axis.title.y = element_text(angle = 0, hjust = 0))\n## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead.\n\np2 <- ggplot(logit_df, aes(x = humidity9am, y = odds)) +\n  geom_line(size = 1, color = clrs[2]) +\n  labs(title = \"Odds\", \n       subtitle = \"No longer bound between 0–1, but still too curvy for linear models\",\n       x = \"9 AM humidity\",\n       y = TeX(\"$\\\\frac{\\\\pi}{1 - \\\\pi}$\")) +\n  theme(plot.title = element_text(face = \"bold\"),\n        axis.title.y = element_text(angle = 0, hjust = 0))\n\np3 <- ggplot(logit_df, aes(x = humidity9am, y = logits)) +\n  geom_line(size = 1, color = clrs[1]) +\n  labs(title = \"Log odds (logits)\", \n       subtitle = \"Linear models are comfy and happy here\",\n       x = \"9 AM humidity\",\n       y = TeX(\"$log \\\\left( \\\\frac{\\\\pi}{1 - \\\\pi} \\\\right)$\")) +\n  theme(plot.title = element_text(face = \"bold\"),\n        axis.title.y = element_text(angle = 0, hjust = 0))\n\np1 / p2 / p3\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n\n## Prelude II: How to interpret logistic regression coefficients\n\n:::{.callout-tip}\n\nSee [my guide here](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#2-fractional-logistic-regression) or [my other guide here](https://www.andrewheiss.com/blog/2022/09/26/guide-visualizing-types-posteriors/#logistic-regression-example) or [this by Steven Miller](http://post8000.svmiller.com/lab-scripts/logistic-regression-lab.html) for more on logistic regression coefficients.\n\n:::\n\nLogit model coefficients can be reported as log odds (or logits) or odds (or odds ratios). We can get actual probabilities if use `plogis()` to calculate the inverse logit of the log odds, or we can calculate marginal effects.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfake_logit_data <- logit_df |> \n  mutate(raintomorrow_fake = map(probs, ~rbinom(15, 1, .))) |> \n  unnest(raintomorrow_fake)\n\nggplot(fake_logit_data, aes(x = humidity9am, y = raintomorrow_fake)) +\n  geom_dots(aes(side = ifelse(raintomorrow_fake == 1, \"bottom\", \"top\")), \n            pch = 19, color = \"grey70\", scale = 0.2) +\n  geom_smooth(method = \"glm\", method.args = list(family = binomial(link = \"logit\")),\n              size = 1, color = clrs[5], se = FALSE)\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_example <- glm(raintomorrow_fake ~ humidity9am, data = fake_logit_data,\n                     family = binomial(link = \"logit\"))\ntidy(model_example)\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -3.65     0.201       -18.2 1.21e-73\n## 2 humidity9am   0.0936   0.00461      20.3 1.12e-91\ntidy(model_example, exponentiate = TRUE)\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)   0.0260   0.201       -18.2 1.21e-73\n## 2 humidity9am   1.10     0.00461      20.3 1.12e-91\n```\n:::\n\n\n\n\nThe intercept $\\beta_0$ is the log odds of the outcome when all other covariates are set to 0. In the fake data here, it's -3.651. That makes no sense by itself, but we can exponentiate it ($e^{-3.651}$) and get an odds ratio of 0.026. That still doesn't make sense for me (maybe some people *do* think in odds ratios?). We can convert the log odds value to a probability with $\\frac{e^{-3.651}}{1 + e^{-3.651}}$, or `` plogis(-3.651) `` in R: 0.025. That means that in this simulated data, there's a 2.5% probability of rain when humidity is 0%.\n\n- Log odds: $-3.651$\n- Odds: $e^{-3.651} = 0.026$\n- Probability: $\\frac{e^{-3.651}}{1 + e^{-3.651}} = 0.025$\n\nThe slope $\\beta_1$ is the slope of the line on the log odds scale. A 1 percentage point increase in humidity is associated with a 0.094 increase in the log odds of rain. [That makes no d**n sense (it compels me though)](https://tenor.com/view/knives-out-it-makes-no-damn-sense-compels-me-though-benoit-blanc-daniel-craig-gif-18728195).\n\nWe can exponentiate the coefficient ($e^{0.094}$) to get an odds ratio of 1.098, or the multiplicative change in odds. This is a little more usable (though not much): a 1 percentage point increase in humidity increases the odds of rain by 9.8%.\n\nWe can convert this coefficient to the probability scale with a little bit of fancy math. We can't just stick the log odds into `plogis()` like we did with the intercept. We need to include details from the intercept in the calculation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplogis(intercept + coefficient) - plogis(intercept)\n```\n:::\n\n\nIf we do that with these coefficients like `` plogis(-3.651 + 0.094) - plogis(-3.651) ``, we get 0.0024, which means that the probability of rain increases by 0.24 percentage points for every 1 percentage point increase in humidity, on average.\n\nThe slope is different across the whole range of 9 AM temperatures though. Averaged across the whole range of humidity, the probability of rain increases by 0.24 percentage points, but the fitted curve is flat at the edges and steep in the middle. We can use `marginaleffects()` to find the slope at different values of humidity:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_example <- marginaleffects(model_example, \n                               newdata = datagrid(humidity9am = c(0, 30, 60, 90)),\n                               by = \"humidity9am\")\nsummary(mfx_example)\n##          Term    Contrast humidity9am    Effect Std. Error z value   Pr(>|z|)\n## 1 humidity9am mean(dY/dX)           0 0.0023107  0.0003398   6.801 1.0395e-11\n## 2 humidity9am mean(dY/dX)          30 0.0196926  0.0008739  22.535 < 2.22e-16\n## 3 humidity9am mean(dY/dX)          60 0.0100879  0.0006424  15.704 < 2.22e-16\n## 4 humidity9am mean(dY/dX)          90 0.0007781  0.0001500   5.188 2.1232e-07\n##       2.5 %   97.5 %\n## 1 0.0016448 0.002977\n## 2 0.0179798 0.021405\n## 3 0.0088289 0.011347\n## 4 0.0004841 0.001072\n## \n## Model type:  glm \n## Prediction type:  response\n```\n:::\n\n\n\n\nWhen humidity is 0, we get the same slope we found manually with `plogis()`, or 0.0023. As humidity increases, the slope increases too. When humidity is 30%, for instance, moving from 30% to 31% increases the probability of rain by 1.97 percentage points, while moving from 60% to 61% humidity increases the probability of rain by 1.01 percentage points. For fun we can plot the whole range of marginal effects:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This does the same thing automatically:\n# plot_cme(model_example, effect = \"humidity9am\", condition = \"humidity9am\")\n\nmodel_example |> \n  marginaleffects(\n    newdata = datagrid(humidity9am = seq(0, 100, by = 1)),\n    by = \"humidity9am\") |> \n  mutate(across(c(dydx, conf.low, conf.high), ~ . * 100)) |> \n  ggplot(aes(x = humidity9am, y = dydx)) +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.3, fill = clrs[1]) +\n  geom_line(size = 1, color = clrs[1]) +\n  labs(x = \"9 AM humidity\", \n       y = \"Percentage point increase in probability of rain\\n(marginal effect)\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## Defining the priors\n\nTo make the intercept more interpretable and to make Stan happier, we'll work with a centered version of humidity rather than the 0–100 scale.\n\nWe'll say that based on our prior knowledge about weather in Perth, there's generally a 20% chance of rain on a given day. Since the intercept here is centered, it represents a typical day with an average level of morning humidity, so we just need to convert 20% to the log odds scale, either manually or with `qlogis(0.2)`:\n\n$$\n\\log \\left( \\frac{0.2}{1 - 0.2} \\right) = -1.39\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqlogis(0.2)\n## [1] -1.386294\n```\n:::\n\n\nWe need a range around that number. In the book they use 0.7 for $\\sigma$, making a range of -1.39 ± (2 * 0.7) = -2.786 and 0.014. If we convert those to probabilities, we get a range from 5% to 50%:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplogis(qlogis(0.2) - (2 * 0.7))\n## [1] 0.05806931\nplogis(qlogis(0.2) + (2 * 0.7))\n## [1] 0.5034264\n```\n:::\n\n\nThat seems fine. Here's what that looks like in plot form:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot() +\n  geom_function(fun = ~dnorm(., mean = -1.39, sd = 0.7),\n                size = 1, color = clrs[2]) +\n  scale_x_continuous(limits = c(-4, 1)) +\n  scale_y_continuous(labels = NULL, breaks = NULL) +\n  labs(x = \"Log odds\", y = NULL)\n\np2 <- tibble(x = seq(-4, 1, by = 0.01)) |> \n  mutate(y = dnorm(x, mean = -1.39, sd = 0.7)) |> \n  mutate(x_prob = plogis(x)) |> \n  ggplot(aes(x = x_prob, y = y)) +\n  geom_line(size = 1, color = clrs[2]) +\n  scale_y_continuous(labels = NULL, breaks = NULL) +\n  labs(x = \"Probability\", y = NULL)\n\np1 | p2\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-12-1.png){width=768}\n:::\n:::\n\n\nFor the $\\beta_1$ coefficient, we have a general idea that more humidity today will increase the probability of rain tomorrow, but no idea how big that effect actually is. In the book they say that the slope is around 0.07 with a $\\sigma$ of 0.035, so 0.07 ± 0.07, or 0–0.14. \n\nLog odds make no sense so we can convert that range to odds ratios:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(0.07 - 0.07)\n## [1] 1\nexp(0.07 + 0.07)\n## [1] 1.150274\n```\n:::\n\n\nThe odds of rain the next day thus increase by 0–15% for each percentage point increase in humidity. Here's what that looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot() +\n  geom_function(fun = ~dnorm(., mean = 0.07, sd = 0.07),\n                size = 1, color = clrs[3]) +\n  scale_x_continuous(limits = c(-0.35, 0.35)) +\n  scale_y_continuous(labels = NULL, breaks = NULL) +\n  labs(x = \"Log odds\", y = NULL)\n\np2 <- tibble(x = seq(-0.35, 0.35, by = 0.01)) |> \n  mutate(y = dnorm(x, mean = 0.07, sd = 0.07)) |> \n  mutate(x_odds = exp(x)) |> \n  ggplot(aes(x = x_odds, y = y)) +\n  geom_line(size = 1, color = clrs[3]) +\n  scale_y_continuous(labels = NULL, breaks = NULL) +\n  labs(x = \"Odds ratio\", y = NULL)\n\np1 | p2\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-14-1.png){width=768}\n:::\n:::\n\n\n## Official formal model\n\nHere's the formal model then:\n\n$$\n\\begin{aligned}\n\\text{Rain tomorrow}_i &\\sim \\operatorname{Bernoulli}(\\pi_i) \\\\\n\\operatorname{logit}(\\pi_i) &= \\beta_{0c} + \\beta_1\\ \\text{9 AM humidity}_i \\\\\n\\\\\n\\beta_{0c} &\\sim \\mathcal{N}(-1.39, 0.7) \\\\\n\\beta_1 &\\sim \\mathcal{N}(0.07, 0.035)\n\\end{aligned}\n$$\n\nWe should get a sense of how reasonable these priors are by simulating them. These plots seem good and fine.\n\n::: {.panel-tabset}\n### brms\n\n\n::: {.cell hash='13-chapter_cache/html/model-weather-prior-brms_0ea396e6612ac89be3e19f675358ba50'}\n\n```{.r .cell-code}\npriors <- c(prior(normal(-1.39, 0.7), class = Intercept),\n            prior(normal(0.07, 0.035), class = b, coef = \"humidity9am_c\"))\n\nmodel_weather_prior_brms <- brm(\n  bf(raintomorrow ~ humidity9am_c),\n  data = weather,\n  family = bernoulli(link = \"logit\"),\n  prior = priors,\n  sample_prior = \"only\",\n  chains = 4, iter = 4000, seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0\n)\n## Start sampling\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- tibble(\n  humidity9am = seq(0, 100, by = 0.1)\n) |> \n  mutate(humidity9am_c = humidity9am - unscaled$humidity9am_centered$scaled_center) |> \n  add_epred_draws(model_weather_prior_brms, ndraws = 100) |> \n  ggplot(aes(x = humidity9am, y = .epred)) +\n  geom_line(aes(group = .draw), alpha = 0.5, size = 0.5, color = clrs[6]) +\n  labs(x = \"9 AM humidity\", y = \"Probability of rain tomorrow\")\n\np2 <- tibble(\n  humidity9am = seq(0, 100, by = 0.1)\n) |> \n  mutate(humidity9am_c = humidity9am - unscaled$humidity9am_centered$scaled_center) |> \n  add_predicted_draws(model_weather_prior_brms, ndraws = 100) |> \n  group_by(.draw) |> \n  summarize(proportion_rain = mean(.prediction == 1)) |> \n  ggplot(aes(x = proportion_rain)) +\n  geom_histogram(binwidth = 0.02, color = \"white\", fill = clrs[1]) +\n  labs(x = \"Proportion of rainy days in each draw\", y = \"Count\")\n\np1 | p2\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-15-1.png){width=768}\n:::\n:::\n\n\n### rstanarm\n\n\n::: {.cell hash='13-chapter_cache/html/model-weather-prior-rstanarm_aa5b730925d5f1f516eef5066622ff4c'}\n\n```{.r .cell-code}\nmodel_weather_prior_rstanarm <- stan_glm(\n  raintomorrow ~ humidity9am_c,\n  data = weather,\n  family = binomial(link = \"logit\"),\n  prior_intercept = normal(-1.39, 0.7),\n  prior = normal(0.07, 0.035),\n  chains = 4, iter = 4000, seed = 84735, refresh = 0,\n  prior_PD = TRUE\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- tibble(\n  humidity9am = seq(0, 100, by = 0.1)\n) |> \n  mutate(humidity9am_c = humidity9am - unscaled$humidity9am_centered$scaled_center) |>\n  add_epred_draws(model_weather_prior_rstanarm, ndraws = 100) |> \n  ggplot(aes(x = humidity9am, y = .epred)) +\n  geom_line(aes(group = .draw), alpha = 0.5, size = 0.5, color = clrs[6]) +\n  labs(x = \"9 AM humidity\", y = \"Probability of rain tomorrow\")\n\np2 <- tibble(\n  humidity9am = seq(0, 100, by = 0.1)\n) |> \n  mutate(humidity9am_c = humidity9am - unscaled$humidity9am_centered$scaled_center) |> \n  add_predicted_draws(model_weather_prior_rstanarm, ndraws = 100) |> \n  group_by(.draw) |> \n  summarize(proportion_rain = mean(.prediction == 1)) |> \n  ggplot(aes(x = proportion_rain)) +\n  geom_histogram(binwidth = 0.02, color = \"white\", fill = clrs[1]) +\n  labs(x = \"Proportion of rainy days in each draw\", y = \"Count\")\n\np1 | p2\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-16-1.png){width=768}\n:::\n:::\n\n:::\n\n\n# 13.3: Simulating the posterior\n\n## Look at the data\n\nTime to look at the actual data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrain_prob <- weather |> \n  mutate(humidity_bracket = cut(humidity9am, seq(10, 100, by = 10))) |> \n  group_by(humidity_bracket) |> \n  summarize(prop_rain = mean(raintomorrow == \"Yes\")) |> \n  mutate(mid = seq(15, 95, by = 10))\n  \nweather |> \n  ggplot(aes(x = humidity9am / 100, y = raintomorrow_num)) +\n  geom_dots(aes(color = raintomorrow, \n                shape = \"Data\",\n                side = ifelse(raintomorrow_num == 1, \"bottom\", \"top\")),\n            scale = 0.7, alpha = 0.5) +\n  scale_color_manual(values = c(clrs[2], clrs[3]), name = \"Rain tomorrow\",\n                     guide = guide_legend(override.aes = list(shape = 19))) +\n  scale_shape_manual(values = c(19, 15), name = NULL,\n                     guide = guide_legend(override.aes = list(linetype = 0))) +\n  geom_point(data = rain_prob, \n             aes(x = mid / 100, y = prop_rain,\n                 shape = \"Proportion of rainy days\")) +\n  # Add a logistic regression curve with a second color scale for optional bonus fun\n  ggnewscale::new_scale_color() +\n  geom_smooth(mapping = aes(color = \"Probability of rain\"),\n              method = \"glm\", method.args = list(family = binomial(link = \"logit\")),\n              size = 1, se = FALSE) +\n  scale_color_manual(values = clrs[5], name = NULL) +\n  scale_x_continuous(labels = label_percent()) +\n  scale_y_continuous(labels = label_percent()) +\n  labs(x = \"9 AM humidity\", y = \"Probability of rain tomorrow\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nIn theory, the fitted model should look like the quantile-based proportions there ↑\n\n## Run the model\n\n::: {.panel-tabset}\n### brms\n\n\n::: {.cell hash='13-chapter_cache/html/model-weather-brms_e092b2f5bb593e176aa6ef631cd87146'}\n\n```{.r .cell-code}\npriors <- c(prior(normal(-1.39, 0.7), class = Intercept),\n            prior(normal(0.07, 0.035), class = b, coef = \"humidity9am_c\"))\n\nmodel_weather_brms <- brm(\n  bf(raintomorrow ~ humidity9am_c),\n  data = weather,\n  family = bernoulli(link = \"logit\"),\n  prior = priors,\n  chains = 4, iter = 4000, seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0\n)\n## Start sampling\n```\n:::\n\n\n### rstanarm\n\n\n::: {.cell hash='13-chapter_cache/html/model-weather-rstanarm_ec97aad6b6037091d6165eacfd6e63a6'}\n\n```{.r .cell-code}\nmodel_weather_rstanarm <- stan_glm(\n  raintomorrow ~ humidity9am_c,\n  data = weather,\n  family = binomial(link = \"logit\"),\n  prior_intercept = normal(-1.39, 0.7),\n  prior = normal(0.07, 0.035),\n  chains = 4, iter = 4000, seed = 84735, refresh = 0\n)\n```\n:::\n\n\n:::\n\n## Diagnostics\n\n::: {.panel-tabset}\n### brms\n\n#### Trace plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_weather_brms |> \n  gather_draws(`^b_.*`, regex = TRUE) |> \n  ggplot(aes(x = .iteration, y = .value, color = factor(.chain))) +\n  geom_line(size = 0.1) +\n  scale_color_viridis_d(option = \"rocket\", end = 0.85) +\n  facet_wrap(vars(.variable), scales = \"free_y\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n#### Trank plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_weather_brms |> \n  gather_draws(`^b_.*`, regex = TRUE) |> \n  group_by(.variable) |> \n  mutate(draw_rank = rank(.value)) |> \n  ggplot(aes(x = draw_rank, color = factor(.chain))) +\n  stat_bin(geom = \"step\", binwidth = 250, position = position_identity(), boundary = 0) +\n  scale_color_viridis_d(option = \"rocket\", end = 0.85) +\n  facet_wrap(vars(.variable), scales = \"free_y\") +\n  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n#### Posterior predictive plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_weather_brms, ndraws = 50)\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n#### LOO, PSIS, and WAIC\n\n\n::: {.cell hash='13-chapter_cache/html/loo-brms_54304cd68cec6b4fbdcd731d9616453d'}\n\n```{.r .cell-code}\nloo(model_weather_brms)\n## \n## Computed from 8000 by 1000 log-likelihood matrix\n## \n##          Estimate   SE\n## elpd_loo   -437.0 19.0\n## p_loo         2.2  0.2\n## looic       874.1 37.9\n## ------\n## Monte Carlo SE of elpd_loo is 0.0.\n## \n## All Pareto k estimates are good (k < 0.5).\n## See help('pareto-k-diagnostic') for details.\n```\n:::\n\n\n### rstanarm\n\n#### Trace plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_weather_rstanarm |> \n  gather_draws(`(Intercept)`, humidity9am_c) |> \n  ggplot(aes(x = .iteration, y = .value, color = factor(.chain))) +\n  geom_line(size = 0.1) +\n  scale_color_viridis_d(option = \"rocket\", end = 0.85) +\n  facet_wrap(vars(.variable), scales = \"free_y\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n#### Trank plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_weather_rstanarm |> \n  gather_draws(`(Intercept)`, humidity9am_c) |> \n  group_by(.variable) |> \n  mutate(draw_rank = rank(.value)) |> \n  ggplot(aes(x = draw_rank, color = factor(.chain))) +\n  stat_bin(geom = \"step\", binwidth = 250, position = position_identity(), boundary = 0) +\n  scale_color_viridis_d(option = \"rocket\", end = 0.85) +\n  facet_wrap(vars(.variable), scales = \"free_y\") +\n  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n#### Posterior predictive plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_weather_rstanarm, n = 50)\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n#### LOO, PSIS, and WAIC\n\n\n::: {.cell hash='13-chapter_cache/html/loo-rstanarm_c3a4a2c16953cd1977e3939cdc0b8f8e'}\n\n```{.r .cell-code}\nloo(model_weather_rstanarm)\n## \n## Computed from 8000 by 1000 log-likelihood matrix\n## \n##          Estimate   SE\n## elpd_loo   -437.0 19.0\n## p_loo         2.1  0.2\n## looic       874.0 38.0\n## ------\n## Monte Carlo SE of elpd_loo is 0.0.\n## \n## All Pareto k estimates are good (k < 0.5).\n## See help('pareto-k-diagnostic') for details.\n```\n:::\n\n\n:::\n\n# 13.3½: Interpreting the posterior\n\nThe book is more focused on classification and prediction here and doesn't go (much) into coefficient interpretation or (at all) into marginal effects, but I will, just for fun.\n\n## Coefficients / parameters\n\n::: {.panel-tabset}\n### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather |> \n  add_epred_draws(model_weather_brms, ndraws = 50) |> \n  ggplot(aes(x = humidity9am)) +\n  geom_dots(data = weather, \n            aes(y = raintomorrow_num, color = raintomorrow,\n                side = ifelse(raintomorrow_num == 1, \"bottom\", \"top\")), \n            pch = 19, scale = 0.5, alpha = 0.5) +\n  geom_line(aes(y = .epred, group = .draw),\n            size = 0.5, alpha = 0.3, color = clrs[6]) +\n  scale_color_manual(values = c(clrs[2], clrs[3]), name = \"Rain tomorrow\", guide = \"none\") +\n  labs(x = \"9 AM humidity\", y = \"Probability of rain tomorrow\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n### rstanarm\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather |> \n  add_epred_draws(model_weather_rstanarm, ndraws = 50) |> \n  ggplot(aes(x = humidity9am)) +\n  geom_dots(data = weather, \n            aes(y = raintomorrow_num, color = raintomorrow,\n                side = ifelse(raintomorrow_num == 1, \"bottom\", \"top\")), \n            pch = 19, scale = 0.5, alpha = 0.5) +\n  geom_line(aes(y = .epred, group = .draw),\n            size = 0.5, alpha = 0.3, color = clrs[6]) +\n  scale_color_manual(values = c(clrs[2], clrs[3]), name = \"Rain tomorrow\", guide = \"none\") +\n  labs(x = \"9 AM humidity\", y = \"Probability of rain tomorrow\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n:::\n\n::: {.panel-tabset}\n### brms\n\nLogit/log odds-scale coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# I normally do this with broom.mixed::tidy() since I use broom::tidy() for\n# everything ordinarily, but (1) I want to try out parameters::model_parameters()\n# since it includes lots of other neat things like PD and ROPE, and (2)\n# broom.mixed::tidy() requires the `effects` argument to work and I always\n# forget to include it (.e.g. tidy(model_weather_brms, effects = \"fixed\"))\nmodel_parameters(model_weather_brms, centrality = \"mean\", dispersion = TRUE, \n                 test = FALSE, verbose = FALSE, ci_method = \"hdi\", priors = TRUE)\n## Parameter     |  Mean |       SD |         95% CI |  Rhat |     ESS |                  Prior\n## --------------------------------------------------------------------------------------------\n## (Intercept)   | -1.68 |     0.10 | [-1.85, -1.48] | 1.000 | 3986.00 | Normal (-1.39 +- 0.70)\n## humidity9am_c |  0.05 | 5.24e-03 | [ 0.04,  0.06] | 1.001 | 4570.00 |  Normal (0.07 +- 0.04)\n```\n:::\n\n\nOdds ratio-scale coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(model_weather_brms, centrality = \"mean\", dispersion = TRUE, \n                 test = FALSE, verbose = FALSE, ci_method = \"hdi\", priors = TRUE,\n                 exponentiate = TRUE) |> \n  print(digits = 3, zap_small = TRUE)\n## Parameter     |  Mean |    SD |       95% CI |  Rhat |      ESS |                  Prior\n## ----------------------------------------------------------------------------------------\n## (Intercept)   | 0.187 | 0.095 | [0.16, 0.23] | 1.000 | 3986.000 | Normal (-1.39 +- 0.70)\n## humidity9am_c | 1.049 | 0.005 | [1.04, 1.06] | 1.001 | 4570.000 |  Normal (0.07 +- 0.04)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_weather_brms |> \n  gather_draws(`^b_.*`, regex = TRUE) |>\n  mutate(.value = exp(.value)) |> \n  mutate(.variable = factor(.variable, \n                            levels = c(\"b_Intercept\", \"b_humidity9am_c\"),\n                            ordered = TRUE)) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = c(clrs[5], clrs[4]), guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\")\n## Warning: Unknown or uninitialised column: `linewidth`.\n## Warning: Using the `size` aesthietic with geom_segment was deprecated in ggplot2 3.4.0.\n## ℹ Please use the `linewidth` aesthetic instead.\n## Warning: Unknown or uninitialised column: `linewidth`.\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n### rstanarm\n\nLogit/log odds-scale coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(model_weather_rstanarm, centrality = \"mean\", dispersion = TRUE, \n                 test = FALSE, verbose = FALSE, ci_method = \"hdi\", priors = TRUE)\n## Parameter     |  Mean |       SD |         95% CI |  Rhat |     ESS |                  Prior\n## --------------------------------------------------------------------------------------------\n## (Intercept)   | -1.68 |     0.09 | [-1.87, -1.50] | 1.000 | 3956.00 | Normal (-1.39 +- 0.70)\n## humidity9am_c |  0.05 | 5.20e-03 | [ 0.04,  0.06] | 1.000 | 3960.00 |  Normal (0.07 +- 0.04)\n```\n:::\n\n\nOdds ratio-scale coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(model_weather_rstanarm, centrality = \"mean\", dispersion = TRUE, \n                 test = FALSE, verbose = FALSE, ci_method = \"hdi\", priors = TRUE,\n                 exponentiate = TRUE) |> \n  print(digits = 3, zap_small = TRUE)\n## Parameter     |  Mean |    SD |       95% CI |  Rhat |      ESS |                  Prior\n## ----------------------------------------------------------------------------------------\n## (Intercept)   | 0.187 | 0.092 | [0.15, 0.22] | 1.000 | 3956.000 | Normal (-1.39 +- 0.70)\n## humidity9am_c | 1.049 | 0.005 | [1.04, 1.06] | 1.000 | 3960.000 |  Normal (0.07 +- 0.04)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_weather_rstanarm |> \n  gather_draws(`(Intercept)`, humidity9am_c) |>\n  mutate(.value = exp(.value)) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = c(clrs[5], clrs[4]), guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\")\n## Warning: Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n:::\n\n## Interpretation and marginal effects\n\n\n\n\n\nThe intercept $\\beta_0$ has a posterior mean of -1.676, and it is the log odds of raining tomorrow when humidity at 9 AM is at its average value (60.9%). That number makes no sense, but if we exponentiate it ($e^{-1.676}$) we get an odds ratio of 0.187, which still doesn't make sense for intercepts. So instead we'll actually just convert the log odds to a probability with $\\frac{e^{-1.676}}{1 + e^{-1.676}}$, or `` plogis(-1.676) `` in R, which is 0.158. This means that when 9 AM humidity is average (again, 60.9%), there's a mean posterior probability of raining tomorrow of 15.8%, with a 95% credible interval of 13.4%–18.4%.\n\nThe posterior mean of the $\\beta_1$ parameter for 9 AM humidity is 0.048, which again, by itself, doesn't make much sense. Exponentiating it ($e^{0.048}$) gives us a mean posterior odds ratio of 1.049, with a 95% credible interval of 1.039–1.06, which *is* interpretable. A 1 percentage point increase in humidity today makes it 4.9% more likely to rain tomorrow (with a 95% credible interval of 3.9%–6.0%)\n\nIn addition to working with odds ratios, we can work with changes in probabilities more directly if we look at marginal effects. Since the fitted line is curvy here, we don't have a single slope—the slope changes across the whole range of 9 AM humidity.\n\nAt low values of humidity, increasing it a little bit doesn't change the slope much at all, but at higher values, like ≈75%, a 1 percentage point increase in humidity increases the probability of rain tomorrow by 1 percentage point or more.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_brms <- model_weather_brms |> \n  marginaleffects(newdata = datagrid(humidity9am_c = seq(0, 100, by = 1) -\n                                       unscaled$humidity9am_centered$scaled_center),\n                  variables = \"humidity9am_c\",\n                  type = \"response\") |> \n  posteriordraws() |> \n  mutate(humidity9am = humidity9am_c + unscaled$humidity9am_centered$scaled_center)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_brms |> \n  filter(humidity9am %in% c(0, 25, 50, 75, 90)) |> \n  group_by(humidity9am) |> \n  summarize(mean_slope = mean(draw),\n            conf.low = mean(conf.low),\n            conf.high = mean(conf.high)) |> \n  mutate(across(c(mean_slope, conf.low, conf.high), ~ . * 100))\n## # A tibble: 5 × 4\n##   humidity9am mean_slope conf.low conf.high\n##         <dbl>      <dbl>    <dbl>     <dbl>\n## 1           0     0.0484   0.0275    0.0750\n## 2          25     0.150    0.113     0.189 \n## 3          50     0.430    0.367     0.497 \n## 4          75     0.948    0.712     1.20  \n## 5          90     1.18     0.888     1.46\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_brms |> \n  ggplot(aes(x = humidity9am, y = draw * 100)) +\n  stat_lineribbon(alpha = 0.25, fill = clrs[6], color = clrs[6]) +\n  labs(x = \"9 AM humidity\", \n       y = \"Percentage point increase in\\nprobability of rain tomorrow\")\n## Warning: Using the `size` aesthietic with geom_ribbon was deprecated in ggplot2 3.4.0.\n## ℹ Please use the `linewidth` aesthetic instead.\n## Warning: Unknown or uninitialised column: `linewidth`.\n## Warning: Using the `size` aesthietic with geom_line was deprecated in ggplot2 3.4.0.\n## ℹ Please use the `linewidth` aesthetic instead.\n## Warning: Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n# 13.4: Prediction and classification\n\nNext we can see how well the model predicts things. In the book they predict the probability that it will rain tomorrow given that there is 99% humidity at 9 AM this morning, so we'll do that here too, both automatically with `posterior_predict()` and manually with `rbinom()`:\n\n::: {.panel-tabset}\n\n### brms\n\nAutomatic way:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhumidity_99_c <- 99 - unscaled$humidity9am_centered$scaled_center\n\nprediction_brms <- model_weather_brms |> \n  predicted_draws(newdata = tibble(humidity9am_c = humidity_99_c))\n\nprediction_brms |> \n  count(.prediction) |> \n  mutate(prop = n / sum(n),\n         prop_nice = label_percent(accuracy = 0.1)(prop)) |> \n  ggplot(aes(x = factor(.prediction), y = n)) + \n  geom_col(aes(fill = factor(.prediction))) +\n  geom_label(aes(label = prop_nice), nudge_y = -500) +\n  scale_fill_manual(values = c(clrs[2], clrs[3]), guide = \"none\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\nManual way:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhumidity_99_c <- 99 - unscaled$humidity9am_centered$scaled_center\n\nprediction_brms_manual <- model_weather_brms |> \n  spread_draws(b_Intercept, b_humidity9am_c) |> \n  mutate(log_odds = b_Intercept + b_humidity9am_c * humidity_99_c,\n         odds = exp(log_odds),\n         prob = odds / (1 + odds),\n         prob_auto = plogis(log_odds),  # Alternatively do this\n         y_new = rbinom(n(), size = 1, prob = prob))\n\nprediction_brms_manual |> \n  count(y_new) |> \n  mutate(prop = n / sum(n),\n         prop_nice = label_percent(accuracy = 0.1)(prop)) |> \n  ggplot(aes(x = factor(y_new), y = n)) + \n  geom_col(aes(fill = factor(y_new))) +\n  geom_label(aes(label = prop_nice), nudge_y = -500) +\n  scale_fill_manual(values = c(clrs[2], clrs[3]), guide = \"none\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n\n### rstanarm\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhumidity_99_c <- 99 - unscaled$humidity9am_centered$scaled_center\n\nprediction_rstanarm <- model_weather_rstanarm |> \n  predicted_draws(newdata = tibble(humidity9am_c = humidity_99_c))\n\nprediction_rstanarm |> \n  count(.prediction) |> \n  mutate(prop = n / sum(n),\n         prop_nice = label_percent(accuracy = 0.1)(prop)) |> \n  ggplot(aes(x = factor(.prediction), y = n)) + \n  geom_col(aes(fill = factor(.prediction))) +\n  geom_label(aes(label = prop_nice), nudge_y = -500) +\n  scale_fill_manual(values = c(clrs[2], clrs[3]), guide = \"none\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\nManual way:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhumidity_99_c <- 99 - unscaled$humidity9am_centered$scaled_center\n\nprediction_rstanarm_manual <- model_weather_rstanarm |> \n  spread_draws(`(Intercept)`, humidity9am_c) |> \n  mutate(log_odds = `(Intercept)` + humidity9am_c * humidity_99_c,\n         odds = exp(log_odds),\n         prob = odds / (1 + odds),\n         prob_auto = plogis(log_odds),  # Alternatively do this\n         y_new = rbinom(n(), size = 1, prob = prob))\n\nprediction_rstanarm_manual |> \n  count(y_new) |> \n  mutate(prop = n / sum(n),\n         prop_nice = label_percent(accuracy = 0.1)(prop)) |> \n  ggplot(aes(x = factor(y_new), y = n)) + \n  geom_col(aes(fill = factor(y_new))) +\n  geom_label(aes(label = prop_nice), nudge_y = -500) +\n  scale_fill_manual(values = c(clrs[2], clrs[3]), guide = \"none\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n:::\n\nBased on these predictions, if it's 99% humidity this morning, it's more likely to rain tomorrow than not (54ish% chance):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction_brms |> \n  count(.prediction) |> \n  mutate(prop = n / sum(n),\n         prop_nice = label_percent(accuracy = 0.1)(prop))\n## # A tibble: 2 × 6\n## # Groups:   humidity9am_c, .row [1]\n##   humidity9am_c  .row .prediction     n  prop prop_nice\n##           <dbl> <int>       <int> <int> <dbl> <chr>    \n## 1          38.1     1           0  3738 0.467 46.7%    \n## 2          38.1     1           1  4262 0.533 53.3%\n```\n:::\n\n\n\n# 13.5 Model evaluation\n\n## How fair is the model?\n\nIt's fine.\n\n## How wrong is the model?\n\nThis is where we'd use `pp_check()`. We did that earlier and got this neat graph:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_weather_brms, ndraws = 50)\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n\nThat shows that the model at least fits the shape of the underlying data, though it has some optical illusions with the density plot there, since the data is actually all only 0s and 1s.\n\nWe can get a more appropriate `pp_check` by changing the type to bars:\n\n::: {.panel-tabset}\n### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_weather_brms, ndraws = 100,\n         type = \"bars\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n\n### rstanarm\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_weather_rstanarm, n = 100,\n         plotfun = \"bars\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n:::\n\nAlternatively, in the book they use a histogram that shows the proportion of rainy days in each simulated dataset and compare that histogram with the observed proportion of rainy days. In this plot it shows that most simulated posterior datasets saw rain on 18% of the days, just like the real data, with some as low as 15% and others as high as 23%:\n\n::: {.panel-tabset}\n### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_weather_brms, ndraws = 500,\n         type = \"stat\") +\n  labs(x = \"Probability of rain\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\n### rstanrm\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_weather_rstanarm, nreps = 500,\n         plotfun = \"stat\") +\n  labs(x = \"Probability of rain\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n\n:::\n\n## How accurate are the model’s posterior classifications?\n\nIn other types of models, we answered this by looking at the difference between actual $Y$ and its posterior predictions. That's a little different here with binary data—our posterior predictions are either right or wrong and don't have any sort of measurable distance. So we want to know how often we're right, not how close we are to being right.\n\nHere we'll get posterior predicted draws for each row in the original dataset (8,000 draws per 1,000 rows). These are a bunch of 1s and 0s, so we'll take the average of those 1s and 0s to get the overall proportion of predicted 1s for that day, which will be the predicted probability of tomorrow's rain for that day. We'll then choose some cutoff point, like 50%, to classify whether we will count that as a prediction of rain tomorrow or not.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction_brms_all <- weather |> \n  add_predicted_draws(model_weather_brms)\n\nrain_classifications <- prediction_brms_all |> \n  group_by(.row) |> \n  summarize(rain_prob_that_day = mean(.prediction),\n            raintomorrow_actual = raintomorrow[1]) |> \n  mutate(raintomorrow_pred = rain_prob_that_day >= 0.5)\nrain_classifications\n## # A tibble: 1,000 × 4\n##     .row rain_prob_that_day raintomorrow_actual raintomorrow_pred\n##    <int>              <dbl> <fct>               <lgl>            \n##  1     1             0.128  No                  FALSE            \n##  2     2             0.078  No                  FALSE            \n##  3     3             0.163  Yes                 FALSE            \n##  4     4             0.117  No                  FALSE            \n##  5     5             0.181  No                  FALSE            \n##  6     6             0.361  No                  FALSE            \n##  7     7             0.0912 No                  FALSE            \n##  8     8             0.107  No                  FALSE            \n##  9     9             0.0842 Yes                 FALSE            \n## 10    10             0.432  Yes                 FALSE            \n## # … with 990 more rows\n```\n:::\n\n\nIn these first 10 rows, none of the days predict rain the following day since their predicted probabilities are all under 0.5. But rows 3, 9, and 10 *did* actually rain the next day, so those predictions were wrong.\n\nWe can get an overall count of times the model predicted rain and was right or wrong by creating what the machine learning world calls a *confusion matrix*. We can do this with dplyr's `count()` and tidyr's `pivot_wider()`, or we can use janitor's `tabyl()`. Both do the same thing.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrain_classifications |> \n  count(raintomorrow_actual, raintomorrow_pred) |> \n  pivot_wider(names_from = \"raintomorrow_pred\", values_from = \"n\")\n## # A tibble: 2 × 3\n##   raintomorrow_actual `FALSE` `TRUE`\n##   <fct>                 <int>  <int>\n## 1 No                      805      9\n## 2 Yes                     172     14\n\nrain_classifications |> \n  janitor::tabyl(raintomorrow_actual, raintomorrow_pred) |> \n  janitor::adorn_totals(c(\"row\", \"col\"))\n##  raintomorrow_actual FALSE TRUE Total\n##                   No   805    9   814\n##                  Yes   172   14   186\n##                Total   977   23  1000\n```\n:::\n\n\nWe can think of this confusion matrix more generally with letters assigned to specific cells, where $Y$ represents the observed outcome and $\\hat{Y}$ represents the predicted outcome:\n\n|         | $\\hat{Y} = 0$ | $\\hat{Y} = 1$ |\n|---------|:-------------:|:-------------:|\n| $Y = 0$ |      *a*      |      *b*      |\n| $Y = 1$ |      *c*      |      *d*      |\n\nBased on this, we correctly classified 805 No/No cases (cell $a$) and 14 Yes/Yes cases(cell *d*), resulting in 819 total correct predictions. That implies an **overall classification accuracy rate** of 81.9%. More formally, this is $\\frac{a + d}{a + b + c + d}$.\n\nWe can also look at the **true negative rate**, or **specificity**. Out of the 814 (805 in *a* + 9 in *b*) days where it didn't rain, we correctly classified 805, or 98.9%. Formally the specificity (true negative rate) is $\\frac{a}{a + b}$.\n\nFinally we can also look at the **true positive rate**, or **sensitivity**. Out of the 186 (172 in *c* + 14 in *d*) days where it *does* rain, we correctly classified 14, or 7.5%. Oooof. We're really good at guessing when it won't rain; we're awful at guessing when it will rain. Formally sensitivity (true positive rate) is $\\frac{c}{c + d}$. \n\nWe don't have to stick with a 50% cutoff for classification. We can increase the sensitivity by saying that we'll predict rain if there's a 20+% probability in a given day.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrain_classifications_20 <- prediction_brms_all |> \n  group_by(.row) |> \n  summarize(rain_prob_that_day = mean(.prediction),\n            raintomorrow_actual = raintomorrow[1]) |> \n  mutate(raintomorrow_pred = rain_prob_that_day >= 0.2)\n\nrain_classifications_20 |> \n  janitor::tabyl(raintomorrow_actual, raintomorrow_pred) |> \n  janitor::adorn_totals(c(\"row\", \"col\"))\n##  raintomorrow_actual FALSE TRUE Total\n##                   No   579  235   814\n##                  Yes    66  120   186\n##                Total   645  355  1000\n```\n:::\n\n\n\n\nNow we have different accuracy rates:\n\n- Overall accuracy ($\\frac{a + d}{a + b + c + d}$): **69.9%**\n- Specificity, or true negative rate ($\\frac{a}{a + b}$): **71.1%**\n- Sensitivity, or true positive rate ($\\frac{c}{c + d}$): **64.5%**\n\nThe sensitivity rate is waaay better than before now! But that's at the cost of specificity:\n\n> Yet this improvement is not without consequences. In lowering the cut-off, we make it more difficult to predict when it *won’t* rain… and we’ll carry around an umbrella more often than we need to.\n\n\n# 13.6: Extending the model\n\nIn the book they run a new model that also includes 3 PM humidity and an indicator for whether or not it rained that day. I'll do that here too, but not with rstanarm. I'll also do it with raw Stan for fun and learning. \n\n## Specify the model and priors\n\nWe'll use the same model as before, but now with a couple new coefficients for 3 PM humidity and rain today. In the book they used vague priors for all the coefficients, so I'll do that here too. (It seems like these all came from rstanarm's autoscaled priors.)\n\n$$\n\\begin{aligned}\n\\text{Rain tomorrow}_i \\sim&\\ \\operatorname{Bernoulli}(\\pi_i) \\\\\n\\operatorname{logit}(\\pi_i) =&\\ \\beta_{0c} + \\beta_1\\ \\text{9 AM humidity}_i + \\\\\n&\\ \\beta_2\\ \\text{3 PM humidity}_i + \\beta_3\\ \\text{Rain today}_i \\\\\n\\\\\n\\beta_{0c} \\sim&\\ \\mathcal{N}(-1.39, 0.7) \\\\\n\\beta_1 \\sim&\\ \\mathcal{N}(0, 0.14) \\\\\n\\beta_2 \\sim&\\ \\mathcal{N}(0, 0.15) \\\\\n\\beta_3 \\sim&\\ \\mathcal{N}(0, 6.45)\n\\end{aligned}\n$$\n\n## Simulate the posterior\n\n::: {.panel-tabset}\n### brms\n\n\n::: {.cell hash='13-chapter_cache/html/model-weather-full-brms_8150762bccd04b6d56726358d6c3fc87'}\n\n```{.r .cell-code}\npriors <- c(prior(normal(-1.39, 0.7), class = Intercept),\n            prior(normal(0, 0.14), class = b, coef = \"humidity9am_c\"),\n            prior(normal(0, 0.15), class = b, coef = \"humidity3pm_c\"),\n            prior(normal(0, 6.45), class = b, coef = \"raintodayYes\"))\n\nmodel_weather_full_brms <- brm(\n  bf(raintomorrow ~ humidity9am_c + humidity3pm_c + raintoday),\n  data = weather,\n  family = bernoulli(link = \"logit\"),\n  prior = priors,\n  chains = 4, iter = 4000, seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0\n)\n## Start sampling\n```\n:::\n\n\n### Raw Stan\n\n\n::: {.cell file='13-stan/weather-full.stan' output.var='' filename='13-stan/weather-full.stan'}\n\n```{.stan .cell-code}\ndata {\n  int<lower=0> n;  // Number of rows\n  int<lower=0> k;  // Number of predictors\n  matrix[n,k] X;   // Predictors\n  array[n] int Y;  // Outcome variable\n}\n\nparameters {\n  real alpha;\n  vector[k] beta;\n}\n\nmodel {\n  // Priors\n  alpha ~ normal(-1.4, 0.7);\n  beta[1] ~ normal(0, 0.14);\n  beta[2] ~ normal(0, 0.15);\n  beta[3] ~ normal(0, 6.45);\n  \n  // Model\n  Y ~ bernoulli_logit_glm(X, alpha, beta);\n}\n\ngenerated quantities {\n  array[n] int Y_rep;\n  vector[n] log_lik;\n\n  vector[n] pi_hat = alpha + X * beta;\n  \n  for (i in 1:n) {\n    // We can use the shortcut bernoulli_logit_glm_lpmf, which works just like \n    // bernoulli_logit_glm from earlier\n    log_lik[i] = bernoulli_logit_glm_lpmf({Y[i]} | X[i,], alpha, beta);\n\n    // Or we can use bernoulli_logit_lpmf and feed it pi_hat\n    // log_lik[i] = bernoulli_logit_lpmf(Y[i] | pi_hat[i]);\n\n    // Posterior predictive distribution\n    Y_rep[i] = bernoulli_logit_rng(pi_hat[i]);\n  }\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_stan <- cmdstan_model(\"13-stan/weather-full.stan\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- model.matrix(~ 1 + humidity9am_c + humidity3pm_c + raintoday, data = weather)[,-1]\n\nweather_samples <- weather_stan$sample(\n  data = list(n = nrow(weather), \n              Y = weather$raintomorrow_num, \n              X = X,\n              k = ncol(X)),\n  parallel_chains = 4, iter_warmup = 2000, iter_sampling = 2000, \n  refresh = 0, seed = BAYES_SEED\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 1.9 seconds.\n## Chain 2 finished in 2.0 seconds.\n## Chain 3 finished in 1.9 seconds.\n## Chain 4 finished in 1.9 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 1.9 seconds.\n## Total execution time: 2.0 seconds.\n```\n:::\n\n\nIt works! I'm not going to work with any of these results, though, since it's a hassle. But it's exciting that it works!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_samples$print(\n  variables = c(\"alpha\", \"beta[1]\", \"beta[2]\", \"beta[3]\"), \n  \"mean\", \"median\", \"sd\", ~quantile(.x, probs = c(0.025, 0.975))\n)\n##  variable  mean median   sd  2.5% 97.5%\n##   alpha   -2.23  -2.22 0.13 -2.49 -1.99\n##   beta[1] -0.01  -0.01 0.01 -0.02  0.01\n##   beta[2]  0.08   0.08 0.01  0.06  0.10\n##   beta[3]  1.14   1.14 0.22  0.72  1.57\n\nweather_samples$loo()\n## \n## Computed from 8000 by 1000 log-likelihood matrix\n## \n##          Estimate   SE\n## elpd_loo   -356.8 20.7\n## p_loo         4.1  0.3\n## looic       713.7 41.5\n## ------\n## Monte Carlo SE of elpd_loo is 0.0.\n## \n## All Pareto k estimates are good (k < 0.5).\n## See help('pareto-k-diagnostic') for details.\n\nyrep_draws <- weather_samples$draws(\"Y_rep\") |> \n  posterior::as_draws_matrix()\n\nbayesplot::ppc_bars(y = weather$raintomorrow_num, \n                    yrep = yrep_draws[sample(nrow(yrep_draws), 100), ])\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-53-1.png){width=672}\n:::\n:::\n\n:::\n\n## Interpretation and marginal effects\n\nLogit/log odds-scale coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(model_weather_full_brms, centrality = \"mean\", dispersion = TRUE, \n                 test = FALSE, verbose = FALSE, ci_method = \"hdi\", priors = TRUE)\n## Parameter     |      Mean |       SD |         95% CI |  Rhat |     ESS |                  Prior\n## ------------------------------------------------------------------------------------------------\n## (Intercept)   |     -2.24 |     0.13 | [-2.50, -1.99] | 1.000 | 5564.00 | Normal (-1.39 +- 0.70)\n## humidity9am_c | -6.91e-03 | 7.51e-03 | [-0.02,  0.01] | 1.000 | 6201.00 |  Normal (0.00 +- 0.14)\n## humidity3pm_c |      0.08 | 8.76e-03 | [ 0.06,  0.10] | 1.001 | 5268.00 |  Normal (0.00 +- 0.15)\n## raintodayYes  |      1.15 |     0.22 | [ 0.70,  1.56] | 1.000 | 6809.00 |  Normal (0.00 +- 6.45)\n```\n:::\n\n\nOdds ratio-scale coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(model_weather_full_brms, centrality = \"mean\", dispersion = TRUE, \n                 test = FALSE, verbose = FALSE, ci_method = \"hdi\", priors = TRUE,\n                 exponentiate = TRUE) |> \n  print(digits = 3, zap_small = TRUE)\n## Parameter     |  Mean |    SD |       95% CI |  Rhat |      ESS |                  Prior\n## ----------------------------------------------------------------------------------------\n## (Intercept)   | 0.107 | 0.130 | [0.08, 0.14] | 1.000 | 5564.000 | Normal (-1.39 +- 0.70)\n## humidity9am_c | 0.993 | 0.008 | [0.98, 1.01] | 1.000 | 6201.000 |  Normal (0.00 +- 0.14)\n## humidity3pm_c | 1.083 | 0.009 | [1.07, 1.10] | 1.001 | 5268.000 |  Normal (0.00 +- 0.15)\n## raintodayYes  | 3.169 | 0.219 | [2.02, 4.75] | 1.000 | 6809.000 |  Normal (0.00 +- 6.45)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_weather_full_brms |> \n  gather_draws(`^b_.*`, regex = TRUE) |>\n  mutate(.value = exp(.value)) |> \n  mutate(.variable = factor(.variable, \n                            levels = c(\"b_Intercept\", \"b_humidity9am_c\",\n                                       \"b_humidity3pm_c\", \"b_raintodayYes\"),\n                            ordered = TRUE)) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = c(clrs[5], clrs[4], clrs[3], clrs[1]), guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\")\n## Warning: Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-56-1.png){width=672}\n:::\n:::\n\n\nAfter exponentiating it, the intercept $\\beta_0$ has a posterior mean of 0.107 with a 95% credible interval of 0.08–0.14. This represents the probability of rain tomorrow (10.7%) when 9 AM humidity is average (60.87), when 3 PM humidity is average (45.8), and when there was no rain today.\n\nThe $\\beta_1$ and $\\beta_2$ coefficients show the effect of humidity. After after un-logiting them through exponentiation, morning humidity doesn't do much anymore. It has a posterior mean of 0.993, with a 95% credible interval of 0.98–1.01. Afternoon humidity, on the other hand, does matter, with a posterior mean of 1.083 and a 95% credible interval of 1.07–1.10. This means that a 1 percentage point increase in afternoon humidity makes it 7–10% more likely to rain tomorrow, on average. The book makes the important point that 9 AM humidity's loss of importance doesn't mean it's not a significant predictor of tomorrow's rain—it *was* in the simpler model above. Instead, \n\n> Rather, `humidity9am` isn’t a significant predictor of tomorrow’s rain *when controlling for afternoon humidity and whether or not it rains today*. Put another way, if we already know today’s `humidity3pm` and rain status, then knowing `humidity9am` doesn’t significantly improve our understanding of whether or not it rains tomorrow. This shift in understanding about `humidity9am` … might not be much of a surprise – `humidity9am` is strongly associated with `humidity3pm` and `raintoday`, thus the information it holds about raintomorrow is somewhat redundant in [the larger model].\n\nAnd finally, the exponentiated $\\beta_3$ coefficient for rain today has a posterior mean of 3.169 witih a 95% credible interval of 2.02–4.75, which means that rain today makes it 2 to almost-5 times more likely to rain tomorrow.\n\nFor fun, we can look at some of the moving predictions and marginal effects of this model. Because there are multiple variables, we need to hold some constant in order to plot these in two dimensions. We'll hold 9 AM humidity constant at its average value (which is conveniently 0, since we centered it) and look at the predicted probabilities of weather across a range of 3 PM humidity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fast automatic version:\n# plot_cap(model_weather_full_brms, condition = c(\"humidity3pm_c\", \"raintoday\"))\n\nexpand_grid(humidity9am_c = 0,\n            humidity3pm = seq(0, 100, by = 1),\n            raintoday = c(\"No\", \"Yes\")) |> \n  mutate(humidity3pm_c = humidity3pm - unscaled$humidity3pm_centered$scaled_center) |> \n  add_epred_draws(model_weather_full_brms) |> \n  ggplot(aes(x = humidity3pm, y = .epred, color = raintoday)) +\n  geom_dots(data = weather, \n            aes(y = raintomorrow_num, \n                side = ifelse(raintomorrow_num == 1, \"bottom\", \"top\")), \n            pch = 19, color = \"grey70\", scale = 0.65, alpha = 0.75) +\n  stat_lineribbon(aes(fill = raintoday), alpha = 0.35) + \n  scale_color_manual(values = c(clrs[6], clrs[4])) +\n  scale_fill_manual(values = c(clrs[6], clrs[4])) +\n  labs(x = \"3 PM humidity\", y = \"Posterior probability of rain tomorrow\", \n       color = \"Rain today\", fill = \"Rain today\") +\n  theme(legend.position = \"bottom\")\n## Warning: Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-57-1.png){width=672}\n:::\n:::\n\n\nThis is neat! When it rains, the probability of rain the next day is higher than it is for non-rainy days, regardless of the afternoon humidity. As afternoon humidity increases, the probability of rain also increases, and seems to be steepest at 60–70% humidity.\n\nWe can find the slopes of those fitted lines with `marginaleffects()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fast automatic version:\n# plot_cme(model_weather_full_brms, effect = \"humidity3pm_c\",\n#          condition = c(\"humidity3pm_c\", \"raintoday\"))\n\nmfx_full <- model_weather_full_brms |> \n  marginaleffects(newdata = datagrid(humidity9am_c = 0,\n                                     humidity3pm_c = seq(0, 100, by = 1) -\n                                       unscaled$humidity3pm_centered$scaled_center,\n                                     raintoday = c(\"No\", \"Yes\")),\n                  variables = c(\"humidity3pm_c\", \"raintoday\"),\n                  type = \"response\")\ntidy(mfx_full)\n##       type          term contrast    estimate    conf.low   conf.high\n## 1 response humidity3pm_c    dY/dX 0.009129328 0.008342123 0.009575226\n## 2 response     raintoday Yes - No 0.132734228 0.079558025 0.192418252\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_full |> \n  posteriordraws() |> \n  mutate(humidity3pm = humidity3pm_c + unscaled$humidity3pm_centered$scaled_center) |> \n  filter(term != \"raintoday\" | raintoday != \"Yes\") |> \n  mutate(raintoday = ifelse(term == \"raintoday\", \"contrast\", as.character(raintoday))) |> \n  ggplot(aes(x = humidity3pm, y = draw, color = raintoday, fill = raintoday)) +\n  stat_lineribbon(alpha = 0.25) +\n  scale_color_manual(values = c(clrs[6], clrs[4], clrs[1]),\n                     breaks = c(\"No\", \"Yes\"), na.value = clrs[1]) +\n  scale_fill_manual(values = c(clrs[6], clrs[4], clrs[1]),\n                    breaks = c(\"No\", \"Yes\"), na.value = clrs[1]) +\n  labs(x = \"3 PM humidity\", \n       y = \"Marginal effect or ∆ in group means\", \n       color = \"Rain today\", fill = \"Rain today\") +\n  facet_wrap(vars(term, contrast), scales = \"free_y\") +\n  theme(legend.position = \"bottom\")\n## Warning: Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n## Unknown or uninitialised column: `linewidth`.\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-59-1.png){width=672}\n:::\n:::\n\n\n\n## Prediction and classification\n\nWe'll use this more complex model to predict the probability of rain tomorrow given 99% humidity at 3 PM and both rain today and no rain today, holding morning humidity constant at its average, similar to what we did with the simple model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhumidity_99_c <- 99 - unscaled$humidity3pm_centered$scaled_center\n\nprediction_full <- model_weather_full_brms |> \n  predicted_draws(newdata = expand_grid(humidity9am_c = 0,\n                                        humidity3pm_c = humidity_99_c,\n                                        raintoday = c(\"No\", \"Yes\")))\n\nprediction_full |> \n  count(.prediction, raintoday) |> \n  mutate(prop = n / sum(n),\n         prop_nice = label_percent(accuracy = 0.1)(prop)) |> \n  ggplot(aes(x = factor(.prediction), y = n)) + \n  geom_col(aes(fill = factor(.prediction))) +\n  geom_label(aes(label = prop_nice), nudge_y = -500) +\n  scale_fill_manual(values = c(clrs[2], clrs[3]), guide = \"none\") +\n  facet_wrap(vars(raintoday))\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-60-1.png){width=672}\n:::\n:::\n\n\n\n## Model evaluation\n\n### How fair is the model?\n\nGreat.\n\n### How wrong is the model?\n\nThe posterior predictive checks look fine:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_weather_full_brms, ndraws = 100,\n         type = \"bars\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-61-1.png){width=672}\n:::\n:::\n\n\nMost simulated posterior datasets saw rain on 18ish% of days, ranging between 14% and 23%, and in reality the true value is around 18%, so that's good:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_weather_full_brms, ndraws = 500,\n         type = \"stat\") +\n  labs(x = \"Probability of rain\")\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-62-1.png){width=672}\n:::\n:::\n\n\n### How accurate are the model's posterior classifications?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction_brms_full <- weather |> \n  add_predicted_draws(model_weather_full_brms)\n\nrain_classifications_full <- prediction_brms_full |> \n  group_by(.row) |> \n  summarize(rain_prob_that_day = mean(.prediction),\n            raintomorrow_actual = raintomorrow[1]) |> \n  mutate(raintomorrow_pred = rain_prob_that_day >= 0.5)\n\nrain_classifications_full |> \n  janitor::tabyl(raintomorrow_actual, raintomorrow_pred) |> \n  janitor::adorn_totals(c(\"row\", \"col\"))\n##  raintomorrow_actual FALSE TRUE Total\n##                   No   783   31   814\n##                  Yes   108   78   186\n##                Total   891  109  1000\n```\n:::\n\n\n\n\nHere are all the different accuracy rates:\n\n- Overall accuracy ($\\frac{a + d}{a + b + c + d}$): **86.1%**\n- Specificity, or true negative rate ($\\frac{a}{a + b}$): **96.2%**\n- Sensitivity, or true positive rate ($\\frac{c}{c + d}$): **41.9%**\n\nThe overall accuracy is a little better than the simple model using a 50% threshold (it was 82ish%; now it's 86%). The specificity/true negative rate declined a *tiny* bit (it was 99%; now it's 96%). The sensitivity/true positive rate is substantially better though (it was 7.5%; now it's 42.5%!!)\n\n\n### How does this model compare with the simpler one?\n\nWe can get a formal measure of these two models' predictive power by comparing their ELPD values. The more complex model is substantially better than the simple one.\n\n\n::: {.cell hash='13-chapter_cache/html/loo-stats_f9d6e6d246803107c75cdbb5c7a310ba'}\n\n```{.r .cell-code}\nloo_stats <- tribble(\n  ~model_name, ~model,\n  \"Simple model\", model_weather_brms,\n  \"Complex model\", model_weather_full_brms\n) |> \n  mutate(loo = map(model, ~loo(.))) |> \n  mutate(loo_stuff = map(loo, ~as_tibble(.$estimates, rownames = \"statistic\"))) |> \n  select(model_name, loo_stuff) |> \n  unnest(loo_stuff) |> \n  filter(statistic == \"elpd_loo\") |> \n  arrange(desc(Estimate))\nloo_stats\n## # A tibble: 2 × 4\n##   model_name    statistic Estimate    SE\n##   <chr>         <chr>        <dbl> <dbl>\n## 1 Complex model elpd_loo     -357.  20.8\n## 2 Simple model  elpd_loo     -437.  19.0\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nloo_stats |> \n  mutate(model_name = fct_rev(fct_inorder(model_name))) |> \n  ggplot(aes(x = Estimate, y = model_name)) +\n  geom_pointrange(aes(xmin = Estimate - 2 * SE, xmax = Estimate + 2 * SE))\n```\n\n::: {.cell-output-display}\n![](13-chapter_files/figure-html/unnamed-chunk-65-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='13-chapter_cache/html/loo-compare_bc1f1588f547d62abe93f6b513e04b90'}\n\n```{.r .cell-code}\nloo_compare(loo(model_weather_brms), \n            loo(model_weather_full_brms))\n##                         elpd_diff se_diff\n## model_weather_full_brms   0.0       0.0  \n## model_weather_brms      -80.1      13.5\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}