{
  "hash": "ef1ccd975b91b60a256947f6c5dd7215",
  "result": {
    "markdown": "---\ntitle: \"Reading notes\"\nsubtitle: \"Bayes' Rule\"\ndate: \"September 3, 2022\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(janitor)\n\n# Import article data\ndata(fake_news)\n\nperc <- scales::label_percent(accuracy = 1)\nperc2 <- scales::label_percent(accuracy = 0.01)\n```\n:::\n\n\nHow many are fake vs. real?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfake_news %>% \n  count(type) %>% \n  adorn_totals(\"row\")\n##   type   n\n##   fake  60\n##   real  90\n##  Total 150\n```\n:::\n\n\n60/150 or 40% of news articles are fake .\n\nHow is the use of exclamation marks distributed across fake and real news articles?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfake_news %>% \n  tabyl(title_has_excl, type) %>% \n  adorn_totals(\"row\")\n##  title_has_excl fake real\n##           FALSE   44   88\n##            TRUE   16    2\n##           Total   60   90\n```\n:::\n\n\n16/60 or 26.67% of news articles with !s are fake; only 2/90 or 2.22% of real articles with have !s.\n\nOur prior is thus that 40% of news articles are fake. We have new data, that !s are more common in fake news articles. So what's the posterior if we find an article with a !?\n\n> The chance that this article is fake jumps from 40% to roughly 90%. Though exclamation points are more common among fake articles, let’s not forget that only 40% of articles are fake.\n\n\n# Conditional probabilities\n\nWe have two variables:\n\n- Fake vs. real status\n- Use of exclamation points\n\nThese features can vary at random across different articles, so we have to represent that randomness with probabilities models\n\n## Prior probability model\n\nWe know from previous data that 40% are fake and 60% are real. If $B$ means the article is fake, we can write that as\n\n$$\nP(B) = 0.40 \\text{ and } P(B^c) = 0.60\n$$\n\n## Conditional probability\n\nThe occurrence of !s depends on fakeness. Conditional probabilities of !s and fakeness, where $A$ is the use of an exclamation mark:\n\n$$\nP(A \\mid B) = 0.2667 \\text{ and } P(A \\mid B^c) = 0.0222\n$$\n\nBy comparing conditional vs. unconditional probabilities, we learn how much $B$ can inform our understanding of $A$.\n\nAn event $A$ might increase in probability given $B$, like how the probability of joining an orchestra is greater if we know someonw practices daily:\n\n$$\nP(\\text{join orchestra} \\mid \\text{practice daily}) > P(\\text{join orchestra})\n$$\n\nOr the probability of getting the flu is lower if you know someone washes their hands a lot:\n\n$$\nP(\\text{get flu} \\mid \\text{wash hands regularly}) < P(\\text{get flu})\n$$\n\n## Likelihood\n\nLikelihood is kind of like the inverse of probability (not really! just that the order of A and B matters)\n\n- If we know $B$, the conditional probability $P(\\cdot \\mid B)$ lets us compare the probabilities of an unknown event $A$ (or $A^c$) occurring with $B$, or\n\n  $$\n  P(A \\mid B) \\text{ vs. } P(A^c \\mid B)\n  $$\n\n- If we know $A$, the likelihood function $L(\\cdot \\mid A) = P(A \\mid \\cdot)$ lets us compare the relative compatibility of data $A$ with events $B$ or $B^c$\n\n  $$\n  L(B \\mid A) \\text{ vs. } L(B^c \\mid A)\n  $$\n\n\nWhat this looks like in practice, where $A$ means having an exclamation mark and $B$ means being fake:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prior probability\nrow_prior <- fake_news %>% \n  count(type) %>% \n  mutate(prop = n / sum(n)) %>% \n  select(-n) %>% \n  pivot_wider(names_from = type, values_from = prop)\n\n# Likelihood\nrow_likelihood <- fake_news %>% \n  count(type, title_has_excl) %>% \n  pivot_wider(names_from = title_has_excl, values_from = n) %>% \n  mutate(likelihood = `TRUE` / (`TRUE` + `FALSE`)) %>% \n  select(-c(`FALSE`, `TRUE`)) %>%\n  pivot_wider(names_from = type, values_from = likelihood)\n\nbind_cols(Statistic = c(\"Prior probability\", \"Likelihood\"),\n          bind_rows(row_prior, row_likelihood)) %>% \n  mutate(Total = fake + real) %>% \n  rename(`Fake ($B$)` = fake, \n         `Real ($B^c$)` = real) %>% \n  knitr::kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|Statistic         | Fake ($B$)| Real ($B^c$)| Total|\n|:-----------------|----------:|------------:|-----:|\n|Prior probability |      0.400|        0.600| 1.000|\n|Likelihood        |      0.267|        0.022| 0.289|\n:::\n:::\n\n\n## Normalizing constants\n\nThe last piece we need is the marginal probability of observing exclamation points across all articles, or $P(A)$, which is the normalizing constant, or $P(B)L(B \\mid A) + P(B^c)L(B^c \\mid A)$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfake_news %>% \n  count(type, title_has_excl) %>% \n  mutate(prop = n / sum(n)) %>% \n  filter(title_has_excl == TRUE) %>% \n  summarize(normalizing_constant = sum(prop))\n##   normalizing_constant\n## 1                 0.12\n```\n:::\n\n\n## Final analytical posterior\n\nThus, given this formula:\n\n$$\n\\text{posterior} = \\frac{\\text{prior} \\times \\text{likelihood}}{\\text{normalizing constant}}\n$$\n\n…we have \n\n$$\n\\text{posterior} = \\frac{0.4 \\times 0.2667}{0.12} = 0.889\n$$\n\n# Simulation\n\nWe can simulate this too\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_params <- tibble(type = c(\"real\", \"fake\"),\n                     prior = c(0.6, 0.4))\n\nset.seed(1234)\n\nsims <- sample(sim_params$type, size = 10000, prob = sim_params$prior, replace = TRUE) %>% \n  enframe(value = \"type\") %>% \n  mutate(data_model = case_when(type == \"fake\" ~ 0.2667,\n                                type == \"real\" ~ 0.0222)) %>% \n  rowwise() %>% \n  mutate(usage = sample(c(\"no\", \"yes\"), size = 1,\n                        prob = c(1 - data_model, data_model))) %>% \n  ungroup()\n\nsims %>% \n  tabyl(usage, type) %>% \n  adorn_totals(c(\"col\", \"row\"))\n##  usage fake real Total\n##     no 2914 5872  8786\n##    yes 1075  139  1214\n##  Total 3989 6011 10000\n\nggplot(sims, aes(x = type, fill = usage)) +\n  geom_bar(position = position_fill())\n```\n\n::: {.cell-output-display}\n![](02-chapter_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Posterior\nsims %>% \n  filter(usage == \"yes\") %>% \n  count(type) %>% \n  mutate(prop = n / sum(n))\n## # A tibble: 2 × 3\n##   type      n  prop\n##   <chr> <int> <dbl>\n## 1 fake   1075 0.886\n## 2 real    139 0.114\n```\n:::\n\n\n# Chess simulation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchess <- c(0.2, 0.5, 0.8)\nprior <- c(0.1, 0.25, 0.65)\n\nset.seed(1234)\nchess_sim <- tibble(pi = sample(chess, size = 10000, prob = prior, replace = TRUE)) %>% \n  mutate(y = rbinom(n(), size = 6, prob = pi))\n\nchess_sim %>% \n  count(pi) %>% \n  mutate(prop = n / sum(n))\n## # A tibble: 3 × 3\n##      pi     n   prop\n##   <dbl> <int>  <dbl>\n## 1   0.2   986 0.0986\n## 2   0.5  2523 0.252 \n## 3   0.8  6491 0.649\n\nchess_sim %>% \n  ggplot(aes(x = y)) +\n  stat_count(aes(y = ..prop..)) +\n  facet_wrap(vars(pi))\n```\n\n::: {.cell-output-display}\n![](02-chapter_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "02-chapter_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}