{
  "hash": "4eb200a2696e73d439faa3eaa399948f",
  "result": {
    "markdown": "---\ntitle: \"18: Non-normal hierarchical regression & classification\"\nsubtitle: \"Reading notes\"\ndate: \"November 8, 2022\"\nformat:\n  html:\n    toc-depth: 5\n---\n\n\n[(Original chapter)](https://www.bayesrulesbook.com/chapter-18.html)\n\nAll this multilevel modeling stuff also works with other distributional families. This chapter covers logistic regression and Poisson regression, but the same principles apply to any distribution supported by Stan. This chapter is a lot less detailed than chapters 15, 16, and 17, which spend a ton of time on the mechanics of multilevel models. Instead, this just shows how to add multiple levels to logit and Poisson models. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(rstanarm)\nlibrary(marginaleffects)\nlibrary(broom)\nlibrary(broom.mixed)\nlibrary(parameters)\nlibrary(tidybayes)\nlibrary(patchwork)\nlibrary(scales)\nlibrary(ggtext)\nlibrary(gghalves)\nlibrary(gt)\n\noptions(width = 100)\n\n# tikz stuff\n# Necessary for using dvisvgm on macOS\n# See https://www.andrewheiss.com/blog/2021/08/27/tikz-knitr-html-svg-fun/\nSys.setenv(LIBGS = \"/usr/local/share/ghostscript/9.53.3/lib/libgs.dylib.9.53\")\n\nfont_opts <- list(dvisvgm.opts = \"--font-format=woff\")\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Tell bayesplot to use the Lakota palette for things like pp_check()\n# bayesplot::color_scheme_set(clrs)\n\n# Tell bayesplot to use the viridis rocket palette for things like pp_check()\nviridisLite::viridis(6, option = \"rocket\", end = 0.85, direction = -1) |> \n  # Take off the trailing \"FF\" in the hex codes\n  map_chr(~str_sub(., 1, 7)) |> \n  bayesplot::color_scheme_set()\n\n# Seed stuff\nset.seed(1234)\nBAYES_SEED <- 1234\n\n# Data stuff\ndata(climbers_sub, package = \"bayesrules\")\ndata(airbnb, package = \"bayesrules\")\n\nclimbers <- climbers_sub %>% \n  select(expedition_id, member_id, success, year, season,\n         age, expedition_role, oxygen_used) |> \n  mutate(age_c = scale(age, scale = FALSE))\n\nairbnb <- airbnb |> \n  mutate(rating_c = scale(rating, scale = FALSE)) |> \n  mutate(neighborhood = as.character(neighborhood))\n\nextract_attributes <- function(x) {\n  attributes(x) %>%\n    set_names(janitor::make_clean_names(names(.))) %>%\n    as_tibble() %>%\n    slice(1)\n}\n\nunscaled_climbers <- climbers %>%\n  select(ends_with(\"_c\")) |> \n  summarize(across(everything(), ~extract_attributes(.))) |> \n  pivot_longer(everything()) |> \n  unnest(value) |> \n  split(~name)\n\nunscaled_airbnb <- airbnb %>%\n  select(ends_with(\"_c\")) |> \n  summarize(across(everything(), ~extract_attributes(.))) |> \n  pivot_longer(everything()) |> \n  unnest(value) |> \n  split(~name)\n\n# Access these things like so:\n# unscaled_climbers$age_c$scaled_center\n```\n:::\n\n\n\n# 18.1: Hierarchical logistic regression\n\n## The general setup\n\nWith the logistic regression example in this chapter, we want to model the probability of a successful Himalayan climbing expedition. The data we have includes details about the expedition team, the year and season of the climb, and details about the climbers themselves, like their age, their role in the expedition, and whether or not they used oxygen during the climb.\n\nMost climbers were unsuccessful and did not make it to the summit:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclimbers |> \n  count(success) |> \n  mutate(prop = n / sum(n))\n## # A tibble: 2 × 3\n##   success     n  prop\n##   <lgl>   <int> <dbl>\n## 1 FALSE    1269 0.611\n## 2 TRUE      807 0.389\n```\n:::\n\n\nThese climbers never climb on their own. They always go in groups ranging from 5 to 44 people, and teams do not always unanimously finish together:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclimbers_expeditions <- climbers |> \n  group_by(expedition_id) |> \n  summarize(n = n(), prop_success = mean(success))\n\np1 <- climbers_expeditions |> \n  ggplot(aes(x = n, y = prop_success)) +\n  geom_count(alpha = 0.8, color = clrs[5]) +\n  scale_size_area(max_size = 8, breaks = c(1, 5, 10)) +\n  labs(x = \"Expedition team size\", \n       y = \"Proportion of expedition team that finished\",\n       size = \"Number of\\nexpeditions\")\n\np2 <- climbers_expeditions |> \n  ggplot(aes(x = prop_success)) +\n  geom_histogram(binwidth = 0.05, center = 0, color = \"white\", fill = clrs[5]) +\n  labs(x = \"Proportion of expedition team that finished\", y = \"Count\")\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-3-1.png){width=864}\n:::\n:::\n\n\nWe thus have a hierarchical/multilevel structure that looks like this, with climbers $y_i$ nested in expedition teams $j$:\n\n\n::: {.cell layout-align=\"center\" engine.opts='{\"dvisvgm.opts\":\"--font-format=woff\"}'}\n::: {.cell-output-display}\n![Multilevel structure of climbers within expeditions](18-chapter_files/figure-html/partial-pooling-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n## Model building\n\nIn this example, we want to model whether an individual climber successfully reaches the summit. This is a binary outcome: 1 if yes, 0 if no. It's also an individual outcome, nested in groups, so it has subscripts:\n\n$$\n\\text{Success}_{i_j} = \\begin{cases}\n1 & \\text{Yes} \\\\\n0 & \\text{No} \\\\\n\\end{cases}\n$$\n\nIn the book they use two covariates to explain climbing success:\n\n- $X_{i_{j}1}$ or $\\text{Age}_{i_j}$: Age of climber $i$ in expedition $j$\n- $X_{i_{j}2}$ or $\\text{Oxygen}_{i_j}$: Whether climber $i$ in expedition $j$ used oxygen\n\n…so we'll do that here too. At first glance, it doesn't look like age makes much of a difference in the probability of success, but oxygen use matters *a lot*. Almost all of the successful climbers used oxygen; only a handful of oxygen-users were unsuccessful:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclimbers |> \n  ggplot(aes(x = age, y = success, color = oxygen_used)) +\n  geom_dots(aes(side = ifelse(success == TRUE, \"bottom\", \"top\")), \n            pch = 19, scale = 0.6) +\n  scale_y_discrete(expand = expansion(mult = 0.1)) +\n  scale_color_manual(values = c(clrs[3], clrs[1])) +\n  labs(x = \"Age\", y = \"Success\", color = \"Oxygen used\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nInstead of building up this model step-by-step like in previous chapters, we'll just define it all at once here:\n\n::: {.column-screen-inset}\n\n$$\n\\begin{aligned}\n\\text{Success}_{i_j} &\\sim \\operatorname{Bernoulli}(\\pi_{i_j}) & \\text{Probability of success for climber}_i \\text{ in team}_j \\\\\n\\operatorname{logit}(\\pi_{i_j}) &= \\beta_{0_j} + \\beta_1\\, \\text{Age}_{i_j} + \\beta_2\\, \\text{Oxygen}_{i_j} & \\text{Model for probability} \\\\\n\\beta_{0_j} &\\sim \\mathcal{N}(\\beta_0, \\sigma_0) & \\text{Team-specific intercepts, or baseline probabilities} \\\\\n\\\\\n\\beta_{0_c} &\\sim \\mathcal{N}(0, 2.5) & \\text{Prior for global average success rate} \\\\\n\\beta_1 &\\sim \\mathcal{N}(0, 2.5) & \\text{Prior for global age effect, holding oxygen constant} \\\\\n\\beta_2 &\\sim \\mathcal{N}(0, 2.5) & \\text{Prior for global oxygen effect, holding age constant} \\\\\n\\sigma_0 &\\sim \\operatorname{Exponential}(1) & \\text{Prior for between-team variability}\n\\end{aligned}\n$$\n\n:::\n\n\\ \n\nOr with offset-based notation:\n\n::: {.column-screen-inset}\n\n$$\n\\begin{aligned}\n\\text{Success}_{i_j} &\\sim \\operatorname{Bernoulli}(\\pi_{i_j}) & \\text{Probability of success for climber}_i \\text{ in team}_j \\\\\n\\operatorname{logit}(\\pi_{i_j}) &= (\\beta_0 + b_{0_j}) + \\beta_1\\, \\text{Age}_{i_j} + \\beta_2\\, \\text{Oxygen}_{i_j} & \\text{Model for probability} \\\\\nb_{0_j} &\\sim \\mathcal{N}(0, \\sigma_0) & \\text{Team-specific offsets from global success rate} \\\\\n\\\\\n\\beta_{0_c} &\\sim \\mathcal{N}(0, 2.5) & \\text{Prior for global average success rate} \\\\\n\\beta_1 &\\sim \\mathcal{N}(0, 2.5) & \\text{Prior for global age effect, holding oxygen constant} \\\\\n\\beta_2 &\\sim \\mathcal{N}(0, 2.5) & \\text{Prior for global oxygen effect, holding age constant} \\\\\n\\sigma_0 &\\sim \\operatorname{Exponential}(1) & \\text{Prior for between-team variability}\n\\end{aligned}\n$$\n\n:::\n\n## Posterior simulation and analysis\n\nWe can run this model by including `(1 | expedition_id)` for the random team intercepts:\n\n::: {.panel-tabset}\n### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npriors <- c(prior(normal(0, 2.5), class = Intercept),\n            prior(normal(0, 2.5), class = b),\n            prior(exponential(1), class = sd))\n\nmodel_success_brms <- brm(\n  bf(success ~ age_c + oxygen_used + (1 | expedition_id)), \n  data = climbers,\n  family = bernoulli(link = \"logit\"),\n  prior = priors,\n  chains = 4, cores = 4, iter = 4000, threads = threading(2), seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0,\n  file = \"18-manual_cache/success-brms\"\n)\n```\n:::\n\n\n### rstanarm\n\nWe'll keep the autoscaled priors here because rstan complains about init issues otherwise? \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_success_rstanarm <- stan_glmer(\n  success ~ age_c + oxygen_used + (1 | expedition_id), \n  data = climbers, family = binomial,\n  prior_intercept = normal(0, 2.5, autoscale = TRUE),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1),\n  chains = 4, cores = 4, iter = 5000*2, seed = 84735, refresh = 0)\n```\n:::\n\n\n:::\n\n### Global analysis\n\nFirst we'll look at what this model says about a typical climber, which involves the $\\beta_0$, $\\beta_1$, and $\\beta_2$ terms:\n\n::: {.panel-tabset}\n\nLogit/log odds-scale coefficients\n\n#### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_success_brms |> \n  tidy(effects = c(\"fixed\"), conf.level = 0.8) |> \n  select(-component)\n## # A tibble: 3 × 6\n##   effect term            estimate std.error conf.low conf.high\n##   <chr>  <chr>              <dbl>     <dbl>    <dbl>     <dbl>\n## 1 fixed  (Intercept)      -3.09     0.349    -3.54     -2.65  \n## 2 fixed  age_c            -0.0473   0.00913  -0.0589   -0.0358\n## 3 fixed  oxygen_usedTRUE   5.65     0.457     5.08      6.25\n```\n:::\n\n\nOdds ratio-scale coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# There's a tiny bug in broom.mixed when exponentiating, so we'll use\n# parameters::model_parameters() instead\nmodel_success_brms %>%\n  model_parameters(centrality = \"mean\", dispersion = TRUE,\n                   test = FALSE, verbose = FALSE, ci_method = \"hdi\", ci = 0.8,\n                   exponentiate = TRUE)\n## Parameter       |   Mean |       SD |           80% CI |  Rhat |     ESS\n## ------------------------------------------------------------------------\n## (Intercept)     |   0.05 |     0.35 | [  0.03,   0.07] | 1.003 | 1359.00\n## age_c           |   0.95 | 9.13e-03 | [  0.94,   0.96] | 1.000 | 7270.00\n## oxygen_usedTRUE | 284.45 |     0.46 | [157.94, 500.89] | 1.002 | 2508.00\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_success_brms |> \n  gather_draws(`^b_.*`, regex = TRUE) |>\n  ungroup() |> \n  mutate(.value = exp(.value),\n         .variable = fct_inorder(.variable)) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = c(clrs[5], clrs[4], clrs[6]), guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-8-1.png){width=768}\n:::\n:::\n\n\n\n\n#### rstanarm\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_success_rstanarm |> \n  tidy(effects = c(\"fixed\"),\n       conf.int = TRUE, conf.level = 0.8)\n## # A tibble: 3 × 5\n##   term            estimate std.error conf.low conf.high\n##   <chr>              <dbl>     <dbl>    <dbl>     <dbl>\n## 1 (Intercept)      -3.16     0.355    -3.63     -2.72  \n## 2 age_c            -0.0475   0.00922  -0.0593   -0.0358\n## 3 oxygen_usedTRUE   5.79     0.474     5.20      6.43\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# There's a tiny bug in broom.mixed when exponentiating, so we'll use\n# parameters::model_parameters() instead\nmodel_success_rstanarm %>%\n  model_parameters(centrality = \"mean\", dispersion = TRUE, prior = FALSE,\n                   test = FALSE, verbose = FALSE, ci_method = \"hdi\", ci = 0.8,\n                   exponentiate = TRUE)\n## Parameter       |   Mean |       SD |           80% CI |  Rhat |      ESS\n## -------------------------------------------------------------------------\n## (Intercept)     |   0.04 |     0.36 | [  0.03,   0.07] | 1.001 |  3980.00\n## age_c           |   0.95 | 9.21e-03 | [  0.94,   0.96] | 1.000 | 26332.00\n## oxygen_usedTRUE | 332.40 |     0.48 | [180.00, 608.64] | 1.001 |  8012.00\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_success_rstanarm |> \n  gather_draws(`(Intercept)`, age_c, oxygen_usedTRUE) |>\n  ungroup() |> \n  mutate(.value = exp(.value),\n         .variable = fct_inorder(.variable)) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = c(clrs[5], clrs[4], clrs[6]), guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-12-1.png){width=768}\n:::\n:::\n\n:::\n\nHere's how to interpret all these coefficients, using the brms results:\n\n#### Intercept ($\\beta_0$)\n\nThe posterior mean for $\\beta_0$ is -3.09, but that's weird and on the logit scale. We can convert this to the probability scale with $\\frac{e^{-3.09}}{1 + e^{-3.09}}$ or with `plogis()`, which is 0.043. This means that the posterior mean probability of success for a climber of average age (36.96 years) and when not using oxygen is 4.3%, and there's an 80% chance it's between 2.8% and 6.6%.\n\n#### Age ($\\beta_1$)\n\nThe posterior mean for $\\beta_1$ is -0.047, but that's also weird and logit-ed. We can exponentiate it ($e^{-0.047}$) and get a mean posterior odds ratio of 0.954, with an 80% credible interval of 0.943–0.965). A one-year increase in a typical climber's age makes climbing success 4.6% *less* likely (with an 80% credible interval of 3.5%–5.7%).\n\nWe can also convert these results to a much more manageable probability scale, but that's a little trickier now that we're working with multiple covariates. We can't just do this, since we also have a `b2` to deal with:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplogis(b0 + b1) - plogis(b0)\n```\n:::\n\n\nInstead, we can use the magical [**marginaleffects**](https://vincentarelbundock.github.io/marginaleffects/) package to get probability-scale estimates. First we'll plot the predicted probabilities of success as age increases, holding oxygen use constant (as a no). Note that we include `re_formula = NA` to omit any random effects—this only uses the global parameters:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fast automatic version:\n# plot_cap(model_success_brms, condition = \"age_c\", re_formula = NA)\n\ndatagrid(model = model_success_brms,\n         age_c = seq(17, 76, by = 1) - unscaled_climbers$age_c$scaled_center) |> \n  add_epred_draws(model_success_brms, re_formula = NA) |> \n  mutate(age = age_c + unscaled_climbers$age_c$scaled_center) |> \n  ggplot(aes(x = age, y = .epred)) +\n  stat_lineribbon(color = clrs[3], fill = clrs[3], alpha = 0.35) +\n  scale_y_continuous(labels = label_percent()) +\n  labs(x = \"Age\", y = \"Posterior probability of success\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nSuccessful expeditions are most likely among younger climbers, and as a typical climber ages, the probability of success decreases. We can get exact estimates of the slope of this posterior with `marginaleffects()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_success <- model_success_brms |>\n  marginaleffects(newdata = datagrid(age_c = seq(17, 76, by = 1) -\n                                       unscaled_climbers$age_c$scaled_center),\n                  variables = \"age_c\",\n                  type = \"response\", re_formula = NA) |>\n  posteriordraws() |>\n  mutate(age = age_c + unscaled_climbers$age_c$scaled_center)\n\nmfx_success |> \n  ggplot(aes(x = age, y = draw * 100)) +\n  stat_lineribbon(alpha = 0.25, fill = clrs[6], color = clrs[6]) +\n  labs(x = \"Age\", \n       y = \"Percentage point change in\\nprobability of climbing success\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nWe can pick out the slope at a few of these different ages:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_success |> \n  filter(age %in% c(18, 40, 60)) |> \n  group_by(age) |> \n  summarize(mean_slope = mean(draw),\n            conf.low = mean(conf.low),\n            conf.high = mean(conf.high)) |> \n  mutate(across(c(mean_slope, conf.low, conf.high), ~ . * 100))\n## # A tibble: 3 × 4\n##     age mean_slope conf.low conf.high\n##   <dbl>      <dbl>    <dbl>     <dbl>\n## 1    18    -0.449    -0.884   -0.166 \n## 2    40    -0.179    -0.324   -0.0784\n## 3    60    -0.0723   -0.128   -0.0336\n```\n:::\n\n\nFor a typical young climber (18 years old), a one-year increase in age is associated with a posterior mean -0.449 percentage point decrease in the probability of success. That's a sizable drop! For a typical middle-aged climber (40 years old), getting older is associated with a smaller -0.179 percentage point drop in probability, while older climbers (60 years old) see an even smaller -0.072 percentage point decline. Age thus seems to matter the most for younger climbers—it doesn't have an effect on the typical older climber.\n\n#### Oxygen ($\\beta_2$)\n\nThe posterior mean for $\\beta_2$ is 5.651 in the log odds world. Exponentiating it ($e^{5.651}$) gives us a *massive* mean posterior odds ratio of 284.446, with an 80% credible interval of 160.629–515.843). Holding age constant, oxygen use in a typical climber increases the odds of success by 161–516 times! Wild!\n\nLet's translate this to probabilities. Holy crap there's a massive difference the probability of success:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatagrid(model = model_success_brms,\n         oxygen_used = c(TRUE, FALSE)) |> \n  add_epred_draws(model_success_brms, re_formula = NA) |> \n  ggplot(aes(x = oxygen_used, y = .epred, fill = oxygen_used, color = oxygen_used)) +\n  stat_gradientinterval(width = 0.25) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_fill_manual(values = c(clrs[3], clrs[1]), guide = \"none\") +\n  scale_color_manual(values = colorspace::darken(c(clrs[3], clrs[1]), 0.5), guide = \"none\") +\n  labs(x = \"Oxygen used\", y = \"Posterior probability of success\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nTo calculate the exact difference we could just use the results from `add_epred_draws()` and do some dplyr `group_by()` and `summarize()` and subtraction work, or we can use **tidybayes**'s `compare_levels()` to do the same thing. This is a [marginal effect at user-specified values](https://www.andrewheiss.com/blog/2022/05/20/marginalia/#marginal-effects-at-user-specified-or-representative-values).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatagrid(model = model_success_brms,\n         oxygen_used = c(TRUE, FALSE)) |> \n  add_epred_draws(model_success_brms, re_formula = NA) |> \n  compare_levels(variable = .epred, by = oxygen_used) |> \n  ggplot(aes(x = .epred * 100)) +\n  stat_halfeye(fill = clrs[4]) +\n  labs(x = \"Difference in probability of success due to oxygen use\\n(Percentage points)\",\n       y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nAlternatively, we can use `marginaleffects::comparisons()` to calculate actual average marginal effects (or rather, group contrasts, since strictly speaking, marginal effects are partial derivatives). Instead of feeding the model a single average value for age, we'll plug in each original row of the data into the model and get one contrast per row.\n\n\n::: {.cell hash='18-chapter_cache/html/mfx-comparisons-success_c69727d744467804adb2ba61108380a5'}\n\n```{.r .cell-code}\nmfx_cmp_success <- model_success_brms |> \n  comparisons(variables = \"oxygen_used\", re_formula = NA)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnrow(mfx_cmp_success)\n## [1] 2076\nnrow(climbers)\n## [1] 2076\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_cmp_success |> \n  posteriordraws() |> \n  group_by(drawid) |> \n  summarize(draw = mean(draw)) |> \n  ggplot(aes(x = draw * 100)) +\n  stat_halfeye(fill = clrs[2]) +\n  labs(x = \"Difference in probability of success due to oxygen use\\n(Percentage points)\",\n       y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nFor even more bonus fun, we can actually do something new with **marginaleffects** and [integrate out the random effects](https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html#brmsmargins) ([see this too for an example](https://vincentarelbundock.github.io/marginaleffects/articles/brms.html#averaging-marginalizing-integrating-random-effects)). So far, we've been using `re_formula = NA` to ignore the expedition team effects entirely. If we use `re_formula = NULL` to include them, we either have to (1) specify one specific expedition team ID, or (2) invent a new hypothetical team that's based on the the global average. Alternatively, we can create a bunch of new hypothetical teams (like 100) and calculate either the marginal effects or contrasts for each coefficient in those hypothetical teams, then take the average (see [this vignette for **brmsmargins** for more details](https://joshuawiley.com/brmsmargins/articles/mixed-effects-marginaleffects.html#integrating-out-random-effects)). Fortunately **marginalffects** can handle all this for us:\n\n\n::: {.cell hash='18-chapter_cache/html/mfx-success-integrated-out_116691b8d62a3eba09a80a061a80b490'}\n\n```{.r .cell-code}\nmfx_success_integrated_out <- comparisons(\n  model_success_brms,\n  # 100 fake expedition IDs\n  newdata = datagrid(expedition_id = -1:-100),\n  allow_new_levels = TRUE,\n  sample_new_levels = \"gaussian\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_success_integrated_out |> summary()\n##          Term     Contrast    Effect    2.5 %  97.5 %\n## 1       age_c  (x + 1) - x -0.004151 -0.09081 0.08254\n## 2 oxygen_used TRUE - FALSE  0.520871  0.39713 0.62711\n## \n## Model type:  brmsfit \n## Prediction type:  response\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_success_integrated_out |> \n  posteriordraws() |> \n  group_by(drawid, term) |> \n  summarize(draw = mean(draw)) |> \n  mutate(term = recode(term, age_c = \"Age\", oxygen_used = \"Oxygen used\")) |> \n  ggplot(aes(x = draw * 100, fill = term)) +\n  stat_halfeye() +\n  facet_wrap(vars(term), scales = \"free_x\") +\n  scale_fill_manual(values = c(clrs[1], clrs[5]), guide = \"none\") +\n  labs(title = \"Average marginal effect of coefficients\",\n       subtitle = \"Random effects integrated out\",\n       x = \"Percentage point change in probability of success\", y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n#### Age and oxygen at the same time\n\nFor fun, here's what the effect of both age and oxygen look like simultaneously:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatagrid(model = model_success_brms,\n         oxygen_used = c(TRUE, FALSE),\n         age_c = seq(17, 76, by = 1) - unscaled_climbers$age_c$scaled_center) |> \n  add_epred_draws(model_success_brms, re_formula = NA, ndraws = 100) |> \n  mutate(age = age_c + unscaled_climbers$age_c$scaled_center) |> \n  ggplot(aes(x = age, y = .epred, color = oxygen_used)) +\n  geom_line(aes(group = paste(oxygen_used, .draw)), alpha = 0.35) +\n  scale_y_continuous(labels = label_percent()) +\n  scale_color_manual(values = c(clrs[3], clrs[1])) +\n  labs(x = \"Age\", y = \"Posterior probability of success\", \n       color = \"Oxygen used\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n### Team-specific analysis\n\nNext we can look at the team-specific details, or the offsets from the baseline probability of success:\n\n$$\nB_0 + b_{0_j}\n$$\n\nThere's a surprising amount of variation in success across teams here. Some have a predicted 97% baseline chance of success; others have practically no baseline chance of success. Here are the top 5 and bottom 5 as an example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nteam_baselines <- model_success_brms |> \n  epred_draws(tibble(expedition_id = unique(climbers$expedition_id),\n                     age_c = 0, oxygen_used = FALSE)) |> \n  ungroup() |> \n  mutate(expedition_id = fct_reorder(factor(expedition_id), .epred, .fun = mean))\n\nteam_baselines |> \n  group_by(expedition_id) |> \n  summarize(avg = mean(.epred)) |> \n  arrange(desc(avg)) |> \n  slice(1:5, 196:200)\n## # A tibble: 10 × 2\n##    expedition_id      avg\n##    <fct>            <dbl>\n##  1 TUKU16301     0.965   \n##  2 SPHN93101     0.950   \n##  3 MANA84101     0.942   \n##  4 AMAD11321     0.931   \n##  5 AMAD98311     0.926   \n##  6 MANA82401     0.000651\n##  7 MAKA08112     0.000606\n##  8 EVER07194     0.000402\n##  9 MANA08324     0.000365\n## 10 EVER19112     0.000112\n```\n:::\n\n\nAnd for bonus fun, here are all 200 teams simultaneously:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_baseline <- model_success_brms |> \n  tidy(effects = c(\"fixed\"), conf.level = 0.8) |> \n  filter(term == \"(Intercept)\") |> \n  mutate(across(c(estimate, conf.low, conf.high), plogis))\n\nteam_baselines |> \n  ggplot(aes(x = .epred, y = expedition_id)) +\n  annotate(geom = \"rect\", ymin = -Inf, ymax = Inf,\n           xmin = global_baseline$conf.low, xmax = global_baseline$conf.high,\n           fill = clrs[2], alpha = 0.4) +\n  geom_vline(xintercept = global_baseline$estimate, color = clrs[2]) +\n  stat_pointinterval(color = clrs[3], size = 0.1,\n                     point_interval = \"mean_qi\") +\n  scale_x_continuous(labels = label_percent()) +\n  labs(x = \"Baseline probability of success\", y = \"Expedition team ID\",\n       title = \"Baseline probability of expedition team success\",\n       subtitle = \"Global baseline and 80% credible interval shown in yellow\") +\n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),\n        panel.grid.major.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n\nWe can also look at how these team-specific offsets influence the age-success relationship. Here we'll plot three arbitrarily chosen teams (I just scrolled through the list and picked at random). All the model does here is shift the baseline intercept around—the slope is the same in all three panels (but looks difference because of logit slopes are nonlinear and weird).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclimbers_small <- climbers |> \n  filter(expedition_id %in% c(\"AMAD81101\", \"AMAD03107\", \"EVER07194\"))\n\nclimbers_small |> \n  add_epred_draws(model_success_brms, ndraws = 250) |> \n  ggplot(aes(x = age, y = as.numeric(success))) +\n  geom_line(aes(y = .epred, group = paste(expedition_id, .draw), \n                color = expedition_id),\n            alpha = 0.2, size = 0.3) +\n  geom_point(data = climbers_small, aes(color = expedition_id)) +\n  scale_color_manual(values = c(clrs[1], clrs[2], clrs[5]), guide = \"none\") +\n  facet_wrap(vars(expedition_id)) +\n  labs(x = \"Age\", y = \"Posterior probability of success\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n### Between-team variability\n\nWith linear regression in chapter 17, we had two forms of variability: \n\n- $\\sigma_y$ for the variability within units nested in groups (i.e. the scale term in $Y_{i_j} \\sim \\mathcal{N}(\\mu_{i_j}, \\sigma_{i_j})$)\n- $\\sigma_0$ for the variability between groups (i.e. the variation around the random offsets in $b_{0_j} \\sim \\mathcal{N}(0, \\sigma_0)$)\n\nIn logistic regression with a Bernoulli model for $Y$, we don't have a corresponding $\\sigma_y$ term for variability within expedition teams. We do have a $\\sigma_0$ term for variability between teams, so we can look at that:\n\n::: {.panel-tabset}\n\n#### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_success_brms |> \n  tidy(effects = c(\"ran_pars\"), conf.level = 0.8) |> \n  select(-component)\n## # A tibble: 1 × 7\n##   effect   group         term            estimate std.error conf.low conf.high\n##   <chr>    <chr>         <chr>              <dbl>     <dbl>    <dbl>     <dbl>\n## 1 ran_pars expedition_id sd__(Intercept)     3.57     0.337     3.16      4.02\n```\n:::\n\n\n#### rstanarm\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_success_rstanarm |> \n  tidy(effects = c(\"ran_pars\"),\n       conf.int = TRUE, conf.level = 0.8)\n## # A tibble: 1 × 3\n##   term                         group         estimate\n##   <chr>                        <chr>            <dbl>\n## 1 sd_(Intercept).expedition_id expedition_id     3.63\n```\n:::\n\n\n:::\n\n$\\sigma_0$ (or `sd__(Intercept)` for the `expedition_id` group) is 3.57, which is the amount of variance in the log odds of the global intercept, so the average baseline log odds of success varies between teams with a standard deviation of 3.57 logits/log odds. We can see this if we look at all the team-specific intercepts on the log odds scale. The global average is -3.09, marked in yellow, and there's a ton of variation around that average—a standard deviation of  3.57.\n\n[According to Isabella Ghement](https://twitter.com/IsabellaGhement/status/1589490172533825536), the \"`sd(Intercept)` term is a quantification of sorts of how 'similar' the intercepts for different [teams] … are\". If it's a big value, the teams aren't super similar; if it's small, the teams are pretty similar. These teams are not similar at all.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nteam_baselines_logit <- model_success_brms |> \n  linpred_draws(tibble(expedition_id = unique(climbers$expedition_id),\n                     age_c = 0, oxygen_used = FALSE)) |> \n  ungroup() |> \n  mutate(expedition_id = fct_reorder(factor(expedition_id), .linpred, .fun = mean))\n\nglobal_baseline_logit <- model_success_brms |> \n  tidy(effects = c(\"fixed\"), conf.level = 0.8) |> \n  filter(term == \"(Intercept)\")\n\nteam_baselines_logit |> \n  ggplot(aes(x = .linpred, y = expedition_id)) +\n  annotate(geom = \"rect\", ymin = -Inf, ymax = Inf,\n           xmin = global_baseline_logit$conf.low, xmax = global_baseline_logit$conf.high,\n           fill = clrs[2], alpha = 0.4) +\n  geom_vline(xintercept = global_baseline_logit$estimate, color = clrs[2]) +\n  stat_pointinterval(color = clrs[6], size = 0.1,\n                     point_interval = \"mean_qi\") +\n  labs(x = \"Baseline log odds\", y = \"Expedition team ID\") +\n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),\n        panel.grid.major.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\nTo make this more interpretable, [according to Isabella Ghement](https://twitter.com/IsabellaGhement/status/1589486966663675907) (and others in that super helpful Twitter thread), we can unlogit this with `plogis(Intercept ± 2*sd(Intercept))`. This gives us a *massive* range in probability land!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_success_brms |> \n  tidy(effects = c(\"fixed\", \"ran_pars\")) |> \n  filter(str_detect(term, \"Intercept\")) |> \n  select(term, estimate) |> \n  mutate(term = janitor::make_clean_names(term)) |> \n  pivot_wider(names_from = term, values_from = estimate) |> \n  mutate(range_low = plogis(intercept - (2 * sd_intercept)),\n         range_high = plogis(intercept + (2 * sd_intercept))) |> \n  mutate(across(starts_with(\"range\"), ~label_percent(accuracy = 0.01)(.)))\n## # A tibble: 1 × 4\n##   intercept sd_intercept range_low range_high\n##       <dbl>        <dbl> <chr>     <chr>     \n## 1     -3.09         3.57 0.00%     98.29%\n```\n:::\n\nTo see this better, we can look back look back at the plot with all 200 team baseline probabilities. There's a ton of variation away from that thin yellow baseline average probability. We've got sizable variation here. \n\nBut also, in the words of TJ Mahr, [\"don't overthink it.\"](https://twitter.com/tjmahr/status/1589471602227679233) :)\n\nWe can get an ICC here like we did with Gaussian regression, but I'm not entirely sure what it means. In Gaussian land, this is the proportion of variability that is attributable to between-team differences. Here, we don't have within-team differences, so I'm not sure what goes in the denominator of the ratio. But it feels like the ICC we used earlier, so it probably means something like 80ish% of the variability in success rates comes from between-team differences? I guess?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::icc(model_success_brms, by_group = TRUE)\n## # ICC by Group\n## \n## Group         |   ICC\n## ---------------------\n## expedition_id | 0.795\n```\n:::\n\n\n\n## Posterior classification\n\nTo see how this model predict/classifies new climbers, we can create a set of simulated climbers with different combinations of ages and oxygen use. As expected, the climber with the highest probability of success is the young one planning on using oxygen; the climber with the lowest probability is the old one sans oxygen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbinary_prediction <- model_success_brms |> \n  predicted_draws(expand_grid(age_c = c(20, 60) - unscaled_climbers$age_c$scaled_center,\n                              oxygen_used = c(FALSE, TRUE), expedition_id = \"New\"),\n                  allow_new_levels = TRUE)\n\nbinary_prediction |> \n  mean_qi(.prediction) |> \n  mutate(age = age_c + unscaled_climbers$age_c$scaled_center,\n         age = glue::glue(\"{age} years old\")) |> \n  ggplot(aes(x = factor(.row), y = .prediction, fill = oxygen_used)) +\n  geom_col() +\n  scale_y_continuous(labels = label_percent()) +\n  scale_fill_manual(values = c(clrs[3], clrs[1])) +\n  facet_wrap(vars(age), scales = \"free_x\") +\n  labs(x = \"Simulated climber\", y = \"Posterior predicted probability of success\",\n       fill = \"Oxygen used\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n\n## Model evaluation\n\n### How fair is the model?\n\nGreat.\n\n> The data we used are part of public record and we do not foresee our analysis having any negative impact on individuals or society. (Again, boring answers to the question of fairness are the best kind.)\n\n### How wrong is the model?\n\nWe can use `pp_check()` to compare the posterior predictions to the actual data, both with bars:\n\n::: {.panel-tabset}\n#### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_success_brms, ndraws = 100, type = \"bars\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n#### rstanarm\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_success_rstanarm, n = 100, plotfun = \"bars\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n:::\n\n…and with a histogram that shows the proportion of successful climbers in each simulated dataset compared with the observed probability of success. Most simulated posterior datasets saw successful climbs ≈42ish% of the the time, with some as low as 36% and some as high as 42%. That seems good and reasonable.\n\n::: {.panel-tabset}\n#### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_success_brms, type = \"stat\") +\n  labs(x = \"Probability of success\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n#### rstanarm\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_success_rstanarm, plotfun = \"stat\") +\n  labs(x = \"Probability of success\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n:::\n\n### How accurate are the model's posterior classifications?\n\nTo check the accuracy of our predictions, we can find the overall classification accuracy rate, the true negative rate (specificity), and the true positive rate (sensitivity rate)\n\n|         | $\\hat{Y} = 0$ | $\\hat{Y} = 1$ |\n|---------|:-------------:|:-------------:|\n| $Y = 0$ |      *a*      |      *b*      |\n| $Y = 1$ |      *c*      |      *d*      |\n\n- **Overall classification accuracy rate** = $\\frac{a + d}{a + b + c + d}$\n- **True negative rate**, or **specificity** = $\\frac{a}{a + b}$\n- **True positive rate**, or **sensitivity** = $\\frac{c}{c + d}$\n\nLet's make predictions with the existing data and classify them using a 50% cutoff—if the probability is above 50%, we'll call it successful.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuccess_preds <- model_success_brms |> \n  predicted_draws(climbers)\n\nsuccess_classifications <- success_preds |> \n  group_by(.row) |> \n  summarize(success_prob = mean(.prediction),\n            success_actual = success[1]) |> \n  mutate(success_pred = success_prob >= 0.5)\n\nsuccess_classifications |> \n  count(success_actual, success_pred) |> \n  pivot_wider(names_from = \"success_pred\", values_from = \"n\")\n## # A tibble: 2 × 3\n##   success_actual `FALSE` `TRUE`\n##   <lgl>            <int>  <int>\n## 1 FALSE             1173     96\n## 2 TRUE                78    729\n\nsuccess_classifications |> \n  janitor::tabyl(success_actual, success_pred) |> \n  janitor::adorn_totals(c(\"row\", \"col\"))\n##  success_actual FALSE TRUE Total\n##           FALSE  1173   96  1269\n##            TRUE    78  729   807\n##           Total  1251  825  2076\n```\n:::\n\n\n\n\nBased on these numbers, we have these accuracy rates:\n\n- Overall accuracy ($\\frac{a + d}{a + b + c + d}$): **91.6%**\n- Specificity, or true negative rate ($\\frac{a}{a + b}$): **92.4%**\n- Sensitivity, or true positive rate ($\\frac{c}{c + d}$): **90.3%**\n\nWow, this is a fantastic model. Use oxygen!\n\nThe model successfully predicts the outcomes for 91.6% of climbers. Because the consequences of failure are so high (injury and death), we should prioritize specificity here. We accurately predicted 92.4% of failed expeditions, which might not be great. \n\nWe can boost that specificity if we increase the probability cutoff and make it harder to predict success. In the book they settle on 0.65 (so a predicted probability of 65% is necessary to be considered a success). This lowers the sensitivity to 80ish%, lowers the overall accuracy to 90ish%, but boosts the specificity to 95ish%.\n\nAnd that's it! Complete analysis of a multilevel logistic regression model!\n\n\n# 18.2: Hierarchical Poisson and negative binomial\n\n## The general setup\n\nIn this example, we want to model the number of reviews an AirBnB listing gets (since review count is probably a good proxy for guests). The data we have comes from Chicago and includes listings in 43 different neighborhoods:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnrow(airbnb)\n## [1] 1561\n\nairbnb |> \n  distinct(neighborhood) |> \n  nrow()\n## [1] 43\n```\n:::\n\n\nWe have listings $y_i$ nested in neighborhoods $j$, so we have a standard multilevel structure:\n\n\n::: {.cell layout-align=\"center\" engine.opts='{\"dvisvgm.opts\":\"--font-format=woff\"}'}\n::: {.cell-output-display}\n![Multilevel structure of AirBnB listings within neighborhoods](18-chapter_files/figure-html/partial-pooling-airbnb-1.svg){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## Model building\n\nWe want to model the count of reviews on a listing, which is a count, and because it's nested in neighborhoods it has subscripts:\n\n$$\n\\text{Number of reviews}_{i_j}\n$$\n\nIn the book they use two variables to explain the count of reviews, but one is categorical (room type, with three levels: private unit, private room, and shared room) and thus gets two parameters:\n\n- $X_{i_{j}1}$ or $\\text{Rating}_{i_j}$: Visitor rating of listing $i$ in neighborhood $j$\n- $X_{i_{j}2}$ or $\\text{Private room}_{i_j}$: Binary indicator for if listing $i$ in neighborhood $j$ is a private room\n- $X_{i_{j}3}$ or $\\text{Shared room}_{i_j}$: Binary indicator for if listing $i$ in neighborhood $j$ is a shared room\n\nSome quick exploratory data analysis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- airbnb |> \n  ggplot(aes(x = reviews)) +\n  geom_histogram(binwidth = 10, color = \"white\", boundary = 0, fill = clrs[3]) +\n  labs(x = \"Number of reviews\", y = \"Count\")\n\np2 <- airbnb |> \n  ggplot(aes(x = rating, y = reviews)) +\n  geom_jitter(color = clrs[1], alpha = 0.4, size = 1) +\n  labs(x = \"Rating\", y = \"Number of reviews\")\n\np3 <- airbnb |> \n  ggplot(aes(x = room_type, y = reviews, \n             color = room_type, fill = room_type)) +\n  geom_half_point(side = \"l\", size = 1, alpha = 0.4) +\n  geom_half_violin(side = \"r\") +\n  scale_color_manual(values = c(clrs[2], clrs[6], clrs[5]), guide = \"none\") +\n  scale_fill_manual(values = c(clrs[2], clrs[6], clrs[5]), guide = \"none\") +\n  scale_x_discrete(labels = label_wrap(10)) +\n  labs(x = \"Room type\", y = \"Number of reviews\")\n\np1 | p2 | p3\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-41-1.png){width=864}\n:::\n:::\n\n\nThe count of reviews looks Poisson-y, since it's a right-skewed count. Poisson distributions have the magical property that the mean and variance of $Y$ are the same. We should check if that's the case here:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairbnb |> \n  summarize(mean = mean(reviews),\n            variance = sd(reviews))\n##       mean variance\n## 1 27.19283 34.94139\n```\n:::\n\n\nThey're not! There's more variance in the count of reviews than we should see in a Poisson distribution.\n\nAs another check, we can compare a super basic intercept-only model of the count of reviews with both a Poisson and a negative binomial model. The Poisson results from `pp_check()` aren't great and show overdispersion; the negative binomial model fits well (since there's a hyperparameter for dispersion). \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_is_poisson <- brm(\n  bf(reviews ~ 1),\n  data = airbnb,\n  family = poisson(),\n  chains = 4, cores = 4, iter = 4000, threads = threading(2), seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0,\n  file = \"18-manual_cache/is-poisson\"\n)\n\nmodel_is_negbinom <- brm(\n  bf(reviews ~ 1),\n  data = airbnb,\n  family = negbinomial(),\n  chains = 4, cores = 4, iter = 4000, threads = threading(2), seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0,\n  file = \"18-manual_cache/is-negbinom\"\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- pp_check(model_is_poisson) +\n  labs(title = \"Poisson model\") +\n  guides(color = \"none\")\n\np2 <- pp_check(model_is_negbinom) +\n  labs(title = \"Negative binomial model\")\n\np1 | p2\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n\nSo we'll use a negative binomial model for this data. Like the logistic regression model, we'll just define it all at once here instead of building it up slowly. In the book they base their priors on rstanarm's magical autoscaled hyperparameters. I'll modify them just a tiny bit:\n\n- $\\beta_{0_c}$ or baseline number of reviews: they used $\\mathcal{N}(3, 2.5)$, which implies a baseline average of $e^3$, or 20ish reviews. That seems fine.\n- $\\beta_1$ or the effect of ratings: they used $\\mathcal{N}(0, 7.37)$, which is pretty vague. This is the slope of the line on the log scale—a one unit increase in ratings is associated with a β increase in the logged count of reviews, or a $e^\\beta$ percent increase in the count of reviews. We'll just use $\\mathcal{N}(0, 7)$ since it feels less arbitrary than the automatic 7.37.\n- $\\beta_2$ (private room) and $\\beta_3$ (shared room) or the effect of room type: they used $\\mathcal{N}(0, 5.04)$ and $\\mathcal{N}(0, 14.19)$. This implies that the two room types influence the logged count of reviews in different ways. We'll just round these to $\\mathcal{N}(0, 5)$ and $\\mathcal{N}(0, 15)$\n- $r$ and $\\sigma_0$: these are standard deviations and have to be positive. $\\operatorname{Exponential}(1)$ seems fine.\n\nWith that, there's the official formal model:\n\n::: {.column-screen-inset}\n\n$$\n\\begin{aligned}\n\\text{Reviews}_{i_j} \\sim&\\ \\operatorname{NegBin}(\\mu_{i_j}, r) & \\text{Reviews for listing}_i \\text{ in neighborhood}_j \\\\\n\\log (\\mu_{i_j}) =&\\ \\beta_{0_j} + \\beta_1\\, \\text{Rating}_{i_j} + & \\text{Model for } \\mu \\\\\n&\\ \\beta_2\\, \\text{Private room}_{i_j} + \\beta_3\\, \\text{Shared room}_{i_j} \\\\\n\\beta_{0_j} \\sim&\\ \\mathcal{N}(\\beta_0, \\sigma_0) & \\text{Neighborhood-specific review counts} \\\\\n\\\\\n\\beta_{0_c} \\sim&\\ \\mathcal{N}(3, 2.5) & \\text{Prior for global average count} \\\\\n\\beta_1 \\sim&\\ \\mathcal{N}(0, 7) & \\text{Prior for global rating effect} \\\\\n\\beta_2 \\sim&\\ \\mathcal{N}(0, 5) & \\text{Prior for global private room effect} \\\\\n\\beta_3 \\sim&\\ \\mathcal{N}(0, 15) & \\text{Prior for global shared room effect} \\\\\nr \\sim&\\ \\operatorname{Exponential}(1) & \\text{Prior for within-listing dispersion} \\\\\n\\sigma_0 \\sim&\\ \\operatorname{Exponential}(1) & \\text{Prior for between-neighborhood variability}\n\\end{aligned}\n$$\n\n:::\n\n\\ \n\nOr with offset-based notation:\n\n::: {.column-screen-inset}\n\n$$\n\\begin{aligned}\n\\text{Reviews}_{i_j} \\sim&\\ \\operatorname{NegBin}(\\mu_{i_j}, r) & \\text{Reviews for listing}_i \\text{ in neighborhood}_j \\\\\n\\log (\\mu_{i_j}) =&\\ (\\beta_0 + b_{0_j}) + \\beta_1\\, \\text{Rating}_{i_j} + & \\text{Model for } \\mu \\\\\n&\\ \\beta_2\\, \\text{Private room}_{i_j} + \\beta_3\\, \\text{Shared room}_{i_j} \\\\\nb_{0_j} \\sim&\\ \\mathcal{N}(0, \\sigma_0) & \\text{Neighborhood-specific offsets from global average count} \\\\\n\\\\\n\\beta_{0_c} \\sim&\\ \\mathcal{N}(3, 2.5) & \\text{Prior for global average count} \\\\\n\\beta_1 \\sim&\\ \\mathcal{N}(0, 7) & \\text{Prior for global rating effect} \\\\\n\\beta_2 \\sim&\\ \\mathcal{N}(0, 5) & \\text{Prior for global private room effect} \\\\\n\\beta_3 \\sim&\\ \\mathcal{N}(0, 15) & \\text{Prior for global shared room effect} \\\\\nr \\sim&\\ \\operatorname{Exponential}(1) & \\text{Prior for within-listing dispersion} \\\\\n\\sigma_0 \\sim&\\ \\operatorname{Exponential}(1) & \\text{Prior for between-neighborhood variability}\n\\end{aligned}\n$$\n\n:::\n\n\n## Posterior simulation and analysis\n\nWe can run this model by including `(1 | expedition_id)` for the random team intercepts:\n\n::: {.panel-tabset}\n### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npriors <- c(prior(normal(3, 2.5), class = Intercept),\n            prior(normal(0, 2.5), class = b, coef = \"rating_c\"),\n            prior(normal(0, 2.5), class = b, coef = \"room_typePrivateroom\"),\n            prior(normal(0, 2.5), class = b, coef = \"room_typeSharedroom\"),\n            prior(exponential(1), class = shape),\n            prior(exponential(1), class = sd))\n\nmodel_reviews_brms <- brm(\n  bf(reviews ~ rating_c + room_type + (1 | neighborhood)), \n  data = airbnb,\n  family = negbinomial(),\n  prior = priors,\n  chains = 4, cores = 4, iter = 4000, threads = threading(2), seed = BAYES_SEED, \n  backend = \"cmdstanr\", refresh = 0,\n  file = \"18-manual_cache/reviews-brms\"\n)\n```\n:::\n\n\n### rstanarm\n\nWe'll keep the autoscaled priors here though?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_rstanarm <- stan_glmer(\n  reviews ~ rating_c + room_type + (1 | neighborhood), \n  data = airbnb, family = neg_binomial_2,\n  prior_intercept = normal(3, 2.5, autoscale = TRUE),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1),\n  chains = 4, cores = 4, iter = 5000*2, seed = 84735, refresh = 0)\n```\n:::\n\n\n:::\n\n\n### Global analysis\n\nFirst we'll look at what this model says about a typical listing, which involves the $\\beta_0$, $\\beta_1$, $\\beta_2$, and $\\beta_3$ terms:\n\n::: {.panel-tabset}\n\nLogged coefficients\n\n#### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_brms |> \n  tidy(effects = c(\"fixed\"), conf.level = 0.8) |> \n  select(-component)\n## # A tibble: 4 × 6\n##   effect term                 estimate std.error  conf.low conf.high\n##   <chr>  <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n## 1 fixed  (Intercept)            3.26      0.0538  3.19         3.32 \n## 2 fixed  rating_c               0.265     0.0847  0.155        0.372\n## 3 fixed  room_typePrivateroom   0.0683    0.0531  0.000556     0.136\n## 4 fixed  room_typeSharedroom   -0.469     0.152  -0.658       -0.274\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_brms |> \n  gather_draws(`^b_.*`, regex = TRUE) |>\n  ungroup() |> \n  mutate(.variable = fct_inorder(.variable)) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = clrs[1:4], guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\") +\n  labs(x = \"Logged value\", y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-46-1.png){width=768}\n:::\n:::\n\n\nUnlogged coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_brms %>%\n  model_parameters(centrality = \"mean\", dispersion = TRUE, component = \"conditional\",\n                   test = FALSE, verbose = FALSE, ci_method = \"hdi\", ci = 0.8,\n                   exponentiate = TRUE)\n## Parameter            |  Mean |   SD |         80% CI |  Rhat |      ESS\n## -----------------------------------------------------------------------\n## (Intercept)          | 25.92 | 0.05 | [24.21, 27.76] | 1.000 |  5461.00\n## rating_c             |  1.30 | 0.08 | [ 1.18,  1.46] | 1.000 | 14545.00\n## room_typePrivateroom |  1.07 | 0.05 | [ 1.00,  1.15] | 1.000 | 13535.00\n## room_typeSharedroom  |  0.63 | 0.15 | [ 0.52,  0.76] | 1.000 | 12843.00\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_brms |> \n  gather_draws(`^b_.*`, regex = TRUE) |>\n  ungroup() |> \n  mutate(.variable = fct_inorder(.variable),\n         .value = exp(.value)) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = clrs[1:4], guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\") +\n  labs(x = \"Unlogged value\", y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-48-1.png){width=768}\n:::\n:::\n\n\n\n\n#### rstanarm\n\nLogged coefficients\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_rstanarm |> \n  tidy(effects = c(\"fixed\"),\n       conf.int = TRUE, conf.level = 0.8)\n## # A tibble: 4 × 5\n##   term                  estimate std.error conf.low conf.high\n##   <chr>                    <dbl>     <dbl>    <dbl>     <dbl>\n## 1 (Intercept)             3.26      0.0502  3.19        3.32 \n## 2 rating_c                0.265     0.0836  0.156       0.372\n## 3 room_typePrivate room   0.0688    0.0525  0.00147     0.135\n## 4 room_typeShared room   -0.468     0.149  -0.658      -0.274\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_rstanarm |> \n  gather_draws(`(Intercept)`, rating_c, \n               `room_typePrivate room`, `room_typeShared room`) |>\n  ungroup() |> \n  mutate(.variable = fct_inorder(.variable)) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = clrs[1:4], guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\") +\n  labs(x = \"Logged value\", y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-51-1.png){width=768}\n:::\n:::\n\n\nUnlogged coefficients\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_rstanarm %>%\n  model_parameters(centrality = \"mean\", dispersion = TRUE, prior = FALSE, \n                   test = FALSE, verbose = FALSE, ci_method = \"hdi\", ci = 0.8,\n                   exponentiate = TRUE)\n## Parameter             |  Mean |   SD |         80% CI |  Rhat |      ESS\n## ------------------------------------------------------------------------\n## (Intercept)           | 25.91 | 0.05 | [24.22, 27.67] | 1.000 |  8368.00\n## rating_c              |  1.30 | 0.08 | [ 1.17,  1.46] | 1.000 | 22356.00\n## room_typePrivate room |  1.07 | 0.05 | [ 1.00,  1.15] | 1.000 | 22730.00\n## room_typeShared room  |  0.63 | 0.15 | [ 0.51,  0.75] | 1.000 | 21767.00\n## reciprocal_dispersion |  2.87 | 0.04 | [ 2.74,  3.00] | 1.000 | 20341.00\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_rstanarm |> \n  gather_draws(`(Intercept)`, rating_c, \n               `room_typePrivate room`, `room_typeShared room`) |>\n  ungroup() |> \n  mutate(.value = exp(.value),\n         .variable = fct_inorder(.variable)) |> \n  ggplot(aes(x = .value, fill = .variable)) +\n  stat_halfeye(normalize = \"xy\") +\n  scale_fill_manual(values = clrs[1:4], guide = \"none\") +\n  facet_wrap(vars(.variable), scales = \"free_x\") +\n  labs(x = \"Unlogged value\", y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-53-1.png){width=768}\n:::\n:::\n\n:::\n\nInterpretation time! (with the brms results):\n\n#### Intercept ($\\beta_0$)\n\nThe posterior mean for $\\beta_0$ is 3.26, but that's logged and fairly meaningless. Exponentiating it like $e^{3.26}$ gives us a posterior mean count of 25.92 reviews for a private property listing with an average rating in an typical neighborhood, and there's an 80% chance the count is between 24.19 and 27.74.\n\n#### Rating ($\\beta_1$)\n\nThe posterior mean for $\\beta_1$ is 0.265, which means that the logged count of reviews should increase by that amount for every one-point increase in rating. Exponentiating that value ($e^{0.265}$) gives us a posterior unlogged value of 1.303 with an 80% credible interval of 1.17–1.45. That means that a 1-point increase in ratings is associated with a 30% increase in the count of reviews with an 80% credible interval of 17%–45%.\n\nWe can measure this with actual counts too instead of working with percent changes. First, we can look at the linear predictor (`posterior_linpred(transform = TRUE)` or `posterior_epred()`) to see how the predicted count of reviews changes across possible ratings:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Automatic way:\n# plot_cap(model_reviews_brms, condition = \"rating_c\", re_formula = NA)\n\ndatagrid(model = model_reviews_brms,\n         rating_c = seq(2.5, 5, by = 0.5) - unscaled_airbnb$rating_c$scaled_center) |> \n  add_epred_draws(model_reviews_brms, re_formula = NA) |> \n  mutate(rating = rating_c + unscaled_airbnb$rating_c$scaled_center) |> \n  ggplot(aes(x = rating, y = .epred)) +\n  stat_lineribbon(color = clrs[1], fill = clrs[1], alpha = 0.35) +\n  labs(x = \"Rating\", y = \"Posterior count of reviews\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-54-1.png){width=672}\n:::\n:::\n\n\nThe slope of this line changes depending on the rating—it gets steeper at higher ratings. We can get exact estimates of the slope of this posterior with `marginaleffects()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_reviews <- model_reviews_brms |>\n  marginaleffects(newdata = datagrid(rating_c = seq(2.5, 5, by = 0.5) -\n                                       unscaled_airbnb$rating_c$scaled_center),\n                  variables = \"rating_c\",\n                  type = \"response\", re_formula = NA) |>\n  posteriordraws() |>\n  mutate(rating = rating_c + unscaled_airbnb$rating_c$scaled_center)\n\nmfx_reviews |> \n  ggplot(aes(x = rating, y = draw)) +\n  stat_lineribbon(alpha = 0.25, fill = clrs[4], color = clrs[4]) +\n  labs(x = \"Rating\", \n       y = \"Marginal effect on count of reviews\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-55-1.png){width=672}\n:::\n:::\n\n\n\n\nThe y-axis here is the slope of the line, not the predicted count of reviews. For a listing currently rated a 3, a one-unit change to a 4 is associated with an increase of `r `round(mfx_reviews_list$x3$mean_slope, 2)` reviews; for a listing rated a 4, a one-unit change to a 5 is associated with a larger increase of 5.51 reviews.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_reviews |> \n  filter(rating %in% c(3, 4)) |> \n  group_by(rating) |> \n  summarize(mean_slope = mean(draw),\n            conf.low = mean(conf.low),\n            conf.high = mean(conf.high))\n## # A tibble: 2 × 4\n##   rating mean_slope conf.low conf.high\n##    <dbl>      <dbl>    <dbl>     <dbl>\n## 1      3       4.15     2.11      5.44\n## 2      4       5.51     2.33      8.22\n```\n:::\n\n\n#### Room type ($\\beta_2$ and $\\beta_3$)\n\nThe posterior means for room type show the average difference in $\\mu$ when the room type is a private room vs. an entire home and a shared room vs. an entire home:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_brms |> \n  tidy(effects = c(\"fixed\"), conf.level = 0.8) |> \n  mutate(across(c(estimate, conf.low, conf.high), list(exp = exp))) |> \n  filter(str_detect(term, \"room_type\")) |> \n  select(-effect, -component, -std.error) |> \n  gt() |> \n  tab_spanner(\n    label = \"Logged scale\",\n    columns = c(estimate, conf.low, conf.high)\n  ) |> \n  tab_spanner(\n    label = \"Exponentiated scale\",\n    columns = c(estimate_exp, conf.low_exp, conf.high_exp)\n  ) |> \n  fmt_number(\n    columns = -term,\n    n_sigfig = 3\n  ) |> \n  tab_source_note(\n    source_note = \"Estimates show posterior means and 80% credible intervals\"\n  )\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"ucfszpxtzb\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#ucfszpxtzb .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#ucfszpxtzb .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#ucfszpxtzb .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#ucfszpxtzb .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#ucfszpxtzb .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#ucfszpxtzb .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#ucfszpxtzb .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#ucfszpxtzb .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ucfszpxtzb .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#ucfszpxtzb .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#ucfszpxtzb .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#ucfszpxtzb .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#ucfszpxtzb .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ucfszpxtzb .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#ucfszpxtzb .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#ucfszpxtzb .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ucfszpxtzb .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#ucfszpxtzb .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ucfszpxtzb .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#ucfszpxtzb .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ucfszpxtzb .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#ucfszpxtzb .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#ucfszpxtzb .gt_left {\n  text-align: left;\n}\n\n#ucfszpxtzb .gt_center {\n  text-align: center;\n}\n\n#ucfszpxtzb .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#ucfszpxtzb .gt_font_normal {\n  font-weight: normal;\n}\n\n#ucfszpxtzb .gt_font_bold {\n  font-weight: bold;\n}\n\n#ucfszpxtzb .gt_font_italic {\n  font-style: italic;\n}\n\n#ucfszpxtzb .gt_super {\n  font-size: 65%;\n}\n\n#ucfszpxtzb .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#ucfszpxtzb .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#ucfszpxtzb .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#ucfszpxtzb .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#ucfszpxtzb .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#ucfszpxtzb .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#ucfszpxtzb .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"2\" colspan=\"1\" scope=\"col\">term</th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"3\" scope=\"colgroup\">\n        <span class=\"gt_column_spanner\">Logged scale</span>\n      </th>\n      <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"3\" scope=\"colgroup\">\n        <span class=\"gt_column_spanner\">Exponentiated scale</span>\n      </th>\n    </tr>\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">estimate</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">conf.low</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">conf.high</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">estimate_exp</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">conf.low_exp</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">conf.high_exp</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td class=\"gt_row gt_left\">room_typePrivateroom</td>\n<td class=\"gt_row gt_right\">0.0683</td>\n<td class=\"gt_row gt_right\">0.000556</td>\n<td class=\"gt_row gt_right\">0.136</td>\n<td class=\"gt_row gt_right\">1.07</td>\n<td class=\"gt_row gt_right\">1.00</td>\n<td class=\"gt_row gt_right\">1.15</td></tr>\n    <tr><td class=\"gt_row gt_left\">room_typeSharedroom</td>\n<td class=\"gt_row gt_right\">−0.469</td>\n<td class=\"gt_row gt_right\">−0.658</td>\n<td class=\"gt_row gt_right\">−0.274</td>\n<td class=\"gt_row gt_right\">0.626</td>\n<td class=\"gt_row gt_right\">0.518</td>\n<td class=\"gt_row gt_right\">0.760</td></tr>\n  </tbody>\n  <tfoot class=\"gt_sourcenotes\">\n    <tr>\n      <td class=\"gt_sourcenote\" colspan=\"7\">Estimates show posterior means and 80% credible intervals</td>\n    </tr>\n  </tfoot>\n  \n</table>\n</div>\n```\n:::\n:::\n\n\nWe'll skip right to the exponentiated scale since that makes more sense to me. When compared to an entire private home, a private room doesn't see too much of a difference in the count of reviews—there's a 7% increase in the count of reviews with an 80% credible interval of 0.1%–14.6%. That range doesn't include zero, but only because we're looking at an 80% credible interval. Expand that to 89% or 89% or whatever and there's a chance that the difference is 0. \n\nShared rooms, on the other hand, have substantially fewer reviews than private home. For these, there's a -37% decrease in the count of reviews with an 80% credible interval of -24%–-48%. That's definitely not zero and it feels like a substantial real difference. For whatever reason, people don't seem to leave as many reviews for shared rooms.\n\nHere's what these differences look like as counts instead of percent changes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatagrid(model = model_reviews_brms,\n         room_type = unique(airbnb$room_type)) |> \n  add_epred_draws(model_reviews_brms, re_formula = NA) |> \n  ggplot(aes(x = room_type, y = .epred, fill = room_type, color = room_type)) +\n  stat_gradientinterval(width = 0.25) +\n  scale_fill_manual(values = c(clrs[2], clrs[6], clrs[5]), guide = \"none\") +\n  scale_color_manual(values = colorspace::darken(c(clrs[2], clrs[6], clrs[5]), 0.5), guide = \"none\") +\n  labs(x = \"Room type\", y = \"Posterior count of reviews\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-59-1.png){width=672}\n:::\n:::\n\n\nAs before, we can find the exact difference in these posteriors with `tidybayes::compare_levels()`. The difference between a private room and an entire house is roughly 2 reviews, while the difference between a shared room and an entire house is a more sizable ≈10 reviews.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroom_type_diffs <- datagrid(\n  model = model_reviews_brms,\n  room_type = unique(airbnb$room_type)\n) |> \n  add_epred_draws(model_reviews_brms, re_formula = NA) |> \n  compare_levels(variable = .epred, by = room_type)\n\nroom_type_diffs |> \n  group_by(room_type) |> \n  mean_qi(.epred)\n## # A tibble: 3 × 7\n##   room_type                      .epred  .lower .upper .width .point .interval\n##   <chr>                           <dbl>   <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 Private room - Entire home/apt   1.84  -0.959   4.71   0.95 mean   qi       \n## 2 Shared room - Entire home/apt   -9.55 -14.3    -3.70   0.95 mean   qi       \n## 3 Shared room - Private room     -11.4  -16.3    -5.55   0.95 mean   qi\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nroom_type_diffs |> \n  filter(room_type != \"Shared room - Private room\") |> \n  ggplot(aes(x = .epred, fill = room_type)) +\n  stat_halfeye() +\n  scale_fill_manual(values = c(clrs[6], clrs[5])) +\n  labs(x = \"Difference in predicted review counts\",\n       y = \"Density\", fill = \"Contrast in room type\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-61-1.png){width=672}\n:::\n:::\n\n\nWe can also use `marginaleffects::comparisons()` to calculate actual average marginal effects (or group contrasts).\n\n\n::: {.cell hash='18-chapter_cache/html/mfx-comparisons-reviews_c4d830dc8d4d32c9c87217da9f2ac5ef'}\n\n```{.r .cell-code}\nmfx_cmp_reviews <- model_reviews_brms |> \n  comparisons(variables = \"room_type\", re_formula = NA)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_cmp_reviews |> \n  posteriordraws() |> \n  group_by(drawid, contrast) |> \n  summarize(draw = mean(draw)) |> \n  ggplot(aes(x = draw, fill = contrast)) +\n  stat_halfeye() +\n  scale_fill_manual(values = c(clrs[6], clrs[5])) +\n  labs(x = \"Difference in predicted review counts\",\n       y = \"Density\", fill = \"Contrast in room type\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-62-1.png){width=672}\n:::\n:::\n\n\nAnd for extra fun we can [integrate out the random effects](https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html#brmsmargins) instead of ignoring them like we've been doing so far. This is super neat! Instead of choosing an arbitrary existing neighborhood for our predictions, this essentially accounts for general neighborhood-level effects but for global parameters.\n\n\n::: {.cell hash='18-chapter_cache/html/mfx-reviews-integrated-out_e62865cc0fec08d45eddd96573f6091d'}\n\n```{.r .cell-code}\nmfx_reviews_integrated_out <- comparisons(\n  model_reviews_brms,\n  # 100 fake neighborhoods\n  newdata = datagrid(neighborhood = -1:-100),\n  allow_new_levels = TRUE,\n  sample_new_levels = \"gaussian\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_reviews_integrated_out |> summary()\n##        Term                       Contrast Effect   2.5 % 97.5 %\n## 1  rating_c                    (x + 1) - x  6.997   2.381 11.909\n## 2 room_type Private room - Entire home/apt  1.848  -1.334  5.097\n## 3 room_type  Shared room - Entire home/apt -9.907 -14.847 -3.660\n## \n## Model type:  brmsfit \n## Prediction type:  response\n```\n:::\n\n\nA one-unit change in rating is associated with a \"significant\" and substantial ≈7 additional reviews; a typical private room sees 2ish more reviews than an entire home, but that could also be 0 or even negative; a typical shared room sees 10ish *fewer* reviews than an entire home, and that difference is \"significant\" and substantial.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmfx_reviews_integrated_out |> \n  posteriordraws() |> \n  group_by(drawid, term, contrast) |> \n  summarize(draw = mean(draw)) |> \n  ggplot(aes(x = draw, fill = contrast)) +\n  stat_halfeye() +\n  facet_wrap(vars(term), scales = \"free_x\") +\n  scale_fill_manual(values = c(clrs[1], clrs[6], clrs[5])) +\n  labs(title = \"Average marginal effect of coefficients\",\n       subtitle = \"Random effects integrated out\",\n       x = \"Change in count of reviews\", y = \"Density\", \n       fill = \"Marginal effect or contrast\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-64-1.png){width=672}\n:::\n:::\n\n\n#### Rating and room type at the same time\n\nFor fun, here's the effect of rating across all three room types. All three room types trend upward in parallel (they just have different intercepts, not room-type-specific slopes), and there's not really a visible difference private rooms and entire homes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatagrid(model = model_reviews_brms,\n         rating_c = seq(2.5, 5, by = 0.5) - unscaled_airbnb$rating_c$scaled_center,\n         room_type = unique(airbnb$room_type)) |> \n  add_epred_draws(model_reviews_brms, re_formula = NA, ndraws = 100) |> \n  mutate(rating = rating_c + unscaled_airbnb$rating_c$scaled_center) |> \n  ggplot(aes(x = rating, y = .epred, color = room_type)) +\n  geom_line(aes(group = paste(room_type, .draw)), alpha = 0.35) +\n  scale_color_manual(values = c(clrs[2], clrs[6], clrs[5])) +\n  labs(x = \"Rating\", y = \"Posterior count of reviews\", \n       color = \"Room type\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-65-1.png){width=672}\n:::\n:::\n\n\n### Neighborhood-specific analysis\n\nNext we can look at the neighborhood-specific details, or the offsets from the baseline probability of success:\n\n$$\nB_0 + b_{0_j}\n$$\n\nUnlike the expedition teams from the logistic regression example, there's not a huge amount of variation between neighborhoods here. If we look at the top 5 and bottom 5, we can see that the widest differences is only a matter of 12 reviews (highest neighborhood − lowest neighborhood):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nneighborhood_baselines <- model_reviews_brms |> \n  epred_draws(tibble(neighborhood = unique(airbnb$neighborhood),\n                     rating_c = 0, room_type = \"Entire home/apt\")) |> \n  ungroup() |> \n  mutate(neighborhood = fct_reorder(factor(neighborhood), .epred, .fun = mean))\n\nneighborhood_baselines |> \n  group_by(neighborhood) |> \n  summarize(avg = mean(.epred)) |> \n  arrange(desc(avg)) |> \n  slice(1:5, 39:43)\n## # A tibble: 10 × 2\n##    neighborhood         avg\n##    <fct>              <dbl>\n##  1 Gage Park           32.5\n##  2 East Garfield Park  32.4\n##  3 West Lawn           32.0\n##  4 Burnside            31.0\n##  5 Edgewater           30.3\n##  6 North Park          23.6\n##  7 Irving Park         23.0\n##  8 South Chicago       22.9\n##  9 Lincoln Square      21.9\n## 10 Albany Park         20.6\n```\n:::\n\n\nWe can see this narrower range when looking at all 43 teams simultaneously:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_baseline <- model_reviews_brms |> \n  tidy(effects = c(\"fixed\"), conf.level = 0.8) |> \n  filter(term == \"(Intercept)\") |> \n  mutate(across(c(estimate, conf.low, conf.high), exp))\n\nneighborhood_baselines |> \n  ggplot(aes(x = .epred, y = neighborhood)) +\n  annotate(geom = \"rect\", ymin = -Inf, ymax = Inf,\n           xmin = global_baseline$conf.low, xmax = global_baseline$conf.high,\n           fill = clrs[2], alpha = 0.4) +\n  geom_vline(xintercept = global_baseline$estimate, color = clrs[2]) +\n  stat_pointinterval(color = clrs[3], size = 0.1,\n                     point_interval = \"mean_qi\") +\n  labs(x = \"Baseline count of reviews\", y = \"Neighborhood\",\n       title = \"Baseline count of reviews for listings in neighborhood\",\n       subtitle = \"Global baseline and 80% credible interval shown in yellow\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-67-1.png){width=672}\n:::\n:::\n\n\n\nWe can also look at how these neighborhood-specific offsets influence the relationship of ratings and review counts. Here are three arbitrarily chosen neighborhoods—the slope is the same in all three panels, but the baseline intercept gets shifted up and down,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairbnb_small <- airbnb |> \n  filter(neighborhood %in% c(\"Albany Park\", \"East Garfield Park\", \"The Loop\"))\n\nairbnb_small |> \n  add_epred_draws(model_reviews_brms, ndraws = 250) |> \n  ggplot(aes(x = rating, y = reviews)) +\n  geom_line(aes(y = .epred, group = paste(neighborhood, .draw), \n                color = neighborhood),\n            alpha = 0.2, size = 0.3) +\n  geom_point(data = airbnb_small, aes(color = neighborhood)) +\n  scale_color_manual(values = c(clrs[1], clrs[2], clrs[5]), guide = \"none\") +\n  labs(x = \"Rating\", y = \"Reviews\") +\n  facet_wrap(vars(neighborhood))\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-68-1.png){width=672}\n:::\n:::\n\n\n### Between-neighborhood variability\n\nWith linear regression we have two forms of variability: \n\n- $\\sigma_y$ for the variability within units nested in groups (i.e. the scale term in $Y_{i_j} \\sim \\mathcal{N}(\\mu_{i_j}, \\sigma_{i_j})$)\n- $\\sigma_0$ for the variability between groups (i.e. the variation around the random offsets in $b_{0_j} \\sim \\mathcal{N}(0, \\sigma_0)$)\n\nWith logistic regression we didn't have a $\\sigma_y$ term for variability within expedition teams, since the Bernoulli model for $Y_{i_j}$ only has one hyperparameter $\\pi_{i_j}$\n\nWith negative binomial regression, though we have two hyperparameters, roughly equivalent to the location ($\\mu$, or mean) and scale ($r$, or spread) of the distribution. I don't think not sure if this $r$ term is technically comparable to $\\sigma_y$ in Gaussian regression, since it doesn't show up in `ran_pars` and is instead a **d**istributional **par**ameter\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_reviews_brms |> \n  tidy(parameters = c(\"shape\", \"^sd_\"))\n## # A tibble: 2 × 6\n##   component term                         estimate std.error conf.low conf.high\n##   <chr>     <chr>                           <dbl>     <dbl>    <dbl>     <dbl>\n## 1 cond      shape                           1.06     0.0355   0.987      1.13 \n## 2 cond      sd_neighborhood__(Intercept)    0.174    0.0724   0.0381     0.328\n```\n:::\n\n\n$\\sigma_0$ (or `sd__(Intercept)` for the `neighborhood` group) is 0.17, which is the amount of variance in the log of the global intercept, so the average baseline log count varies between neighborhoods with a standard deviation of 0.17 log units. We can see this in a plot of each neighborhood's log-scale baseline average. The global average is 3.26, marked in yellow, and there a little bit of variation around that average—a standard deviation of  0.17.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_baseline_log <- model_reviews_brms |> \n  tidy(effects = c(\"fixed\"), conf.level = 0.8) |> \n  filter(term == \"(Intercept)\")\n\nneighborhood_baselines_log <- model_reviews_brms |> \n  linpred_draws(tibble(neighborhood = unique(airbnb$neighborhood),\n                       rating_c = 0, room_type = \"Entire home/apt\")) |> \n  ungroup() |> \n  mutate(neighborhood = fct_reorder(factor(neighborhood), .linpred, .fun = mean))\n\nneighborhood_baselines_log |> \n  ggplot(aes(x = .linpred, y = neighborhood)) +\n  annotate(geom = \"rect\", ymin = -Inf, ymax = Inf,\n           xmin = global_baseline_log$conf.low, xmax = global_baseline_log$conf.high,\n           fill = clrs[2], alpha = 0.4) +\n  geom_vline(xintercept = global_baseline_log$estimate, color = clrs[2]) +\n  stat_pointinterval(color = clrs[6], size = 0.1,\n                     point_interval = \"mean_qi\") +\n  labs(x = \"Baseline average log count of laws\", y = \"Neighborhood\")\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-70-1.png){width=672}\n:::\n:::\n\n\nFor whatever reason, we can't get an ICC for the percent of variation explained by between-neighborhood differences.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::icc(model_reviews_brms)\n## [1] NA\n```\n:::\n\n\nWe *can* use `performance::variance_decomposition()` to get a comparable number, since it uses the posterior predictive distribution of the model to figure out the between-group variance. It looks like neighborhood difference only explain 8ish% of the variation? But the credible interval goes negative and I don't know what it would mean to have a negative ratio like that?\n\n\n::: {.cell hash='18-chapter_cache/html/model-reviews-var_7b4dd7ba6960466a6a1e3682ad36b390'}\n\n```{.r .cell-code}\nperformance::variance_decomposition(model_reviews_brms)\n## # Random Effect Variances and ICC\n## \n## Conditioned on: all random effects\n## \n## ## Variance Ratio (comparable to ICC)\n## Ratio: 0.08  CI 95%: [-0.18 0.31]\n## \n## ## Variances of Posterior Predicted Distribution\n## Conditioned on fixed effects: 714.85  CI 95%: [556.40 907.03]\n## Conditioned on rand. effects: 776.68  CI 95%: [644.48 946.32]\n## \n## ## Difference in Variances\n## Difference: 62.25  CI 95%: [-132.07 267.03]\n```\n:::\n\n\n\n## Posterior predictions\n\nAccording to the image above that shows the baseline average differences across neighborhoods, Albany Park has fewer reviews than average, East Garfield Park has more reviews than average, and The Loop has basically the average number of reviews.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredicted_reviews <- model_reviews_brms |> \n  predicted_draws(\n    expand_grid(rating_c = 5 - unscaled_airbnb$rating_c$scaled_center,\n                room_type = \"Entire home/apt\",\n                neighborhood = c(\"Albany Park\", \"East Garfield Park\", \"The Loop\"))\n  )\n\npredicted_reviews |> \n  ggplot(aes(x = .prediction, fill = neighborhood)) +\n  geom_histogram(binwidth = 2, color = \"white\", linewidth = 0.3) +\n  stat_pointinterval() +\n  scale_fill_manual(values = c(clrs[1], clrs[2], clrs[5]), guide = \"none\") +\n  coord_cartesian(xlim = c(0, 150)) +\n  labs(x = \"Predicted count of reviews\") +\n  facet_wrap(vars(neighborhood), ncol = 1) +\n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-72-1.png){fig-align='center' width=576}\n:::\n:::\n\n\nEast Garfield has a higher predicted count of reviews, but there's ultimately not a huge difference across these neighborhoods.\n\n\n## Model evaluation\n\n### How fair is the model?\n\nFine, but not super generalizable:\n\n> What was available was information about the AirBnB market in Chicago. Thus, we’d be hesitant to use our analysis for anything more than general conclusions about the broader market.\n\n### How wrong is the model?\n\n`pp_check()` looks great:\n\n::: {.panel-tabset}\n#### brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_reviews_brms, ndraws = 25)\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-73-1.png){width=672}\n:::\n:::\n\n\n#### rstanarm\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_reviews_rstanarm, n = 25)\n```\n\n::: {.cell-output-display}\n![](18-chapter_files/figure-html/unnamed-chunk-74-1.png){width=672}\n:::\n:::\n\n\n:::\n\n### How accurate are the model's posterior classifications?\n\nWe don't have competing models to compare, so LOO isn't super helpful, but it does show that there aren't any concerning Pareto k values, so that's good I guess.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nloo(model_reviews_brms)\n## \n## Computed from 8000 by 1561 log-likelihood matrix\n## \n##          Estimate    SE\n## elpd_loo  -6737.7  50.5\n## p_loo        29.4   2.7\n## looic     13475.4 101.1\n## ------\n## Monte Carlo SE of elpd_loo is 0.1.\n## \n## Pareto k diagnostic values:\n##                          Count Pct.    Min. n_eff\n## (-Inf, 0.5]   (good)     1559  99.9%   1584      \n##  (0.5, 0.7]   (ok)          2   0.1%   1103      \n##    (0.7, 1]   (bad)         0   0.0%   <NA>      \n##    (1, Inf)   (very bad)    0   0.0%   <NA>      \n## \n## All Pareto k estimates are ok (k < 0.7).\n## See help('pareto-k-diagnostic') for details.\n```\n:::\n\n\nWe also can calculate the mean absolute prediction error (MAE) and scaled MAE. This shows that the observed number of reviews for a listing is around ≈18ish reviews away from its posterior mean prediction, or ≈1 standard deviation:\n\n\n::: {.cell hash='18-chapter_cache/html/unnamed-chunk-76_864607367515b18da842c03e61c1e830'}\n\n```{.r .cell-code}\nreviews_preds_brms <- model_reviews_brms |> \n  add_predicted_draws(newdata = airbnb)\n\nreviews_preds_brms |> \n  ungroup() |> \n  mutate(error = reviews - .prediction) |> \n  summarize(mae = median(abs(error)),\n            mae_scaled = median(abs(error / mad(.prediction))))\n## # A tibble: 1 × 2\n##     mae mae_scaled\n##   <dbl>      <dbl>\n## 1    18      0.934\n```\n:::\n\n\nAnd that's it! Complete analysis of a multilevel Poisson/negative binomial regression model!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}