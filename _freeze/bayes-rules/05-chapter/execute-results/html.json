{
  "hash": "463d08c3f81e4e1b75ce4104c42e2f51",
  "result": {
    "markdown": "---\ntitle: \"Reading notes\"\nsubtitle: \"Conjugate families\"\ndate: \"September 6, 2022\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nset.seed(1234)\nBAYES_SEED <- 1234\n```\n:::\n\n\nConjugate families are neat because they let us calculate exact posteriors without difficult integration, like the beta binomial trick:\n\n$$\n\\pi \\mid (Y = y) \\sim \\operatorname{Beta}(\\alpha + y, \\quad \\beta + n - y)\n$$\n\n# 5.2 Gamma-Poisson conjugate family\n\nUseful for modeling rates and counts, like fraudulent phone calls per day. \n\n- Rate of calls per day = $\\lambda$. Any positive value.\n- Number of calls per day = $Y_i$. Any non-negative integer.\n\n## Poisson distributions\n\n*See [this from program evaluation](https://evalf22.classes.andrewheiss.com/example/random-numbers.html#poisson-distribution) too, where I give up and say*\n\n> *I have absolutely zero mathematical intuition for how [$\\lambda$] works.* The two shape parameters for a Beta distribution at least fit in a fraction and you can wrap your head around that, but the lambda in a Poisson distribution is just a mystery to me.\n\nIn general, as the rate of events $\\lambda$ increases…\n\n- the typical number of events increases,\n- the variability increases, and\n- the skew decreases\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexpand_grid(y = 0:12, lambda = c(1, 2, 5)) %>% \n  mutate(density = dpois(y, lambda)) %>% \n  ggplot(aes(x = y, y = density)) +\n  geom_col() + \n  facet_wrap(vars(lambda), \n             labeller = as_labeller(function(x) glue::glue(\"Poisson(λ = {x})\")))\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## Gamma distributions\n\nGamma models are positive and right skewed, and conjugate to Poisson. They take two hyperparameters: $s$ (shape) and $r$ (rate). Exponential models are Gammas with $s = 1$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexpand_grid(y = seq(0, 7, length.out = 1001), s = c(1, 2, 4), r = c(1, 2)) %>% \n  mutate(density = dgamma(y, shape = s, rate = r)) %>% \n  mutate(panel_name = glue::glue(\"Gamma(s = {s}, r = {r})\"),\n         panel_name = fct_inorder(panel_name)) %>% \n  ggplot(aes(x = y, y = density)) +\n  geom_area() + \n  facet_wrap(vars(panel_name), dir = \"v\", nrow = 2)\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nTuning the gamma prior: We think the rate of calls is 5 a day, with a range of 2–7ish. Through trial and error, it looks like $\\lambda \\sim \\operatorname{Gamma}(10, 2)$ fits that well:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_function(fun = ~dgamma(., shape = 10, rate = 2)) +\n  xlim(c(0, 15)) +\n  labs(x = \"λ\")\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Gamma-Poisson conjugacy\n\nGamma and Poisson families work together like Beta and binomial!\n\nModel:\n\n$$\n\\begin{aligned}\nY_i \\mid \\lambda &\\stackrel{\\text{ind}}{\\sim} \\operatorname{Poisson}(\\lambda) \\\\\n\\lambda &\\sim \\operatorname{Gamma}(s, r)\n\\end{aligned}\n$$\n\nAnd the magical posterior based on the two distributions' conjugacy:\n\n$$\n\\lambda \\mid y \\sim \\operatorname{Gamma}(s + \\sum y_i,\\quad r + n)\n$$\n\nAnd summary statistics:\n\n$$\n\\begin{aligned}\nE(\\lambda) &= \\frac{s}{r} \\\\\n\\operatorname{Mode}(\\lambda) &= \\frac{s - 1}{r} \\\\\n\\operatorname{Var}(\\lambda) &= \\frac{s}{r^2} \\\\\n\\operatorname{SD}(\\lambda) &= \\sqrt{\\frac{s}{r^2}}\n\\end{aligned}\n$$\n\nTime to try it!\n\nWe'll assume that the daily rate of calls $\\lambda$ is distributed with $\\operatorname{Gamma}(10, 2)$. Over 4 days, we receive 6, 2, 2, and 1 calls. That's an $n$ of 4 and a $\\sum y_i$ of (6 + 2 + 2 + 1), or 11, and an average of $\\frac{11}{4}$, or 2.75.\n\nThe posterior model is then the $\\operatorname{Gamma}(10, 2)$ prior mixed with the likelihood in fancy conjugate-y ways:\n\n$$\n\\begin{aligned}\n\\lambda \\mid y &\\sim \\operatorname{Gamma}(s + \\sum y_i,\\quad r + n) \\\\\n\\lambda \\mid (6, 2, 2, 1) &\\sim \\operatorname{Gamma}(10 + 11,\\quad 2 + 4) \\\\\n&\\sim \\operatorname{Gamma}(21, 6)\n\\end{aligned}\n$$\n\nThis new data changes our understanding of the rate of calls per day:\n\n$$\n\\begin{aligned}\nE(\\lambda) &= \\frac{10}{2} = 5 \\text{ calls a day, from prior} \\\\\nE[\\lambda \\mid (6, 2, 2, 1)] &= \\frac{21}{6} = 3.5 \\text{ calls a day, from posterior}\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\nSD(\\lambda) &= \\sqrt{\\frac{10}{2^2}} = 1.581 \\\\\nSD[\\lambda \\mid (6, 2, 2, 1)] &= \\sqrt{\\frac{21}{6^2}} = 0.764\n\\end{aligned}\n$$\n\nAnd here's what that looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  stat_function(fun = ~dgamma(., shape = 10, rate = 2), \n                geom = \"area\", aes(fill = \"Gamma(10, 2) prior\"), alpha = 0.75) +\n  stat_function(fun = ~dgamma(., shape = (10 + 11), rate = (2 + 4)),\n                geom = \"area\", aes(fill = \"Gamma(21, 6) posterior\"), alpha = 0.75) +\n  xlim(c(0, 15)) +\n  scale_fill_manual(values = clrs[5:6])\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nAnd confirming with the `summarize_gamma_poisson()` helper function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_gamma_poisson(shape = 10, rate = 2, sum_y = 11, n = 4)\n##       model shape rate mean     mode       var        sd\n## 1     prior    10    2  5.0 4.500000 2.5000000 1.5811388\n## 2 posterior    21    6  3.5 3.333333 0.5833333 0.7637626\n```\n:::\n\n\nAnd confirming with brms, just because this conjugate prior stuff feels like dark magic:\n\n\n::: {.cell hash='05-chapter_cache/html/model-poisson-brms_4324933133e4a0131468f7f262a712c7'}\n\n```{.r .cell-code}\nmodel_rate <- brm(\n  bf(fraud_calls ~ 0 + Intercept),\n  data = list(fraud_calls = c(6, 2, 2, 1)),\n  family = poisson(link = \"identity\"),\n  prior = prior(gamma(10, 2), class = b, lb = 0),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED,\n  backend = \"rstan\", cores = 4\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_rate %>% \n  spread_draws(b_Intercept) %>%\n  summarize(across(b_Intercept, lst(mean, sd, median, hdci = ~median_hdci(., width = 0.89)))) %>% \n  unnest(b_Intercept_hdci)\n## # A tibble: 1 × 9\n##   b_Intercept_mean b_Intercept…¹ b_Int…²     y  ymin  ymax .width .point .inte…³\n##              <dbl>         <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>  <chr>  \n## 1             3.50         0.756    3.44  3.44  2.09  5.00   0.95 median hdci   \n## # … with abbreviated variable names ¹​b_Intercept_sd, ²​b_Intercept_median,\n## #   ³​.interval\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_rate %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value)) +\n  geom_density(aes(fill = \"Posterior\"), color = NA, alpha = 0.75) +\n  stat_function(geom = \"area\", fun = ~dgamma(., 10, 2), aes(fill = \"Gamma(10, 2) prior\"), alpha = 0.75) +\n  scale_fill_manual(values = clrs[5:6]) +\n  xlim(c(0, 15))\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nAHHH it works!\n\n\n# 5.3: Normal-Normal conjugate family\n\nGeneral story here: we're interested in $\\mu$m or the average volume of the hippocampus. Wikipedia says that one half is between 3–3.5 cm^3^, so the total volume is between 6–7 cm^3^.\n\n## Normal distributions\n\nNormal distribution defined with $\\mu$ and $\\sigma$ (I've got this intuition, but I'll plot it anyway):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexpand_grid(y = seq(-2, 10, length.out = 1001), \n            params = list(list(mu = 2, sigma = 0.5), \n                          list(mu = 2, sigma = 1),\n                          list(mu = 4, sigma = 2))) %>%\n  mutate(density = map2_dbl(y, params, ~dnorm(.x, .y$mu, .y$sigma))) %>% \n  mutate(panel_name = map_chr(params, ~glue::glue(\"N({.x$mu}, {.x$sigma})\"))) %>% \n  ggplot(aes(x = y, y = density)) +\n  geom_area() +\n  facet_wrap(vars(panel_name))\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## Normal prior\n\nSo, if we think the volume of the hippocampus is 6.5 cm^3^, ± 0.8, we can do 6.5 ± (2 * 0.4), or:\n\n$$\n\\mu \\sim \\mathcal{N}(6.5, 0.4^2)\n$$\n\nHere's what that looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_function(fun = ~dnorm(., mean = 6.5, sd = 0.4)) +\n  xlim(c(5, 8))\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## Normal-normal conjugacy\n\nNormal-normal situations are conjugates, which means we can find exact posteriors without complex integration. This is a little more complicated than the nice easy Beta-binomial or even the Gamma-Poisson conjugates, though. \n\nHere's the model:\n\n$$\n\\begin{aligned}\nY_i \\mid \\mu &\\stackrel{\\text{ind}}{\\sim} \\mathcal{N}({\\mu, \\sigma^2}) \\\\\n\\mu &\\sim \\mathcal{N}(\\theta, \\tau^2)\n\\end{aligned}\n$$\n\nAnd the magical posterior:\n\n$$\n\\mu \\mid \\vec{y} \\; \\sim \\;  \\mathcal{N}\\bigg(\\theta\\frac{\\sigma^2}{n\\tau^2+\\sigma^2} + \\bar{y}\\frac{n\\tau^2}{n\\tau^2+\\sigma^2}, \\; \\frac{\\tau^2\\sigma^2}{n\\tau^2+\\sigma^2}\\bigg)\n$$\n\nWow that's a ***mess***. We need these things:\n\n- Prior mean ($\\theta$)\n- Prior sd ($\\tau$)\n- Observed mean ($\\bar{y}$)\n- Observed sd ($\\sigma$)\n- Number of observations ($n$)\n\nLet's try it with real data, with the `football` data from **bayesrules**. What's the average hippocampus volume for football players with concussions? This is our $\\bar{y}$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconcussion_subjects <- bayesrules::football %>% \n  filter(group == \"fb_concuss\")\n\nconcussion_subjects %>% \n  summarize(across(volume, lst(mean, sd)))\n##   volume_mean volume_sd\n## 1      5.7346 0.5933976\n```\n:::\n\n\nIn the book, they look at the distribution and figure that a standard deviation of 0.5 seems reasonable (and it's basically that in the data too)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconcussion_subjects %>% \n  ggplot(aes(x = volume)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nWith that, we have all these pieces:\n\n- Prior mean ($\\theta$): 6.5\n- Prior sd ($\\tau$): 0.4\n- Observed mean ($\\bar{y}$): 5.735\n- Observed (assumed) sd ($\\sigma$): 0.5\n- Number of observations ($n$): 25\n\nMath time!\n\n$$\n\\begin{aligned}\n\\mu \\mid \\vec{y} \\; &\\sim \\; \\mathcal{N}\\bigg(\\theta\\frac{\\sigma^2}{n\\tau^2+\\sigma^2} + \\bar{y}\\frac{n\\tau^2}{n\\tau^2+\\sigma^2}, \\; \\frac{\\tau^2\\sigma^2}{n\\tau^2+\\sigma^2}\\bigg) \\\\\n&\\sim \\; \\mathcal{N}\\bigg(6.5\\frac{0.5^2}{25 \\times 0.4^2+0.5^2} + 5.735\\frac{25 \\times 0.4^2}{25 \\times 0.4^2+0.5^2}, \\; \\frac{0.4^2 \\times 0.5^2}{25 \\times 0.4^2+0.5^2}\\bigg) \\\\\n&\\sim \\; \\mathcal{N}\\bigg(5.78, 0.009^2\\bigg)\n\\end{aligned}\n$$\n\nOr, with the `summarize_normal_normal()` helper function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_normal_normal(mean = 6.5, sd = 0.4, sigma = 0.5,\n                        y_bar = 5.735, n = 25)\n##       model mean mode         var         sd\n## 1     prior 6.50 6.50 0.160000000 0.40000000\n## 2 posterior 5.78 5.78 0.009411765 0.09701425\n```\n:::\n\n\nAnd here's what that looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  stat_function(fun = ~dnorm(., mean = 6.5, sd = 0.4), \n                geom = \"area\", aes(fill = \"N(6.5, 0.4) prior\"), alpha = 0.75,\n                n = 1001) +\n  stat_function(fun = ~dnorm(., mean = 5.78, sd = 0.097),\n                geom = \"area\", aes(fill = \"N(5.78, 0.097) posterior\"), alpha = 0.75,\n                n = 1001) +\n  xlim(c(5, 8)) +\n  scale_fill_manual(values = clrs[6:5], guide = guide_legend(reverse = TRUE))\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nAnd confirming with brms:\n\n\n::: {.cell hash='05-chapter_cache/html/model-normal-brms_6dcc53cc98fd34f6faf42ad2b0004242'}\n\n```{.r .cell-code}\nmodel_volume <- brm(\n  bf(volume ~ 0 + Intercept),\n  data = concussion_subjects,\n  family = gaussian(),\n  prior = prior(normal(6.5, 0.4), class = b),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED,\n  backend = \"rstan\", cores = 4\n)\n## Compiling Stan program...\n## Trying to compile a simple C file\n## Start sampling\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_volume %>% \n  spread_draws(b_Intercept) %>%\n  summarize(across(b_Intercept, lst(mean, sd, median, hdci = ~median_hdci(., width = 0.89)))) %>% \n  unnest(b_Intercept_hdci)\n## # A tibble: 1 × 9\n##   b_Intercept_mean b_Intercept…¹ b_Int…²     y  ymin  ymax .width .point .inte…³\n##              <dbl>         <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>  <chr>  \n## 1             5.80         0.124    5.80  5.80  5.57  6.05   0.95 median hdci   \n## # … with abbreviated variable names ¹​b_Intercept_sd, ²​b_Intercept_median,\n## #   ³​.interval\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_volume %>% \n  gather_draws(b_Intercept) %>% \n  ggplot(aes(x = .value)) +\n  geom_density(aes(fill = \"Posterior\"), color = NA, alpha = 0.75) +\n  stat_function(geom = \"area\", fun = ~dnorm(., 6.5, 0.4), aes(fill = \"N(6.5, 0.4) prior\"), alpha = 0.75) +\n  scale_fill_manual(values = clrs[5:6]) +\n  xlim(c(5, 8))\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nSO COOL.\n\n## Overriding the observed sd with an assumed sd\n\nBUT that's not actually correct because it's using the actual observed standard deviation (0.5934) instead of the assumed standard deviation (0.5) from the conjugate calculation earlier. I can't figure out how to override brms's sd, but we can use raw Stan:\n\n**normal_normal.stan**:\n\n\n::: {.cell output.var='normal_normal' hash='05-chapter_cache/html/normal-normal_e537135ce8f831a575780b4c730e831f'}\n\n```{.stan .cell-code}\ndata {\n  int<lower = 1> N;  // Number of observations\n  vector[N] volume;  // Observed hippocampus volumes\n  real volume_sd;    // Assumed sd of hippocampus volumes\n}\n\nparameters {\n  real mu;  // Posterior average hippocampus volume\n}\n\nmodel {\n  // Prior\n  mu ~ normal(6.5, 0.4);\n\n  // Likelihood\n  volume ~ normal(mu, volume_sd);\n}\n```\n:::\n\n::: {.cell hash='05-chapter_cache/html/model-normal-stan_83f864ce587e30ced1b69d817e65df7b'}\n\n```{.r .cell-code}\nmodel_volume_stan <- rstan::sampling(\n  normal_normal,\n  data = list(volume = concussion_subjects$volume, \n              volume_sd = 0.5,\n              N = nrow(concussion_subjects)),\n  iter = 5000, warmup = 1000, seed = BAYES_SEED, chains = 4\n)\n```\n:::\n\n\nThe results are basically identical to the math-based version!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_volume_stan %>% \n  spread_draws(mu) %>%\n  summarize(across(mu, lst(mean, sd, median, hdci = ~median_hdci(., width = 0.89)))) %>% \n  unnest(mu_hdci)\n## # A tibble: 1 × 9\n##   mu_mean  mu_sd mu_median     y  ymin  ymax .width .point .interval\n##     <dbl>  <dbl>     <dbl> <dbl> <dbl> <dbl>  <dbl> <chr>  <chr>    \n## 1    5.78 0.0978      5.78  5.78  5.59  5.98   0.95 median hdci\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_normal_normal(mean = 6.5, sd = 0.4, sigma = 0.5,\n                        y_bar = 5.735, n = 25)\n##       model mean mode         var         sd\n## 1     prior 6.50 6.50 0.160000000 0.40000000\n## 2 posterior 5.78 5.78 0.009411765 0.09701425\n```\n:::\n\n\nAnd the distribution is the same too:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_volume_stan %>% \n  gather_draws(mu) %>% \n  ggplot(aes(x = .value)) +\n  geom_density(aes(fill = \"Posterior\"), color = NA, alpha = 0.75) +\n  stat_function(geom = \"area\", fun = ~dnorm(., 6.5, 0.4), aes(fill = \"N(6.5, 0.4) prior\"), alpha = 0.75) +\n  scale_fill_manual(values = clrs[5:6]) +\n  xlim(c(5, 8))\n```\n\n::: {.cell-output-display}\n![](05-chapter_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}