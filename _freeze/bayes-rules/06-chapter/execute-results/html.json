{
  "hash": "251ee5668d24bc7efb2a79e246b4b166",
  "result": {
    "markdown": "---\ntitle: \"Reading notes\"\nsubtitle: \"Approximating the posterior\"\ndate: \"September 27, 2022\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(rstan)\nlibrary(cmdstanr)\nlibrary(posterior)\nlibrary(brms)\nlibrary(tidybayes)\n\n# Plot stuff\nclrs <- MetBrewer::met.brewer(\"Lakota\", 6)\ntheme_set(theme_bw())\n\n# Seed stuff\nset.seed(1234)\nBAYES_SEED <- 1234\n```\n:::\n\n\n\n# 6.1 Grid approximation\n\n## Beta-binomial example\n\n$$\n\\begin{aligned}\nY &\\sim \\operatorname{Binomial}(10, π) \\\\\n\\pi &= \\operatorname{Beta}(2, 2)\n\\end{aligned}\n$$\n\nWe can figure this posterior out mathematically using conjugate priors. If we know that Y = 9, then\n\n$$\n\\pi \\mid (Y = 9) \\sim \\operatorname{Beta}(2 + 9, 10 - 2 + 2) \\rightarrow \\operatorname{Beta}(11, 3)\n$$\n\nBut we can also do this with grid approximation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a grid of 6 pi values\ngrid_data <- tibble(pi_grid = seq(0, 1, length.out = 6)) |> \n  # Evaluate the prior and likelihood at each pi\n  mutate(prior = dbeta(pi_grid, 2, 2),\n         likelihood = dbinom(9, 10, pi_grid)) |> \n  # Approximate the posterior\n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\ngrid_data\n## # A tibble: 6 × 5\n##   pi_grid prior likelihood unnormalized posterior\n##     <dbl> <dbl>      <dbl>        <dbl>     <dbl>\n## 1     0    0    0            0          0        \n## 2     0.2  0.96 0.00000410   0.00000393 0.0000124\n## 3     0.4  1.44 0.00157      0.00226    0.00712  \n## 4     0.6  1.44 0.0403       0.0580     0.183    \n## 5     0.8  0.96 0.268        0.258      0.810    \n## 6     1    0    0            0          0\n\nggplot(grid_data, aes(x = pi_grid, y = posterior)) +\n  geom_point() +\n  geom_segment(aes(xend = pi_grid, yend = 0))\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nThat's our discretized posterior, but since there are only 6 values, it's not great. If we sample from it, the samples will be just 0.6, 0.8, etc.:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_samples <- grid_data |> \n  slice_sample(n = 10000, replace = TRUE, weight_by = posterior)\n\nposterior_samples |> count(pi_grid)\n## # A tibble: 3 × 2\n##   pi_grid     n\n##     <dbl> <int>\n## 1     0.4    56\n## 2     0.6  1809\n## 3     0.8  8135\n```\n:::\n\n\nLet's compare that to the actual $\\operatorname{Beta}(11, 3)$ posterior:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(posterior_samples, aes(x = pi_grid)) +\n  geom_histogram(aes(y = ..density..), color = \"white\", binwidth = 0.1, boundary = 0) +\n  stat_function(fun = ~dbeta(., 11, 3)) +\n  xlim(c(0, 1))\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nlol\n\nHere's the same grid approximation with 10,000 grid values this time:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_data <- tibble(pi_grid = seq(0, 1, length.out = 10000)) |> \n  mutate(prior = dbeta(pi_grid, 2, 2),\n         likelihood = dbinom(9, 10, pi_grid)) |> \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n\n# Actual approximated posterior\nggplot(grid_data, aes(x = pi_grid, y = posterior)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Samples from the posterior\nposterior_samples <- grid_data |> \n  slice_sample(n = 10000, replace = TRUE, weight_by = posterior)\n\nggplot(posterior_samples, aes(x = pi_grid)) +\n  geom_histogram(aes(y = ..density..), color = \"white\", binwidth = 0.01, boundary = 0) +\n  stat_function(fun = ~dbeta(., 11, 3)) +\n  xlim(c(0, 1))\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n:::\n\n\n## Gamma-Poisson example\n\n$$\n\\begin{aligned}\nY_i &\\sim \\operatorname{Poisson}(\\lambda) \\\\\n\\lambda &= \\operatorname{Gamma}(3, 1)\n\\end{aligned}\n$$\n\nIf we see Y = 2 and then Y = 8, our true posterior based on conjugate family magic ends up being this:\n\n$$\n\\lambda \\mid Y = (2, 8) \\sim \\operatorname{Gamma}(3 + (2 + 8), 1 + 2) \\rightarrow \\operatorname{Gamma}(13, 3)\n$$\n\nGrid time:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_data <- tibble(lambda_grid = seq(0, 15, length.out = 501)) |> \n  mutate(prior = dgamma(lambda_grid, 3, 1),\n         likelihood = dpois(2, lambda_grid) * dpois(8, lambda_grid)) |> \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n\n# Actual approximated posterior\nggplot(grid_data, aes(x = lambda_grid, y = posterior)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Samples from the posterior\nposterior_samples <- grid_data |> \n  slice_sample(n = 10000, replace = TRUE, weight_by = posterior)\n\nggplot(posterior_samples, aes(x = lambda_grid)) +\n  geom_histogram(aes(y = ..density..), color = \"white\", binwidth = 0.5, boundary = 0) +\n  stat_function(fun = ~dgamma(., 13, 3)) +\n  xlim(c(0, 15))\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\nLovely.\n\n\n# 6.2 Markov chains via rstan\n\n**MCMC samples aren't independent**—each value depends on the previous value (hence \"chains\"). But you only need to know one previous value of $\\theta$ to calculate the next $\\theta$, so there's no long history or anything. Also, the chain of $\\theta$ values aren't even simulated from the posterior. But with magical MCMC *algorithms*, we can approximate the posterior with the values in the chains\n\n## Beta-binomaial\n\nLet's do this model again, but with Stan instead of with grid approximation:\n\n$$\n\\begin{aligned}\nY &\\sim \\operatorname{Binomial}(10, π) \\\\\n\\pi &= \\operatorname{Beta}(2, 2)\n\\end{aligned}\n$$\n\n\n::: {.cell output.var='bb_sim'}\n\n```{.stan .cell-code}\n// Step 1: Define the model\n// Stuff from R\ndata {\n  int<lower=0, upper=10> Y;\n}\n\n// Thing to estimate\nparameters {\n  real<lower=0, upper=1> pi;\n}\n\n// Prior and likelihood\nmodel {\n  Y ~ binomial(10, pi);\n  pi ~ beta(2, 2);\n}\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 2: Simulate the posterior\n# Compiled cmdstan objects are R6 objects with functions embedded in specific\n# slots, which makes it hard to look them up in the documentation. ?CmdStanModel\n# shows an index of all the available methods, like $sample()\nbb_sim_samples <- bb_sim$sample(\n  data = list(Y = 9),\n  parallel_chains = 4, iter_warmup = 2500, iter_sampling = 2500, \n  refresh = 0, seed = BAYES_SEED\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.3 seconds.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# cmdstan samples are also R6 objects with embedded functions. $draws() lets you\n# extract the draws as an array\nbb_sim_samples$draws(variables = \"pi\") |> head(4)\n## # A draws_array: 4 iterations, 4 chains, and 1 variables\n## , , variable = pi\n## \n##          chain\n## iteration    1    2    3    4\n##         1 0.89 0.75 0.71 0.87\n##         2 0.94 0.87 0.56 0.82\n##         3 0.88 0.89 0.59 0.82\n##         4 0.89 0.81 0.67 0.76\n\n# Or we can use posterior::as_draws_array to avoid R6\n# as_draws_array(bb_sim_samples)\n\n# Or even better, use tidybayes\nbb_sim_samples |>\n  spread_draws(pi) |> \n  head(4)\n## # A tibble: 4 × 4\n##   .chain .iteration .draw    pi\n##    <int>      <int> <int> <dbl>\n## 1      1          1     1 0.888\n## 2      1          2     2 0.938\n## 3      1          3     3 0.877\n## 4      1          4     4 0.892\n```\n:::\n\n\nThe values in these chains **aren't** independent. In chain 1 here, for instance, it starts with 0.89, then plugs that into the next iteration to get 0.94, then plugs *that* into the next iteration to get 0.88, then plugs *that* into the *next* iteration to get 0.89, and so on.\n\nThe chain explores the **sample space**, or range of posterior plausible $\\pi$s. We want them to explore lots of values along their journey, and we can check that by looking at traceplots (to show the history of the chain) and density plots (to show the distribution of values that were visited)\n\n::: {.panel-tabset}\n### Trace plot, first few iterations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Look at the first 20, for fun\nbb_sim_samples |>\n  gather_draws(pi) |> \n  filter(.iteration <= 20) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 1) +\n  facet_grid(rows = vars(.variable), cols = vars(.chain)) +\n  labs(color = \"Chain\")\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### Full trace plot, separate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbb_sim_samples |>\n  gather_draws(pi) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.1) +\n  facet_grid(rows = vars(.variable), cols = vars(.chain)) +\n  labs(color = \"Chain\")\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n### Full trace plot, mixed\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbb_sim_samples |>\n  gather_draws(pi) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.1) +\n  labs(color = \"Chain\")\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n:::\n\n\nAnd here's the distribution of the draws, which should be the same as the numeric $\\operatorname{Beta}(11, 3)$ posterior:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbb_sim_samples |>\n  spread_draws(pi) |> \n  ggplot(aes(x = pi)) +\n  stat_density(geom = \"area\", fill = clrs[1]) +\n  stat_function(fun = ~dbeta(., 11, 3), color = clrs[3], size = 1)\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n## Gamma-Poisson\n\n$$\n\\begin{aligned}\nY_i &\\sim \\operatorname{Poisson}(\\lambda) \\\\\n\\lambda &= \\operatorname{Gamma}(3, 1)\n\\end{aligned}\n$$\n\n\n::: {.cell output.var='gp_sim'}\n\n```{.stan .cell-code}\n// Step 1: Define the model\n// Stuff from R\ndata {\n  array[2] int Y;\n}\n\n// Thing to estimate\nparameters {\n  real<lower=0, upper=15> lambda;\n}\n\n// Prior and likelihood\nmodel {\n  Y ~ poisson(lambda);\n  lambda ~ gamma(3, 1);\n}\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 2: Simulate the posterior\ngp_sim_samples <- gp_sim$sample(\n  data = list(Y = c(2, 8)),\n  parallel_chains = 4, iter_warmup = 2500, iter_sampling = 2500, \n  refresh = 0, seed = BAYES_SEED\n)\n## Running MCMC with 4 parallel chains...\n## \n## Chain 1 finished in 0.0 seconds.\n## Chain 2 finished in 0.0 seconds.\n## Chain 3 finished in 0.0 seconds.\n## Chain 4 finished in 0.0 seconds.\n## \n## All 4 chains finished successfully.\n## Mean chain execution time: 0.0 seconds.\n## Total execution time: 0.2 seconds.\n```\n:::\n\n\nCheck the chains:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngp_sim_samples |>\n  gather_draws(lambda) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.1) +\n  labs(color = \"Chain\")\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nCompare the distribution with the true $\\operatorname{Gamma}(13, 3)$ posterior:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngp_sim_samples |>\n  spread_draws(lambda) |> \n  ggplot(aes(x = lambda)) +\n  stat_density(geom = \"area\", fill = clrs[2]) +\n  stat_function(fun = ~dgamma(., 13, 3), color = clrs[3], size = 1)\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n# 6.3: Markov chain diagnostics\n\n## 6.3.1: Examining trace plots\n\nTrace plots should look like nothing (\"hairy caterpillars\"). This indicates that the chains are stable, well-mixed, and converged:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngp_sim_samples |>\n  gather_draws(lambda) |> \n  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +\n  geom_line(size = 0.1) +\n  labs(color = \"Chain\")\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nWe can also use trace rank plots (trank plots), where we take all the samples for a parameter ($\\lambda$ here), calculate their ranks, and make a histogram of those ranks colored by chain. According to McElreath (p. 284),\n\n> If the chains are exploring the same space efficinetly, the histograms should be similar to one another and largely overlapping.\n\nNeat!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngp_sim_samples |>\n  spread_draws(lambda) |> \n  mutate(draw_rank = rank(lambda)) |> \n  ggplot(aes(x = draw_rank)) +\n  stat_bin(aes(color = factor(.chain)), geom = \"step\", binwidth = 500, \n           position = position_identity(), boundary = 0) + \n  labs(color = \"Chain\") +\n  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nHere are some bad traceplots from Figure 6.12 in the book:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/bad-trace-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\nChain A has a noticeable slope, which is a sign that it hasn't stabilized. It hasn't found a good range of possible $\\pi$ values. It is mixing slowly.\n\nChain B gets stuck when exploring smaller values of $\\pi$\n\nFix these issues by (1) making sure the model and priors are appropriate, and (2) run the chain for more iterations.\n\n## 6.3.2 Comparing parallel chains\n\nWe want to see consistency across the four chains. Check with a density plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngp_sim_samples |>\n  spread_draws(lambda) |> \n  ggplot(aes(x = lambda, color = factor(.chain))) +\n  geom_density() +\n  labs(color = \"Chain\")\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## 6.3.3. Effective sample size and autocorrelation\n\nSince there are so many MCMC draws, it's tricky to know what the actual sample size is. \"How many [truly] independent sample values would it take to produce an equivalently accurate posterior approximation?\" That's what the effective sample size ratio\nis for:\n\n$$\n\\frac{N_\\text{effective}}{N}\n$$\n\nThere's no official rule for this, but it would be bad if a chain had a ratio of less than 0.1, or where the effective sample size is less than 10% of the actual sample size.\n\nFor both of these models the ratio is 34ish%, which means \"our 20,000 Markov chain values are about as useful as only 6800 independent samples (0.34 × 20000).\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::neff_ratio(bb_sim_samples)\n##        pi \n## 0.3423651\nbayesplot::neff_ratio(gp_sim_samples)\n##    lambda \n## 0.3456354\n```\n:::\n\n\nThe `bayesplot::neff_ratio()` uses the `ess_basic` summary statistic, which [Aki Vehtari says is fine here](https://avehtari.github.io/rhat_ess/ess_comparison.html). We can also extract the ESS basic statistic with `posterior::ess_basic()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior::ess_basic(bb_sim_samples$draws(variables = \"pi\"))\n## [1] 3401.823\n```\n:::\n\n\nHowever, in the documentation for `ess_basic()`, the Stan team strongly recommends using either `ess_bulk` or `ess_tail`, both of which are reported by default in `summary()` (and also in rstanarm and brms models):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior::ess_bulk(bb_sim_samples$draws(variables = \"pi\")) / 10000\n## [1] 0.3114404\nposterior::ess_tail(bb_sim_samples$draws(variables = \"pi\")) / 10000\n## [1] 0.3960722\nbb_sim_samples$summary() |> \n  select(variable, mean, median, ess_bulk, ess_tail)\n## # A tibble: 2 × 5\n##   variable   mean median ess_bulk ess_tail\n##   <chr>     <dbl>  <dbl>    <dbl>    <dbl>\n## 1 lp__     -7.80  -7.52     4526.    4831.\n## 2 pi        0.785  0.800    3140.    3991.\n```\n:::\n\n\nWe can also look at autocorrelation. There's inherently *some* degree of autocorrelation, since each draw depends on the previous one, but we still want draws to bounce around and to not be too correlated after a few lagged periods.\n\nWe can check this with an autocorrelation plot. This shows the correlation between an MCMC draw and the one before it at different lags. When the lag is 0, there's perfect correlation (since it's the correlation between the draw and itself). At lag 1, there's a correlation of 0.5 between a draw and its previous value, and it drops off to near 0 by the time we get to 5 lags. That's good.\n\n> [T]here’s very little correlation between Markov chain values that are more than a few steps apart. This is all good news. It’s more confirmation that our Markov chain is mixing quickly, i.e., quickly moving around the range of posterior plausible π values, and thus at least mimicking an independent sample.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boring bayesplot way\n# mcmc_acf(bb_sim_samples$draws(variables = \"pi\"))\n\nautocor_manual <- bb_sim_samples |>\n  spread_draws(pi) |> \n  group_by(.chain) |> \n  nest() |> \n  summarize(autocor = map(data, ~{\n    x <- acf(.$pi, plot = FALSE, lag.max = 20)\n    tibble(lag = x$lag, acf = x$acf)\n  })) |>\n  unnest(autocor)\n\nggplot(autocor_manual, aes(x = lag, y = acf, color = factor(.chain))) +\n  geom_line() +\n  scale_x_continuous(breaks = 0:20) +\n  labs(x = \"Lag\", y = \"Autocorrelation\", color = \"Chain\") +\n  theme(panel.grid.minor = element_blank())\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\nFinally, we can look at $\\hat{R}$ or R-hat. R-hat looks at the consistency of values across chains:\n\n> R-hat addresses this consistency by comparing the variability in sampled π values *across* all chains combined to the variability *within* each individual chain\n\n$$\n\\hat{R} \\approx \\sqrt{\\frac{\\operatorname{Variability}_\\text{combined}}{\\operatorname{Variability}_\\text{within}}}\n$$\n\nWe want R-hat to be 1. When R-hat > 1, it means there's instability across chains, and more specifically that \"the variability in the combined chains exceeds that within the chains. R-hat > 1.05 is bad (and the Stan people have recently [considered thinking about 1.01 as a possible warning sign](https://arxiv.org/pdf/1903.08008.pdf), and proposed alternative mixing statistics, like R*).\n\nBasically we want the variability across the chains to look just like the variability within the chains so that it's impossible to distinguish between them in a trace plot. Can you see any rogue chains here? Nope. We're good.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrhat_basic(bb_sim_samples$draws(variables = \"pi\"))\n## [1] 1.000178\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbb_sim_samples |>\n  gather_draws(pi) |> \n  ggplot(aes(x = .iteration, y = .value, group = .chain)) +\n  geom_line(size = 0.1) +\n  labs(color = \"Chain\")\n```\n\n::: {.cell-output-display}\n![](06-chapter_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "06-chapter_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}